---
about_this_resource_text: <p><b>Topics covered:</b>&nbsp;Universal Hashing, Perfect
  Hashing</p><p><b>Instructors:</b>&nbsp;Prof. Erik Demaine,&nbsp;Prof. Charles Leiserson&nbsp;</p>
course_id: 6-046j-introduction-to-algorithms-sma-5503-fall-2005
embedded_media:
- id: lec8.pdf
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-8-universal-hashing-perfect-hashing/lec8.pdf
  title: lec8.pdf
  type: null
  uid: f6dbba11eee38c20d1133fe4c7e556bc
- id: 6_046J_lec08_th.jpg
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-8-universal-hashing-perfect-hashing/6_046J_lec08_th.jpg
  title: 6_046J_lec08_th.jpg
  type: null
  uid: 9f9a0a2067e8e6c43503e78c4ebaa688
- id: Video-YouTube-Stream
  media_location: s7QSM_hlS1U
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-YouTube-Stream
  type: Video
  uid: a41e341200beab1b79a4c1224f23975c
- id: Thumbnail-YouTube-JPG
  media_location: https://img.youtube.com/vi/s7QSM_hlS1U/default.jpg
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Thumbnail-YouTube-JPG
  type: Thumbnail
  uid: 3c1b6e89a960b13d071496295b5ae7ef
- id: Video-iTunesU-MP4
  media_location: https://itunes.apple.com/us/itunes-u/id341597754
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-iTunes U-MP4
  type: Video
  uid: fc74785b263f79db8d736959073d575f
- id: Video-InternetArchive-MP4
  media_location: http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-05oct2005-220k.mp4
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-Internet Archive-MP4
  type: Video
  uid: 8a6b2b0a4913cbd19d8d150968b97e90
- id: Video-iTunesU-MP3
  media_location: http://deimos3.apple.com/WebObjects/Core.woa/Browse/mit.edu.1298167185.01298167189.1303740701?i=2057332323
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-iTunes U-MP3
  type: Video
  uid: a7bca60ba5ebff190205fb0d4fb4a7f1
- id: Video-InternetArchive-MP3
  media_location: http://www.archive.org/download/MIT6.046JF05/ocw-6.046-05oct2005.mp3
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-Internet Archive-MP3
  type: Video
  uid: 4d35515fb571f575d81a5044aac9d9d6
- id: Video-VideoLecturesnet-Stream
  media_location: http://videolectures.net/mit6046jf05_introduction_algorithms/
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Video-VideoLectures.net-Stream
  type: Video
  uid: e8491469f29f1f251591f7cb03b4bcab
- id: Thumbnail-OCW-JPG
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Thumbnail-OCW-JPG
  type: Thumbnail
  uid: 101cdd034a26f0a55c8eaa670f55ffae
- id: 3Play-3PlayYouTubeid-MP4
  media_location: s7QSM_hlS1U
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: 3Play-3Play YouTube id
  type: 3Play
  uid: a0ed9e0314bce368c9200ffe27376aaf
- id: s7QSM_hlS1U.srt
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-8-universal-hashing-perfect-hashing/s7QSM_hlS1U.srt
  title: 3play caption file
  type: null
  uid: 14e244eb2acddfb86d13307de4433d6b
- id: s7QSM_hlS1U.pdf
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-8-universal-hashing-perfect-hashing/s7QSM_hlS1U.pdf
  title: 3play pdf file
  type: null
  uid: bca0ea665bfebaf4b67b821ddaa6945f
- id: Caption-3Play YouTube id-SRT
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Caption-3Play YouTube id-SRT-English - US
  type: Caption
  uid: 9fa902dc522f8938e5d49507c77b8bf0
- id: Transcript-3Play YouTube id-PDF
  parent_uid: de9e94bd085415a2dd7fbc73512ae8b0
  title: Transcript-3Play YouTube id-PDF-English - US
  type: Transcript
  uid: 96f259630ed3fb38d8e8c87c2ffbe9a4
inline_embed_id: 55175928lecture8:universalhashing,perfecthashing60426594
layout: video
order_index: null
parent_uid: c492612542f7cc7a09f73790a5f91d81
related_resources_text: <p>Lecture Notes (<a target="_blank" href="./resolveuid/f6dbba11eee38c20d1133fe4c7e556bc">PDF</a>)<br
  />             <a target="_blank" href="./resolveuid/efc69ef86c18e164d675bd8808c6477a">Assignments</a><br
  />             <a target="_blank" href="./resolveuid/144d9e513546eac8c1fd9b0d278e6eb2">Exams</a></p>
short_url: lecture-8-universal-hashing-perfect-hashing
technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-8-universal-hashing-perfect-hashing
template_type: Tabbed
title: 'Lecture 8: Universal Hashing, Perfect Hashing'
transcript: <p><span m='0'>So to finish up,</span> <span m='9000'>Hashing.</span>
  </p><p><span m='15000'>Today we're going to do some amazing stuff with hashing.</span>
  </p><p><span m='19000'>And, really, this is such neat stuff,</span> <span m='21000'>it's
  amazing. We're going to start by</span> <span m='24000'>addressing a fundamental
  weakness of hashing.</span> </p><p><span m='34000'>And that is that for any choice
  of hash function</span> <span m='49000'>There exists a bad set of keys that all
  hash to the same slot.</span> </p><p><span m='69000'>OK. So you pick a hash function.</span>
  </p><p><span m='71000'>We looked at some that seem to work well in practice,</span>
  <span m='75000'>that are easy to put into your code.</span> </p><p><span m='78000'>But
  whichever one you pick, there's always some bad set of</span> <span m='83000'>keys.
  So you can imagine,</span> <span m='85000'>just to drive this point home a little
  bit.</span> </p><p><span m='90000'>Imagine that you're building a compiler for a
  customer and you</span> <span m='95000'>have a symbol table in your compiler and
  one of the things</span> <span m='100000'>that the customer is demanding is that
  compilations go fast.</span> </p><p><span m='106000'>They don't want to sit around
  waiting for compilations.</span> </p><p><span m='110000'>And you have a competitor
  who's also building a compiler and</span> <span m='116000'>they're going to test
  the compiler, both of your compilers</span> <span m='121000'>and sort of have a
  run-off. And one of the things in the</span> <span m='127000'>test that they're
  going to allow you to do is not only will the</span> <span m='132000'>customer run
  his own benchmarks, but he'll let you make up</span> <span m='136000'>benchmarks
  for the other program, for your competitor.</span> </p><p><span m='140000'>And your
  competitor gets to make up benchmarks for you.</span> </p><p><span m='144000'>So
  and not only that, but you're actually sharing</span> <span m='148000'>code. So
  you get to look at what the</span> <span m='152000'>competitor is actually doing
  and what hash function they're</span> <span m='157000'>actually using. So it's pretty
  clear that in</span> <span m='160000'>this circumstance, you have an adversary who
  is</span> <span m='164000'>going to look at whatever hash function you have and
  figure out</span> <span m='169000'>OK, what's a set of variable names and so forth
  that are</span> <span m='173000'>going to all hash to the same slot so that essentially
  you're</span> <span m='178000'>just chasing through a linked list whenever it comes
  to</span> <span m='183000'>looking something up. Slowing down your program</span>
  <span m='187000'>enormously compared to if in fact they got distributed nicely</span>
  <span m='192000'>across the hash table which is, what after all,</span> <span m='195000'>you
  have a hash table in there to do in the first place.</span> </p><p><span m='199000'>And
  so the question is, how do you defeat this</span> <span m='202000'>adversary? And
  the answer is one word.</span> </p><p><span m='211000'>One word. How do you achieve?</span>
  </p><p><span m='213000'>How do you defeat any adversary in this class?</span> </p><p><span
  m='217000'>Randomness. OK.</span> </p><p><span m='218000'>Randomness. OK.</span>
  </p><p><span m='219000'>You make it so that he can't guess.</span> </p><p><span
  m='222000'>And the idea is that you choose a hash function at random.</span> </p><p><span
  m='227000'>Independent. So he can look at the code,</span> <span m='230000'>but
  when it actually runs, it's going to use a random hash</span> <span m='235000'>function
  that he has no way of predicting what the hash</span> <span m='240000'>function
  is that will actually be used.</span> </p><p><span m='245000'>OK. So that's the
  game and that way</span> <span m='247000'>he can provide an input, but he can't
  provide an input</span> <span m='251000'>that's guaranteed to force you to run slowly.</span>
  </p><p><span m='255000'>You might get unlucky in your choice of hash function,</span>
  <span m='259000'>but it's not going to be because of the adversary.</span> </p><p><span
  m='263000'>So the idea is to choose a hash function --</span> <span m='274000'>--
  at random, independently from the keys</span> <span m='278000'>that you're, that
  are going to be fed to it.</span> </p><p><span m='282000'>So even if your adversary
  can see your code,</span> <span m='287000'>he can't tell which hash function is
  going to be actually</span> <span m='293000'>used at run time. Doesn't get to see
  the output</span> <span m='298000'>of the random numbers. And so it turns out you
  can</span> <span m='304000'>make this scheme work and the name of the scheme is
  universal</span> <span m='311000'>hashing, OK, is one way of making this scheme
  work.</span> </p><p><span m='322000'>So let's do some math. So let U be a universe
  of keys.</span> </p><p><span m='334000'>And let H be a finite collection --</span>
  <span m='348000'>-- of hash functions --</span> <span m='356000'>-- mapping U to
  what are going to be the slots in our hash</span> <span m='364000'>table. OK.</span>
  </p><p><span m='366000'>So we just have H as some finite collection.</span> </p><p><span
  m='371000'>We say that H is universal --</span> <span m='382000'>-- if for all pairs
  of the keys, distinct keys --</span> <span m='396000'>-- so the keys are distinct,
  the following is true.</span> </p><p><span m='423000'>So if the set of keys, if
  for any pair of keys I pick,</span> <span m='428000'>the number of hash functions
  that hash those two keys to the</span> <span m='435000'>same place is a one over
  m fraction of the total set of</span> <span m='441000'>keys. So let m just,</span>
  <span m='443000'>so to view that, another way of viewing that is</span> <span m='448000'>if
  H is chosen randomly --</span> <span m='459000'>-- from the set of keys H, the probability
  of collision</span> <span m='471000'>between x and y is what?</span> </p><p><span
  m='492000'>What's the probability if the fraction of hash functions,</span> <span
  m='497000'>OK, if the number of hash functions is H over m,</span> <span m='502000'>what's
  the probability of a collision between x and y?</span> </p><p><span m='507000'>If
  I pick a hash function at random.</span> </p><p><span m='512000'>So I pick a hash
  function at random, what's the odds they</span> <span m='519000'>collide? One over
  m.</span> </p><p><span m='522000'>Now let's draw a picture for that, help people
  see that</span> <span m='529000'>that's in fact the case. So imagine this is our
  set of</span> <span m='536000'>all hash functions. OK.</span> </p><p><span m='540000'>And
  then if I pick a particular x and y, let's say that this is</span> <span m='548000'>the
  set of hash functions such that H of x is equal to H of y.</span> </p><p><span m='556000'>And
  so what we're saying is that the cardinality of that set</span> <span m='563000'>is
  one over m times the cardinality of H.</span> </p><p><span m='570000'>So if I throw
  a dart and pick one hash function at random,</span> <span m='573000'>the odds are
  one in m that the hash function falls into this</span> <span m='577000'>particular
  set. And of course,</span> <span m='579000'>this has to be true of every x and y
  that I can pick.</span> </p><p><span m='583000'>Of course, it will be a different
  set,</span> <span m='585000'>a different x and y will somehow map the hash functions</span>
  <span m='589000'>differently, but the odds that for any x and y that I pick,</span>
  <span m='592000'>the odds that if I have a random hash function,</span> <span m='595000'>it
  hashes it to the same place, is one over m.</span> </p><p><span m='600000'>Now this
  is a little bit hard sometimes for people to get</span> <span m='603000'>their head
  around because we're used to thinking of perhaps</span> <span m='607000'>picking
  keys at random or something.</span> </p><p><span m='609000'>OK, that's not what's
  going on here.</span> </p><p><span m='611000'>We're picking hash functions at random.</span>
  </p><p><span m='614000'>So our probability space is defined over the hash functions,</span>
  <span m='618000'>not over the keys. And this has to be true now for</span> <span
  m='621000'>any particular two keys that I pick that are distinct.</span> </p><p><span
  m='624000'>That the places that they hash, this set of hash functions,</span> <span
  m='628000'>I mean this is like a marvelous property if you think about it.</span>
  </p><p><span m='634000'>OK, that you can actually find ones where no matter what
  two</span> <span m='639000'>elements I pick, the odds are exactly one in m</span>
  <span m='643000'>that a random hash function from this set is going to hash them</span>
  <span m='648000'>to the same place. So very neat.</span> </p><p><span m='651000'>Very,
  very neat property and we'll see the mathematics</span> <span m='656000'>associated
  with this is very cool.</span> </p><p><span m='660000'>So our theorem is that if
  we choose h randomly from the set</span> <span m='674000'>of hash functions H, and
  then we suppose we're</span> <span m='685000'>hashing n keys into m slots in Table
  T --</span> <span m='704000'>-- then for given key x --</span> <span m='712000'>--
  the expected number of collisions with x --</span> <span m='723000'>-- is less than
  n over m. And who remembers what we call</span> <span m='732000'>n over m? Alpha,
  which is the,</span> <span m='736000'>what's the term that we use there?</span>
  </p><p><span m='742000'>Load factor. The load factor of the table.</span> </p><p><span
  m='750000'>OK, load factor alpha. So the average number of keys</span> <span m='756000'>per
  slot is the load factor of the table.</span> </p><p><span m='762000'>So we're saying,
  so what is this theorem saying?</span> </p><p><span m='768000'>It's saying that
  in fact, if we have one of these</span> <span m='775000'>universal sets of hash
  functions, then things perform</span> <span m='782000'>exactly the way we want them
  to. Things get distributed evenly.</span> </p><p><span m='790000'>The number of
  things that are going to collide with any</span> <span m='795000'>particular key
  that I pick is going to be n over m.</span> </p><p><span m='799000'>So that's a
  really good property to have.</span> </p><p><span m='802000'>Now I haven't shown
  you, the construction of U is going,</span> <span m='807000'>sorry, of the set of
  hash functions H, that that</span> <span m='811000'>construction will take us a
  little bit of effort.</span> </p><p><span m='816000'>But first I want to show you
  why this is such a great</span> <span m='819000'>property. Basically it's this theorem.</span>
  </p><p><span m='822000'>So let's prove this theorem. So any questions about what
  the</span> <span m='826000'>statement of the theorem is? So we're going to go actually</span>
  <span m='830000'>kind of fast today. We've got a lot of good stuff</span> <span
  m='834000'>today. So I want to make sure people</span> <span m='837000'>are onboard
  as we go through. So if there are any questions,</span> <span m='843000'>make sure,
  you know, statement of theorem of</span> <span m='847000'>whatever, best to get
  them out early so that you're not</span> <span m='853000'>confused later on when
  the going gets a little more exciting.</span> </p><p><span m='859000'>OK? OK, good.</span>
  </p><p><span m='861000'>So to prove this, let's let C sub x be the random</span>
  <span m='866000'>variable denoting the total number of collisions --</span> <span
  m='878000'>-- of keys in T with x. So this is a total number and</span> <span m='884000'>one
  of the techniques that you use a lot in probabilistic</span> <span m='891000'>analysis
  of randomized algorithms is recognizing that C</span> <span m='897000'>of x is in
  fact a sum of indicator random variables.</span> </p><p><span m='905000'>If you
  can decompose things into indicator random variables,</span> <span m='911000'>the
  analysis goes much more easily than if you're left with</span> <span m='917000'>aggregate
  variables. So here we're going to let our</span> <span m='922000'>indicator random
  variable be little c of x.,</span> <span m='927000'>which is going to be one if
  h of x equals h of y and 0</span> <span m='932000'>otherwise.</span> </p><p><span
  m='940000'>And so we can note two things. First, what is the expectation</span>
  <span m='949000'>of C of x..</span> </p><p><span m='957000'>OK, if I have a process
  which is picking a hash function at</span> <span m='960000'>random, what's the expectation
  of C of x.?</span> </p><p><span m='964000'>One over m. Because that's basically
  this</span> <span m='967000'>definition here. Now in other words I pick a</span>
  <span m='971000'>hash function at random, what's the odds that the hash</span> <span
  m='976000'>is the same? It's one over m.</span> </p><p><span m='979000'>And then
  the other thing is, and the reason we pick this</span> <span m='984000'>thing is
  that I can express capital C sub x,</span> <span m='988000'>the random variable
  denoting the total number of collisions</span> <span m='993000'>as being just the
  sum over all the keys in the table except x</span> <span m='999000'>of C of x..
  So for each one that would</span> <span m='1006000'>cause me a collision, with x,
  I add one and if it</span> <span m='1013000'>wouldn't cause me a collision, I add
  0.</span> </p><p><span m='1020000'>And that adds up all of the collisions that I
  would have in</span> <span m='1026000'>the table with x.</span> </p><p><span m='1037000'>Is
  there any questions so far? Because this is the set-up.</span> </p><p><span m='1040000'>The
  set-up in most of these things, the set-up is where most</span> <span m='1044000'>students
  make mistakes and most practicing researchers make</span> <span m='1047000'>mistakes
  as well, let me tell you.</span> </p><p><span m='1050000'>And then once you get
  the set-up right,</span> <span m='1052000'>then working out the math is fine, but
  it's often that set-up</span> <span m='1056000'>of how do you actually translate
  the situation into the math.</span> </p><p><span m='1060000'>That's the hard part.
  Once you get that right,</span> <span m='1063000'>well, then, algebra, we can all
  do algebra.</span> </p><p><span m='1066000'>Of course, we can also all make mistakes
  doing algebra,</span> <span m='1069000'>but at least those mistakes are much more
  easy to check than the</span> <span m='1073000'>one that does the translation. So
  I want to make sure people</span> <span m='1077000'>are sort of understanding of
  how that's set up.</span> </p><p><span m='1080000'>So now we just have to use our
  math skills.</span> </p><p><span m='1085000'>So the expectation then of the number
  of collisions is the</span> <span m='1092000'>expectation of C sub x and that's
  just the expectation of</span> <span m='1098000'>just plugging the sum of y and
  T minus the element x of c_xy.</span> </p><p><span m='1106000'>So that's just definition.
  And that's equal to the sum of</span> <span m='1113000'>y and T minus x of expectation
  of c_xy.</span> </p><p><span m='1119000'>So why is that? Yeah, that's linearity.</span>
  </p><p><span m='1132000'>Linearity of expectation, doesn't require independence.</span>
  </p><p><span m='1136000'>It's true of all random variables.</span> </p><p><span
  m='1140000'>And that's equal to, and now the math gets easier.</span> </p><p><span
  m='1147000'>So what is that? One over m.</span> </p><p><span m='1150000'>That makes
  the summation easy to evaluate.</span> </p><p><span m='1156000'>That's just n minus
  one over m.</span> </p><p><span m='1170000'>So fairly simple analysis and shows
  you why we would love to</span> <span m='1175000'>have one of these sets of universal
  hash functions because</span> <span m='1181000'>if you have them, then they behave
  exactly the</span> <span m='1185000'>way you would want it to behave. And you defeat
  your adversary</span> <span m='1191000'>by just picking up the hash function at
  random.</span> </p><p><span m='1195000'>There's nothing he can do. Or she.</span>
  </p><p><span m='1200000'>OK, any questions about that proof?</span> </p><p><span
  m='1202000'>OK, now we get into the fun math.</span> </p><p><span m='1204000'>Constructing
  one of these babies.</span> </p><p><span m='1207000'>OK.</span> </p><p><span m='1220000'>This
  is not the only construction.</span> </p><p><span m='1223000'>This is a construction
  of a classic universal hash function.</span> </p><p><span m='1231000'>And there
  are other constructions in the literature</span> <span m='1237000'>and I think there's
  one on the practice quiz.</span> </p><p><span m='1242000'>So let's see. So this
  one works when m is</span> <span m='1247000'>prime. So it works when the set of</span>
  <span m='1251000'>slots is a prime number. Number of slots is a prime</span> <span
  m='1257000'>number. So the idea here is we're going</span> <span m='1265000'>to
  decompose any key k in our universe into r plus 1 digits.</span> </p><p><span m='1276000'>So
  k, we're going to look at as being a k 0, k one,</span> <span m='1285000'>k_r where
  0 is less than or equal to k sub I,</span> <span m='1293000'>is less than or equal
  to m minus one.</span> </p><p><span m='1301000'>So the idea is in some sense we're
  looking at what the</span> <span m='1307000'>representation would be of k base m.</span>
  </p><p><span m='1312000'>So if it were base two, it would be just one bit at a</span>
  <span m='1318000'>time. These would just be the bits.</span> </p><p><span m='1321000'>I'm
  not going to do base two. We're going to do base min</span> <span m='1325000'>general
  and so each of these represents one of the digits.</span> </p><p><span m='1329000'>And
  the way I've done it is I've done low order digit first.</span> </p><p><span m='1333000'>It
  actually doesn't matter. We're not actually going to</span> <span m='1336000'>care
  really about what the order is, but basically we're just</span> <span m='1340000'>looking
  at busting it into a twofold represented by each of</span> <span m='1344000'>those
  digits. So one algorithm for computing</span> <span m='1347000'>this out of k is
  take the remainder mod m.</span> </p><p><span m='1351000'>That's the low order one.
  OK, take what's left.</span> </p><p><span m='1354000'>Take the remainder of that
  mod m.</span> </p><p><span m='1357000'>Take whatever's left, etc.</span> </p><p><span
  m='1359000'>So you're familiar with the conversion to a base</span> <span m='1362000'>representation.
  That's exactly how we're</span> <span m='1366000'>getting this representation. So
  we treat,</span> <span m='1369000'>this is just a question of taking the data that
  we've got</span> <span m='1373000'>and treating it as an r plus one base m number.</span>
  </p><p><span m='1377000'>And now we invoke our randomized strategy.</span> </p><p><span
  m='1382000'>The randomized strategy is going to be able to have a class</span> <span
  m='1385000'>of hash functions that's dependent essentially on random</span> <span
  m='1389000'>numbers. And the random numbers we're</span> <span m='1391000'>going
  to pick is we're going to pick an a at random --</span> <span m='1408000'>-- which
  we're also going to look at as a base mnumber.</span> </p><p><span m='1413000'>For
  each a_i is chosen randomly --</span> <span m='1429000'>-- from --</span> <span
  m='1435000'>-- 0 to m minus one. So one of our,</span> <span m='1438000'>it's a
  random if you will, it's a random base mdigit.</span> </p><p><span m='1443000'>Random
  base m digit. So each one of these is picked</span> <span m='1446000'>at random.
  And for each one we,</span> <span m='1449000'>possible value of A, we're going to
  get a different</span> <span m='1453000'>hash function. So we're going to index
  our</span> <span m='1456000'>hash functions by this random number.</span> </p><p><span
  m='1459000'>So this is where the randomness is going to come in.</span> </p><p><span
  m='1463000'>Everybody with me? And here's the hash function.</span> </p><p><span
  m='1496000'>So what we do is we dot product this vector with this vector and</span>
  <span m='1506000'>take the result, mod m.</span> </p><p><span m='1511000'>So each
  digit of k of our key gets multiplied by a random</span> <span m='1518000'>other
  digit. We add all those up and we take</span> <span m='1525000'>that mod m. So that's
  a dot product</span> <span m='1529000'>operator. And this is what we're going to</span>
  <span m='1534000'>show is universal, that this set of h sub a,</span> <span m='1537000'>where
  I look over that whole set.</span> </p><p><span m='1539000'>So one of the things
  we need to know is how big is the set of</span> <span m='1544000'>hash functions
  here.</span> </p><p><span m='1559000'>So how big is this set of hash functions?</span>
  </p><p><span m='1561000'>How many different hash functions do I have in this set?</span>
  </p><p><span m='1584000'>It's basic 6.042 material. It's basically how many vectors</span>
  <span m='1591000'>of length r plus one where each element of the vector is a</span>
  <span m='1598000'>number of 0 to m minus one, has m different values.</span> </p><p><span
  m='1605000'>So how many? m minus one to the r.</span> </p><p><span m='1610000'>No.
  Close.</span> </p><p><span m='1611000'>It's up there. It's a big number.</span>
  </p><p><span m='1616000'>m to the r plus one. Good.</span> </p><p><span m='1621000'>It's
  m, so the size of H is equal to m to the r plus one.</span> </p><p><span m='1626000'>So
  we're going to want to remember that.</span> </p><p><span m='1630000'>OK, so let's
  just understand why that is.</span> </p><p><span m='1633000'>I have m choices for
  the first value of A.</span> </p><p><span m='1637000'>m for the second, etc.</span>
  </p><p><span m='1639000'>m for the r th. And since there are plus one</span> <span
  m='1643000'>things here, for each choice here, I have this many same</span> <span
  m='1648000'>number of choices here, so it's a product.</span> </p><p><span m='1654000'>OK,
  so this is the product rule in counting.</span> </p><p><span m='1659000'>So if you
  haven't reviewed your 6.042 notes for counting,</span> <span m='1665000'>this is
  going to be a good idea to go back and review that</span> <span m='1672000'>because
  we're doing stuff of that nature.</span> </p><p><span m='1677000'>This is just the
  product rule. Good.</span> </p><p><span m='1681000'>So then the theorem we want
  to prove is that H is universal.</span> </p><p><span m='1690000'>And this is going
  to involve a little bit of number theory,</span> <span m='1694000'>so it gets kind
  of interesting. And it's a non-trivial proof,</span> <span m='1699000'>so this is
  where if there's any questions as I'm going along,</span> <span m='1703000'>please
  ask because the argument is not as simple as other</span> <span m='1708000'>arguments
  we've seen so far. OK, not the ones we've seen so</span> <span m='1713000'>far have
  been simple, but this is definitely a more</span> <span m='1718000'>involved mathematical
  argument. So here's a proof.</span> </p><p><span m='1723000'>So let's let, so we
  have two keys.</span> </p><p><span m='1726000'>What are we trying to show if it's
  universal,</span> <span m='1730000'>that if I pick any two keys, the number of hash
  functions</span> <span m='1735000'>for which they hash to the same thing is the
  size of set of hash</span> <span m='1741000'>functions divided by m. OK, so I'm
  going to look at two</span> <span m='1748000'>keys. So let's pick two keys</span>
  <span m='1751000'>arbitrarily. So x, and we'll decompose it</span> <span m='1756000'>into
  our base r representation and y, y_0, y_1 --</span> <span m='1773000'>So these are
  two distinct keys. So if these are two distinct</span> <span m='1779000'>keys, so
  they're different, then this base representation</span> <span m='1785000'>has the
  property that they've got to differ somewhere.</span> </p><p><span m='1790000'>Right?
  OK, they differ in at least one</span> <span m='1794000'>digit.</span> </p><p><span
  m='1808000'>OK, and this is where most people get lost because I'm</span> <span
  m='1812000'>going to make a simplification. They could differ in any one of</span>
  <span m='1816000'>these digits. I'm going to say they differ in</span> <span m='1820000'>position
  0 because it doesn't matter which one I do,</span> <span m='1824000'>the math is
  the same, but it'll make it so that if I</span> <span m='1828000'>pick some said
  they differ in some position i,</span> <span m='1831000'>I would have to be taking
  summations as you'll see over</span> <span m='1835000'>the elements that are not
  i, and that's complicated.</span> </p><p><span m='1841000'>If I do it in position
  0, then I can just sum for the</span> <span m='1844000'>rest of them. So the math
  is going to be</span> <span m='1846000'>identical if I were to do it for any position
  because it's</span> <span m='1850000'>symmetric. All the digits are symmetric.</span>
  </p><p><span m='1852000'>So let's say they differ in position 0, but the same</span>
  <span m='1856000'>argument is going to be true if they differed in some other</span>
  <span m='1859000'>position. So let's say,</span> <span m='1862000'>so we're saying
  without loss of generality.</span> </p><p><span m='1865000'>So that's without loss
  of generality.</span> </p><p><span m='1868000'>Position 0. Because all the positions
  are</span> <span m='1872000'>symmetric here. And so, now we need to ask the</span>
  <span m='1876000'>question for how many --</span> <span m='1884000'>-- hash functions
  in our universal, purportedly universal</span> <span m='1890000'>set do x and y
  collide?</span> </p><p><span m='1899000'>OK, we've got to count them up. So how
  often do they collide?</span> </p><p><span m='1902000'>This is where we're going
  to pull out some heavy duty number</span> <span m='1906000'>theory. So we must have,</span>
  <span m='1908000'>if they collide --</span> <span m='1916000'>-- that h sub a of
  x is equal to h sub a of y.</span> </p><p><span m='1923000'>That's what it means
  for them to collide.</span> </p><p><span m='1929000'>So that implies that the sum
  of i equal 0 to r of a sub i x sub</span> <span m='1940000'>i is equal to the sum
  of i equals 0 to r of a sub i y sub i</span> <span m='1950000'>mod m. Actually this
  is congruent mod</span> <span m='1955000'>m. So congruence for those people</span>
  <span m='1958000'>who haven't seen much number theory, is basically the way of</span>
  <span m='1963000'>essentially, rather than having to say mod everywhere in here</span>
  <span m='1968000'>and mod everywhere in here, we just at the end say OK,</span>
  <span m='1972000'>do a mod at the end. Everything is being done mod,</span> <span
  m='1976000'>module m. And then typically we use a</span> <span m='1979000'>congruence
  sign. OK, there's a more mathematical</span> <span m='1986000'>definition but this
  will work for us engineers.</span> </p><p><span m='1993000'>OK, so everybody with
  me so far?</span> </p><p><span m='1998000'>This is just applying the definition.</span>
  </p><p><span m='2003000'>So that implies that the sum of i equals 0 to r of a i
  x i minus</span> <span m='2012000'>y i is congruent to zeros mod m. OK, just threw
  it on the other</span> <span m='2021000'>side and applied the distributive law.</span>
  </p><p><span m='2025000'>Now what I'm going to do is pull out the 0-th position</span>
  <span m='2029000'>because that's the one that I care about.</span> </p><p><span
  m='2033000'>And this is where it saves me on the math, compared to if I</span> <span
  m='2038000'>didn't say that it was 0. I'd have to pull out x_i.</span> </p><p><span
  m='2043000'>It wouldn't matter, but it just would make the math</span> <span m='2045000'>a
  little bit cruftier</span> <span m='2063000'>OK, so now we've just pulled out one
  term.</span> </p><p><span m='2070000'>That implies that a_0 x_0 minus y_0 is congruent
  to minus --</span> <span m='2094000'>-- mod m. Now remember that when I have a</span>
  <span m='2098000'>minus number mod m, I just map it into whatever,</span> <span
  m='2102000'>into that range from 0 to m minus one.</span> </p><p><span m='2107000'>So
  for example, minus five mod seven is two.</span> </p><p><span m='2112000'>So if
  any of these things are negative, we simply translate</span> <span m='2119000'>them
  into by adding multiples of mbecause adding multiples of m</span> <span m='2127000'>doesn't
  affect the congruence.</span> </p><p><span m='2139000'>OK. And now for the next
  step,</span> <span m='2141000'>we need to use a number theory fact.</span> </p><p><span
  m='2144000'>So let's pull out our number theory --</span> <span m='2157000'>-- textbook
  and take a little digression</span> <span m='2170000'>So this comes from the theory
  of finite fields.</span> </p><p><span m='2174000'>So for people who are knowledgeable,</span>
  <span m='2177000'>that's where you're plugging your knowledge in.</span> </p><p><span
  m='2181000'>If you're not knowledgeable, this is a great area of math to</span>
  <span m='2186000'>learn about. So here's the fact.</span> </p><p><span m='2190000'>So
  let m be prime. Then for any z,</span> <span m='2194000'>little z element of z sub
  m, and z sub m is the integers mod</span> <span m='2201000'>m. So this is essentially
  numbers</span> <span m='2206000'>from 0 to m minus one with all the operations,</span>
  <span m='2211000'>times, minus, plus, etc., defined on that</span> <span m='2217000'>such
  that if you end up outside of the range of 0 to m minus</span> <span m='2224000'>one,
  you re-normalize by subtracting or adding multiples</span> <span m='2231000'>of
  m to get back within the range from 0 to m minus one.</span> </p><p><span m='2241000'>So
  it's the standard thing of just doing things module m.</span> </p><p><span m='2250000'>So
  for any z such that z is not congruent to 0,</span> <span m='2258000'>there exists
  a unique z inverse in z sub m, such that if I</span> <span m='2267000'>multiply
  z times the inverse, it produces something congruent</span> <span m='2277000'>to
  one mod m. So for any number it says,</span> <span m='2284000'>I can find another
  number that when multiplied by it gives me</span> <span m='2291000'>one. So let's
  just do an example for</span> <span m='2295000'>m equals seven. So here we have,</span>
  <span m='2298000'>we'll make a little table. So z is not equal to 0,</span> <span
  m='2304000'>so I just write down the other numbers.</span> </p><p><span m='2309000'>And
  let's figure out what z inverse is.</span> </p><p><span m='2315000'>So what's the
  inverse of one? What number when multiplied by</span> <span m='2321000'>one gives
  me one? One.</span> </p><p><span m='2323000'>Good. How about two?</span> </p><p><span
  m='2325000'>What number when I multiply it by two gives me one?</span> </p><p><span
  m='2331000'>Four. Because two times four is eight</span> <span m='2335000'>and eight
  is congruent to one mod seven.</span> </p><p><span m='2341000'>So I've re-normalized
  it. What about three?</span> </p><p><span m='2352000'>Five. Good.</span> </p><p><span
  m='2353000'>Five. Three times five is 15.</span> </p><p><span m='2356000'>That's
  congruent to one mod seven because 15 divided by</span> <span m='2362000'>seven
  is two remainder of one. So that's the key thing.</span> </p><p><span m='2368000'>What
  about four? Two.</span> </p><p><span m='2372000'>Five? Three. And six.</span> </p><p></p><p><span
  m='2383000'>Yeah. Six. Yeah, six it turns out. OK, six times six is 36.</span> </p><p><span
  m='2388000'>OK, mod seven. Basically subtract off the 35,</span> <span m='2392000'>gives
  m one. So people have observed some</span> <span m='2396000'>interesting facts that
  if one number's an inverse of another,</span> <span m='2402000'>then that other
  is an inverse of the one.</span> </p><p><span m='2408000'>So that's actually one
  of these things that you prove when you</span> <span m='2412000'>do group theory
  and field theory and so forth.</span> </p><p><span m='2416000'>There are all sorts
  of other great properties of this kind of</span> <span m='2421000'>math. But the
  main thing is,</span> <span m='2423000'>and this turns out not to be true if m is
  not a prime.</span> </p><p><span m='2427000'>So can somebody think of, imagine we're
  doing something</span> <span m='2431000'>mod 10. Can somebody think of a number</span>
  <span m='2436000'>that doesn't have an inverse mod 10?</span> </p><p><span m='2439000'>Yeah.
  Two.</span> </p><p><span m='2440000'>Another one is five. OK, it turns out the divisors</span>
  <span m='2445000'>in fact actually, more generally,</span> <span m='2449000'>something
  that is not relatively prime,</span> <span m='2453000'>meaning that it has no common
  factors, the GCD is not one</span> <span m='2458000'>between that number and the
  modulus.</span> </p><p><span m='2464000'>OK, those numbers do not have an inverse
  mod m.</span> </p><p><span m='2468000'>OK, but if it's prime, every number is relatively</span>
  <span m='2473000'>prime to the modulus. And that's the property that</span> <span
  m='2477000'>we're taking advantage of. So this is our fact and so,</span> <span
  m='2482000'>in this case what I'm after is I want to divide by x_0 minus</span>
  <span m='2488000'>y_0. That's what I want to do at</span> <span m='2491000'>this
  point. But I can't do that if x_0,</span> <span m='2494000'>first of all, if m isn't
  prime,</span> <span m='2496000'>I can't necessarily do that. I might be able to,</span>
  <span m='2500000'>but I can't necessarily. But if m is prime,</span> <span m='2503000'>I
  can definitely divide by x_0 minus y_0.</span> </p><p><span m='2506000'>I can find
  that inverse. And the other thing I have to</span> <span m='2509000'>do is make
  sure x_0 minus y_0 is not 0.</span> </p><p><span m='2512000'>OK, it would be 0 if
  these two were equal, but our supposition</span> <span m='2517000'>was they weren't
  equal. And once again,</span> <span m='2521000'>just bringing it back to the without
  loss of generality,</span> <span m='2525000'>if it were some other position that
  we were off,</span> <span m='2528000'>I would be doing exactly the same thing with
  that position.</span> </p><p><span m='2533000'>So now we're going to be able to
  divide.</span> </p><p><span m='2536000'>So we continue with our --</span> <span
  m='2544000'>-- continue with our proof. So since x_0 is not equal to</span> <span
  m='2553000'>y_0, there exists an inverse for x_0 minus y_0.</span> </p><p><span
  m='2562000'>And that implies, just continue on from over</span> <span m='2568000'>there,
  that a_0 is congruent therefore to minus the sum of i</span> <span m='2576000'>equal
  one to r of a_i, x_i minus y_i times x_0 minus</span> <span m='2584000'>y_0 inverse.
  So let's just go back to the</span> <span m='2590000'>beginning of our proof and
  see what we've derived.</span> </p><p><span m='2595000'>If we're saying we have
  two distinct keys,</span> <span m='2599000'>and we've picked all of these a_i randomly,</span>
  <span m='2604000'>and we're saying that these two distinct keys hash to the same</span>
  <span m='2610000'>place. If they hash to the same place,</span> <span m='2614000'>it
  says that a_0 essentially had to have a particular value</span> <span m='2621000'>as
  a function of the other a_i. Because in other words,</span> <span m='2627000'>once
  I've picked each of these a_i from one to r,</span> <span m='2631000'>if I did them
  in that order, for example,</span> <span m='2634000'>then I don't have a choice
  for how I pick a_0 to make it</span> <span m='2638000'>collide. Exactly one value
  allows it to</span> <span m='2640000'>collide, namely the value of a_0 given by
  this.</span> </p><p><span m='2645000'>If I picked a different value of a_0, they
  wouldn't collide.</span> </p><p><span m='2650000'>So let m write that down. Thus,
  while you think about it</span> <span m='2712000'>So for any choice of these a_i,
  there's exactly one of the</span> <span m='2718000'>impossible choices of a_0 that
  cause a collision.</span> </p><p><span m='2724000'>And for all the other choices
  I might make of a_0,</span> <span m='2729000'>there's n collision. So essentially
  I don't have,</span> <span m='2736000'>if they're going to collide, I've reduced
  essentially the</span> <span m='2742000'>number of degrees of freedom of my randomness
  by a factor of m.</span> </p><p><span m='2749000'>So if I count up the number of
  h_a's that cause x and y to</span> <span m='2755000'>collide, that's equal to, well,
  there's m choices,</span> <span m='2761000'>just using the product rule again.</span>
  </p><p><span m='2766000'>There's m choices for a_1 times m choices for a_2,</span>
  <span m='2773000'>up to m choices for a_r and then only one choice for a_0.</span>
  </p><p><span m='2781000'>So this is choices for a_1, a_2, a_r and only one choice</span>
  <span m='2788000'>for a_0 if they're going to collide.</span> </p><p><span m='2795000'>If
  they're not going to collide, I've got more choices</span> <span m='2800000'>for
  a_0. But if I want them to collide,</span> <span m='2803000'>there's only one value
  I can pick, namely this value.</span> </p><p><span m='2808000'>That's the only value
  for which I will pick.</span> </p><p><span m='2813000'>And that's equal to m to
  the r, which is just the size of H</span> <span m='2818000'>divided by m. And that
  completes the proof.</span> </p><p><span m='2831000'>So there are other universal
  constructions,</span> <span m='2834000'>but this is a particularly elegant one.</span>
  </p><p><span m='2838000'>So the point is that I have m plus one, sorry,</span> <span
  m='2842000'>r plus one degrees of freedom where each degree of freedom I</span>
  <span m='2847000'>have m choices. But if I want them to collide,</span> <span m='2853000'>once
  I've picked any of the, once I've picked r of those</span> <span m='2860000'>possible
  choices, the last one is forced if I</span> <span m='2865000'>want it to collide.
  So therefore,</span> <span m='2868000'>the set of functions for which it collides
  is only one in m.</span> </p><p><span m='2875000'>A very slick construction. Very
  slick.</span> </p><p><span m='2881000'>OK. Everybody with me here?</span> </p><p><span
  m='2883000'>Didn't lose too many people? Yeah, question.</span> </p><p><span m='2887000'>Well,
  part of it is, actually this is a quite common</span> <span m='2892000'>type of
  thing to be doing actually.</span> </p><p><span m='2895000'>If you take a class,
  so we have follow on classes in</span> <span m='2899000'>cryptography and so forth,
  and this kind of thing of</span> <span m='2904000'>taking dot products, modulo m
  and also Galois fields</span> <span m='2909000'>which are particularly simple finite
  fields and things like</span> <span m='2914000'>that, people play with these all
  the time.</span> </p><p><span m='2920000'>So Galois fields are like using exor's
  as your,</span> <span m='2923000'>same sort of thing as this except base two.</span>
  </p><p><span m='2926000'>And so there's a lot of study of this sort of thing.</span>
  </p><p><span m='2929000'>So people understand these kind of properties.</span> </p><p><span
  m='2933000'>But yeah, it's like what's the algorithm for having a brilliant</span>
  <span m='2937000'>insight into algorithms? It's like OK.</span> </p><p><span m='2941000'>Wish
  I knew. Then I'd just turn the crank.</span> </p><p><span m='2945000'>[LAUGHTER]
  But if it were that easy, I wouldn't be standing up</span> <span m='2951000'>here
  today. [LAUGHTER] Good.</span> </p><p><span m='2953000'>OK, so now I want to take
  on another topic which is also I</span> <span m='2959000'>find, I think this is
  astounding.</span> </p><p><span m='2962000'>It's just beautiful, beautiful mathematics
  and a big</span> <span m='2967000'>impact on your ability to build good hash functions.</span>
  </p><p><span m='2974000'>Now I want to talk about another one topic,</span> <span
  m='2977000'>which is related, which is the topic of perfect</span> <span m='2981000'>hashing.</span>
  </p><p><span m='2994000'>So everything we've done so far does expected time performance.</span>
  </p><p><span m='2999000'>Hashing is good in the expected sense.</span> </p><p><span
  m='3003000'>A perfect hashing addresses the following questions.</span> </p><p><span
  m='3008000'>Suppose that I gave you a set of keys, and I said just build</span>
  <span m='3014000'>me a static table so I can look up whether the key is in the</span>
  <span m='3020000'>table with worst case time. Good worst case time.</span> </p><p><span
  m='3025000'>So I have a fixed set of keys. They might be something like</span> <span
  m='3031000'>for example, the hundred most common or thousand most common</span>
  <span m='3037000'>words in English. And when I get a word I want to</span> <span
  m='3042000'>check quickly in this table, is the word that I've got one</span> <span
  m='3047000'>of the most common words in English.</span> </p><p><span m='3049000'>I
  would like to do that not with expected performance,</span> <span m='3054000'>but
  guaranteed worst case performance.</span> </p><p><span m='3057000'>Is there a way
  of building it so that I can find this quickly?</span> </p><p><span m='3063000'>So
  the problem is given n keys --</span> <span m='3072000'>-- construct a static hash
  table.</span> </p><p><span m='3074000'>In other words, no insertion and deletion.</span>
  </p><p><span m='3077000'>We're just going to put the elements in there.</span> </p><p><span
  m='3080000'>A size --</span> <span m='3090000'>-- m equal Order n. So I don't want
  it to be a huge</span> <span m='3097000'>table. I want it to be a table that is</span>
  <span m='3102000'>the size of my keys. Table of size m equals Order n,</span> <span
  m='3110000'>such that search takes O(1) time in the worst case.</span> </p><p><span
  m='3126000'>So there's no place in the table where I'm going to have,</span> <span
  m='3130000'>I know in the average case, that's not hard to do.</span> </p><p><span
  m='3134000'>But in the worst case, I want to make sure that</span> <span m='3138000'>there's
  no particular spot where the number of keys piles up to</span> <span m='3142000'>be
  a large number. OK, in no spot should that</span> <span m='3146000'>happen. Every
  single search I do should</span> <span m='3149000'>take Order one time. There shouldn't
  be any</span> <span m='3153000'>statistical variation in terms of how long it takes
  me to get</span> <span m='3157000'>something. Does everybody understand what</span>
  <span m='3159000'>the puzzle is? So this is a great,</span> <span m='3162000'>because
  this actually ends up having a lot of uses.</span> </p><p><span m='3165000'>You
  know, you want to build a table for something and you know</span> <span m='3169000'>what
  the values are that you're going look up in it.</span> </p><p><span m='3172000'>But
  you don't want to spend a lot of space on it and so forth.</span> </p><p><span m='3176000'>So
  the idea here is actually going to be to use a two-level</span> <span m='3180000'>scheme.</span>
  </p><p><span m='3189000'>So the idea is we're going to use a two-level scheme with</span>
  <span m='3202000'>universal hashing at both levels.</span> </p><p><span m='3211000'>So
  the idea is we're going to hash, we're going to have a hash</span> <span m='3216000'>table,
  we're going to hash into slots, but rather than using</span> <span m='3221000'>chaining,
  we're going to have another hash table there.</span> </p><p><span m='3226000'>We're
  going to do a second hash into the second hash table.</span> </p><p><span m='3231000'>And
  the idea is that we're going to do it in such a way</span> <span m='3236000'>that
  we have no collisions at level two.</span> </p><p><span m='3241000'>So we may have
  collisions at level one.</span> </p><p><span m='3243000'>We'll take anything that
  collides at level one and put</span> <span m='3248000'>them into a hash table and
  then our second level hash table,</span> <span m='3252000'>but that hash table,
  no collisions.</span> </p><p><span m='3255000'>Boom. We're just going to hash right</span>
  <span m='3257000'>in there. And it'll just go boom to its</span> <span m='3260000'>thing.
  So let's draw a picture of this</span> <span m='3263000'>to illustrate the scheme.
  OK, so we have --</span> <span m='3274000'>-- 0 one, let's say six, m minus one.</span>
  </p><p><span m='3277000'>So here's our hash table. And what we're going to do is</span>
  <span m='3282000'>we're going to use universal hashing at the first level,</span>
  <span m='3287000'>OK. So we find a universal hash</span> <span m='3289000'>function.
  We pick a hash function at</span> <span m='3292000'>random. And what we'll do is
  we'll hash</span> <span m='3296000'>into that level. And then what we'll do is we'll</span>
  <span m='3300000'>keep track of two things. One is what the size of the</span> <span
  m='3305000'>hash table is at the next level. So in this case,</span> <span m='3309000'>the
  size of the hash table will only use the number of slots.</span> </p><p><span m='3313000'>There's
  going to be four. And we're also going to keep a</span> <span m='3317000'>separate
  hash key for the second level.</span> </p><p><span m='3319000'>So each slot will
  have its own hash function for the second</span> <span m='3323000'>level. So for
  example,</span> <span m='3325000'>this one might have a key of 31 that is a random
  number.</span> </p><p><span m='3330000'>The a's here. a's up there.</span> </p><p><span
  m='3332000'>There we go, a's up there.</span> </p><p><span m='3334000'>So that's
  going to be the basis of my hash function,</span> <span m='3339000'>the key with
  which I'm going to hash.</span> </p><p><span m='3342000'>This one say has 86. And
  let's say that this,</span> <span m='3346000'>and then we have a pointer to the
  hash table.</span> </p><p><span m='3350000'>This is say S_1. And it's got four slots
  and we</span> <span m='3355000'>stored up 14 and 27. And these two slots are empty.</span>
  </p><p><span m='3361000'>And this one for example, had what?</span> </p><p><span
  m='3369000'>Two nines.</span> </p><p><span m='3388000'>So the idea here is that
  in this case if we look over all</span> <span m='3394000'>our top level hash function,
  which I'll just call H,</span> <span m='3400000'>has that H of 14 is equal to H
  of 27 is equal to one.</span> </p><p><span m='3407000'>Because we're in slot one.
  OK, so these two both hash to</span> <span m='3413000'>the same slot in the level
  one hash table.</span> </p><p><span m='3417000'>This is level one. And this is level
  two over</span> <span m='3422000'>here. So level one hashing,</span> <span m='3426000'>14
  and 27 collided. They went into the same slot</span> <span m='3431000'>here. But
  at level two,</span> <span m='3433000'>they got hashed to different places and the
  hash function I</span> <span m='3440000'>use is going to be indexed by whatever
  the random numbers are</span> <span m='3446000'>that I chose and found for those
  and I'll show you how we find</span> <span m='3453000'>those. We have then h of
  31 of 14 is</span> <span m='3456000'>equal to one h of 31 of 27 is equal to two.</span>
  </p><p><span m='3463000'>For level two. So I go, hash in here,</span> <span m='3466000'>find
  the, use this as the basis of my hash function to hash into</span> <span m='3471000'>whatever
  table I've got here. And so, if there are no,</span> <span m='3475000'>if I can
  guarantee that there are no collisions at level two,</span> <span m='3480000'>this
  is going to cost me Order one time in the worst case to</span> <span m='3485000'>look
  something up. How do I look it up?</span> </p><p><span m='3489000'>Take the value.
  I apply h to it.</span> </p><p><span m='3492000'>That takes me to some slot. Then
  I look to see what the key</span> <span m='3496000'>is for this hash function. I
  apply that hash function and</span> <span m='3501000'>that takes me to another slot.
  Then I go there.</span> </p><p><span m='3504000'>And that took me basically two
  applications of hash functions</span> <span m='3509000'>plus some look-up, plus
  who knows what minor</span> <span m='3513000'>amount of bookkeeping. So the reason
  we're going to</span> <span m='3521000'>have no collisions at this level is the
  following.</span> </p><p><span m='3530000'>If they're n sub i items that hash to
  a level one slot i,</span> <span m='3541000'>then we're going to use m sub i, which
  is equal to n sub i</span> <span m='3551000'>squared slots in the level two hash
  table.</span> </p><p><span m='3569000'>OK, so I should have mentioned here this
  is going to be m sub</span> <span m='3573000'>i, the size of the hash table and
  this is going to be my a sub</span> <span m='3577000'>i essentially.</span> </p><p><span
  m='3585000'>So I'm going to use, so basically I'm going to hash</span> <span m='3590000'>n
  sub i things into n sub i squared locations here.</span> </p><p><span m='3595000'>So
  this is going to be incredibly sparse.</span> </p><p><span m='3600000'>OK, it's
  going to be quadratic in size.</span> </p><p><span m='3602480'>And so what I'm going
  to show is that under those</span> <span m='3605612'>circumstances, it's easy for
  me to find hash</span> <span m='3608418'>functions such that there are n collisions.</span>
  </p><p><span m='3611159'>That's the name of the game. Figure out how can I make
  these</span> <span m='3615010'>hash functions so that there are no collisions.</span>
  </p><p><span m='3618012'>So that's why I draw this with so few elements here.</span>
  </p><p><span m='3621341'>So here for example, I have two elements and I have</span>
  <span m='3624604'>a hash table size four here. I have three elements.</span> </p><p><span
  m='3627867'>I need a hash table size nine. OK, if there are a hundred</span> <span
  m='3632520'>elements, I need a hash table size 10,000.</span> </p><p><span m='3634918'>I'm
  not going to pick something so there's likely that there's</span> <span m='3638485'>anything
  of that size. And then the fact that this</span> <span m='3641350'>actually works
  and gives us all the properties that we want,</span> <span m='3644801'>that's part
  of the analysis. So does everybody see that this</span> <span m='3648251'>takes
  Order one worst case time and what the basic structure of</span> <span m='3651877'>it
  is? These things,</span> <span m='3652988'>by the way, are not in this case prime.</span>
  </p><p><span m='3655210'>I could always pick primes that were close to this.</span>
  </p><p><span m='3658134'>I didn't do that in this case. Or I could use a universal
  hash</span> <span m='3663730'>function that in fact would work for things other
  than primes.</span> </p><p><span m='3669103'>But I didn't do that for this example.</span>
  </p><p><span m='3672362'>We all ready for analysis? OK, let's do some analysis</span>
  <span m='3676943'>then.</span> </p><p><span m='3689000'>And this is really pretty
  analysis.</span> </p><p><span m='3691000'>Partly as you'll see because we've already
  done some of this</span> <span m='3693528'>analysis.</span> </p><p><span m='3710000'>So
  the trick is analyzing level two.</span> </p><p><span m='3713238'>That's the main
  thing that I want to analyze,</span> <span m='3717309'>to show that I can find hash
  functions here that are going</span> <span m='3722583'>to, when I map them into,
  very sparsely,</span> <span m='3726192'>into these arrays here, that in fact,</span>
  <span m='3729523'>such hash functions exist and I can compute them in advance.</span>
  </p><p><span m='3736000'>So that I have a good way of storing those.</span> </p><p><span
  m='3743344'>So here's the theorem we're going to use.</span> </p><p><span m='3750338'>My
  hash and keys into m equals n squared slots using a random</span> <span m='3760830'>hash
  function in a universal set H.</span> </p><p><span m='3768000'>Then the expected
  number of collisions is less than one</span> <span m='3780393'>half. OK.</span>
  </p><p><span m='3782502'>The expected number of collisions I don't expect there</span>
  <span m='3791372'>to be even one collision. I expect there to be less than</span>
  <span m='3800577'>half a collision on average. And so, let's prove this,</span>
  <span m='3809447'>so that the probability that two given keys collide under h</span>
  <span m='3819154'>is what? What's the probability that two</span> <span m='3825216'>given
  keys collide under h when h is chosen randomly from the</span> <span m='3831443'>universal
  set? One over m.</span> </p><p><span m='3834037'>Right? That's the definition,</span>
  <span m='3836943'>right, of, which is in this case equal to one over n</span> <span
  m='3842235'>squared. So now how many keys,</span> <span m='3846210'>how many pairs
  of keys do I have in this table?</span> </p><p><span m='3851052'>How many keys could
  possibly collide with each other?</span> </p><p><span m='3856526'>OK. So that's
  basically just</span> <span m='3859368'>looking at how many different pairs of keys
  do I have to</span> <span m='3865157'>evaluate this for. So that's n choose two
  pairs of</span> <span m='3870315'>keys. n choose two pairs of keys.</span> </p><p><span
  m='3876654'>So therefore, the expected number of</span> <span m='3882689'>collisions
  is while for each of these n, not n over two.</span> </p><p><span m='3892172'>n
  choose two pairs of keys. The probability that it</span> <span m='3900793'>collides
  is one in n squared. So that's equal to n times n</span> <span m='3908923'>minus
  one over two, if you remember your formula,</span> <span m='3912221'>times one in
  n squared. And that's less than a half.</span> </p><p><span m='3924000'>So for every
  pair of keys, so those of you who remember</span> <span m='3928183'>from 6.042 the
  birthday paradox, this is related to the birthday</span> <span m='3933063'>paradox
  a little bit. But here I basically have a</span> <span m='3936800'>large set, and
  I'm looking at all pairs, but my set is</span> <span m='3940333'>sufficiently big
  that the odds that I get a collision is</span> <span m='3944000'>relatively small.
  If I start increasing it beyond</span> <span m='3947199'>the square root of m, OK,
  the number of elements,</span> <span m='3950400'>it starts getting bigger in the
  square root of m then the odds</span> <span m='3954466'>of a collision go up dramatically
  as you know from</span> <span m='3957733'>the birthday paradox. But if I'm less
  than,</span> <span m='3961532'>if I'm really sparse in there, I don't get collisions.</span>
  </p><p><span m='3965401'>Or at least I get a relatively small number expected.</span>
  </p><p><span m='3969197'>Now I want to remind you of something which actually in
  the</span> <span m='3973430'>past I have just assumed, but I want to actually go</span>
  <span m='3977080'>through it briefly. It's Markov's inequality.</span> </p><p><span
  m='3980291'>So who remembers Markov's inequality?</span> </p><p><span m='3982919'>Don't
  everybody raise their hand at once.</span> </p><p><span m='3985839'>So Markov's
  inequality says the following.</span> </p><p><span m='3990000'>This is one of these
  great probability facts.</span> </p><p><span m='3994145'>For random variable x which
  is bounded below by 0,</span> <span m='3998762'>says the probability that x is bigger
  than, greater than or</span> <span m='4004227'>equal to any given value T is less
  than or equal to the</span> <span m='4009316'>expectation of x divided by T. It's
  a great fact.</span> </p><p><span m='4013838'>Doesn't happen if x isn't bound below
  by 0.</span> </p><p><span m='4017796'>But it's a great fact. It allows me to relate
  the</span> <span m='4023230'>probability of an event to its expectation.</span>
  </p><p><span m='4026833'>And the idea is in general that if the expectation is going
  to</span> <span m='4032066'>be small, then I can't have a high probability that
  the value</span> <span m='4037213'>of the random variable is large. It doesn't make
  sense.</span> </p><p><span m='4041845'>How could you have a high probability that
  it's a million</span> <span m='4046649'>when my expectation is one or in this case
  we're going to apply</span> <span m='4051968'>it when the expectation is a half?</span>
  </p><p><span m='4056000'>Couldn't happen. And the proof follows just</span> <span
  m='4059676'>directly on the definition of expectation, and so I'mdoing</span> <span
  m='4064666'>this for a discrete random variable.</span> </p><p><span m='4067730'>So
  the expectation by definition is just the sum from</span> <span m='4072282'>little
  x goes to 0 to infinity of x times the probability that</span> <span m='4077622'>my
  random variable takes on the value x.</span> </p><p><span m='4082000'>That's the
  definition. And now it's just a question of</span> <span m='4086560'>doing like
  the coarsest approximation you can imagine.</span> </p><p><span m='4091120'>First
  of all, let me just simply throw away</span> <span m='4094734'>all small terms that
  can be greater to or equal to x equals</span> <span m='4099725'>T to infinity of
  x times the probability that x is equal to</span> <span m='4104716'>little x. So
  just throw away all the low</span> <span m='4108072'>order terms. Now what I'm going
  to do is</span> <span m='4111426'>replace every one of these terms is lower bounded
  by the value x</span> <span m='4116848'>equals T. So that's just the summation of</span>
  <span m='4122875'>x equals T to infinity of T times the probability that x</span>
  <span m='4129750'>equals x. OK.</span> </p><p><span m='4131250'>Over x going from
  T larger. Because these are only bigger</span> <span m='4138250'>values. And that's
  just equal then to</span> <span m='4142009'>T, because I can pull that out, and
  the summation of x equals T</span> <span m='4146306'>to infinity of the probability
  that x equals x is just the</span> <span m='4150256'>probability that x is greater
  than or equal to T.</span> </p><p><span m='4160000'>And that's done because I just
  divide by T.</span> </p><p><span m='4171000'>So that's Markov's inequality. Really
  dumb.</span> </p><p><span m='4174379'>Really simple. There are much stronger things</span>
  <span m='4177919'>like Chebyshev bounds and Chernoff bounds and things of</span>
  <span m='4182264'>that nature. But Markov's is like</span> <span m='4184839'>unbelievably
  simple and useful. So we're going to just apply</span> <span m='4189586'>that as
  a corollary.</span> </p><p><span m='4206000'>So the probability now of no collisions,
  when I hash n keys</span> <span m='4213059'>into n squared slots using a universal
  hash function,</span> <span m='4219391'>I claim is the probability of no collisions
  is greater than or</span> <span m='4226817'>equal to a half. So I pick a hash function
  at</span> <span m='4232173'>random. What are the odds that I got no</span> <span
  m='4236409'>collisions when I hashed those n keys into n squared slots?</span> </p><p><span
  m='4240917'>Answer. Probability is I have no</span> <span m='4243326'>collisions
  is at least a half. Half the time I'm guaranteed</span> <span m='4247834'>that there
  won't be a collision. And the proof,</span> <span m='4251409'>pretty simple. The
  probability of no</span> <span m='4254129'>collisions is the same as the probability
  as,</span> <span m='4257549'>sorry, is one minus the probability that I have at
  most</span> <span m='4261746'>one collision. So the odds that I have at</span> <span
  m='4265850'>least one collision, the odds that I have at least</span> <span m='4269337'>one
  collision, probability greater than or</span> <span m='4272254'>equal to one collision
  is less than or equal to,</span> <span m='4275599'>now I just apply Markov's inequality
  with this.</span> </p><p><span m='4278872'>So it's just the expected number of collisions
  --</span> <span m='4289000'>-- divided by one. And that is by Markov's</span> <span
  m='4293090'>inequality less than, by definition,</span> <span m='4296272'>excuse
  me, of expected number of collisions,</span> <span m='4300181'>which we've already
  shown, is less than a half.</span> </p><p><span m='4304363'>So the probability of
  at least one collision is less than a</span> <span m='4309636'>half. The probability
  of 0 collisions</span> <span m='4312909'>is at least a half. So we're done here.</span>
  </p><p><span m='4316363'>So to find a good level to hash function is easy.</span>
  </p><p><span m='4322000'>I just test a few at random. Most of them out there,</span>
  <span m='4326562'>OK, half of them, at least half of them are going</span> <span
  m='4330856'>to work. So this is in some sense,</span> <span m='4333808'>if you think
  about it, a randomized construction,</span> <span m='4338102'>because I can't tell
  you which one it's going to be.</span> </p><p><span m='4342664'>It's non-constructive
  in that sense, but it's a randomized</span> <span m='4347763'>construction. But
  they have to exist because</span> <span m='4352485'>most of them out there have
  this good property.</span> </p><p><span m='4356297'>So I'mgoing to be able to find
  for each one of these,</span> <span m='4360605'>I just test a few at random, and
  I find one.</span> </p><p><span m='4364168'>Test a few at random, find one, etc.</span>
  </p><p><span m='4367068'>Fill in my table there. Because all that is</span> <span
  m='4370548'>pre-computation. And I'mgoing to find them</span> <span m='4373945'>because
  the odds are good that one exists.</span> </p><p><span m='4377342'>So --</span>
  <span m='4393000'>-- we just test a few at random.</span> </p><p><span m='4404000'>And
  we'll find one quickly --</span> <span m='4412000'>-- since at least half will work.</span>
  </p><p><span m='4414300'>I just want to show that there exists good ones.</span>
  </p><p><span m='4417679'>All I have to prove is that at least one works for each
  of</span> <span m='4421777'>these cases. In fact, I've shown that</span> <span m='4424366'>there's
  a huge number that will work.</span> </p><p><span m='4426954'>Half of them will
  work. But to show it exists,</span> <span m='4430189'>I would just have to show
  that the probability was greater than</span> <span m='4435941'>we need to still
  analyze the storage because I promised in my</span> <span m='4440254'>theorem that
  the table would be of size order n.</span> </p><p><span m='4445000'>And yet now
  I've said there's all of these quadratic-sized</span> <span m='4452702'>slots here.
  So I'mgoing to show that that's</span> <span m='4458378'>order n.</span> </p><p><span
  m='4471000'>So for level one, that's easy.</span> </p><p><span m='4475605'>We'll
  just choose the number of slots to be equal to the number</span> <span m='4485450'>of
  keys. And that way the storage at</span> <span m='4491008'>level one is just order
  n. And now let's let n sub i be</span> <span m='4499583'>the random variable for
  the number of keys --</span> <span m='4513000'>-- that hash to slot i in T. OK,
  so n sub i is just what</span> <span m='4521712'>we've called it. Number of elements
  that slot</span> <span m='4528683'>there. And we're going to use m sub i</span>
  <span m='4534386'>equals n sub i squared slots in each level two table S sub i.</span>
  </p><p><span m='4545000'>So the expected total storage --</span> <span m='4554000'>--
  is just n for level one, order n if you want,</span> <span m='4561085'>but basically
  n slots for level one plus the expected value,</span> <span m='4569979'>whatever
  I expect the sum of i equals 0 to m minus one of theta</span> <span m='4579326'>of
  n sub i squared to be.</span> </p><p><span m='4590000'>Because I basically have
  to add up the square for every element</span> <span m='4596048'>that applies here,
  the square of what's in there.</span> </p><p><span m='4600731'>Who recognizes this
  summation? Where have we seen that before?</span> </p><p><span m='4606682'>Who attends
  recitation? Where have we seen this before?</span> </p><p><span m='4611951'>What's
  the --</span> <span m='4623000'>We're summing the expected value of a bunch of --</span>
  <span m='4631000'>Yeah, what was that algorithm? We did the sorting algorithm,</span>
  <span m='4634959'>right? What was the sorting algorithm</span> <span m='4637375'>for
  which this was an important thing to evaluate?</span> </p><p><span m='4646000'>Don't
  everybody shout it out at once.</span> </p><p><span m='4649272'>What was that sorting
  algorithm called?</span> </p><p><span m='4653000'>Bucket sort. Good.</span> </p><p><span
  m='4655397'>Bucket sort. Yeah.</span> </p><p><span m='4657794'>We showed that the
  sum of the squares of random variables when</span> <span m='4666397'>they're falling
  randomly into n bins is order n.</span> </p><p><span m='4673025'>Right?</span> </p><p><span
  m='4696000'>And you can also out of this get a, as we did before,</span> <span m='4700105'>get
  a probability bound. What's the probability that</span> <span m='4704131'>it's more
  than a certain amount times n using Markov's</span> <span m='4708315'>inequality.
  But this is the key thing is</span> <span m='4711394'>we've seen this analysis.
  OK, we used it there in time,</span> <span m='4716109'>so there's a little bit,
  but that's one of the reasons</span> <span m='4719963'>we study sorting at the beginning
  of the term is because</span> <span m='4723963'>the techniques of sorting, they
  just propagate into all</span> <span m='4727890'>these other areas of analysis.
  You see a lot of the same kinds</span> <span m='4732327'>of things. And so now that
  you know bucket</span> <span m='4735309'>sort clearly so well, now you know that
  this without</span> <span m='4739018'>having to do any extra work. So you might
  want to go back</span> <span m='4744610'>and review your bucket sort analysis, because
  it's applied</span> <span m='4749925'>now. Same analysis.</span> </p><p><span m='4751604'>Two
  places. OK.</span> </p><p><span m='4752909'>Good recitation this Friday, which will
  be a quiz review and</span> <span m='4758411'>we have a quiz next, there's no class
  on Monday,</span> <span m='4762794'>but we have a quiz on next Wednesday.</span>
  </p><p><span m='4766151'>OK, so good luck everybody on the quiz.</span> </p><p><span
  m='4771000'>Make sure you get plenty of sleep.</span> </p>
type: course
uid: de9e94bd085415a2dd7fbc73512ae8b0

---
None