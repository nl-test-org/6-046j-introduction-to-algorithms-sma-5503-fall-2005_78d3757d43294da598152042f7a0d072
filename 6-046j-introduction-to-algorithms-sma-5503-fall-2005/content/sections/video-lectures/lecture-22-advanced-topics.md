---
about_this_resource_text: <p><strong>Topics covered:&nbsp;</strong>Advanced Topics</p>
  <p><strong>Instructors:&nbsp;</strong>Prof. Erik Demaine,&nbsp;Prof. Charles Leiserson</p>
course_id: 6-046j-introduction-to-algorithms-sma-5503-fall-2005
embedded_media:
- id: 6_046J2005L22.pdf
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-22-advanced-topics/6_046J2005L22.pdf
  title: 6_046J2005L22.pdf
  type: null
  uid: dd5db041b0184f75cab51dea74fd5d1d
- id: 6_046J_lec22_th.jpg
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-22-advanced-topics/6_046J_lec22_th.jpg
  title: 6_046J_lec22_th.jpg
  type: null
  uid: 8fccfff4468dd69544b304721ded74e1
- id: Video-YouTube-Stream
  media_location: PYvJmLKhM-Y
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-YouTube-Stream
  type: Video
  uid: b730099609d3db889392704ca98a4b81
- id: Thumbnail-YouTube-JPG
  media_location: https://img.youtube.com/vi/PYvJmLKhM-Y/default.jpg
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Thumbnail-YouTube-JPG
  type: Thumbnail
  uid: c6ca17b40d315d12842ce2b3d0a2b4fd
- id: Video-iTunesU-MP4
  media_location: https://itunes.apple.com/us/itunes-u/id341597754
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-iTunes U-MP4
  type: Video
  uid: 648f66512bc986a2572b8a0a89e5b794
- id: Video-InternetArchive-MP4
  media_location: http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-05dec2005-220k.mp4
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-Internet Archive-MP4
  type: Video
  uid: 4893bacadaba0dc3ee06927966b4a12c
- id: Video-iTunesU-MP3
  media_location: http://deimos3.apple.com/WebObjects/Core.woa/Browse/mit.edu.1298167185.01298167189.1302879706?i=1404599442
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-iTunes U-MP3
  type: Video
  uid: 59c9d34a995cbd0deceba72cd019aff5
- id: Video-InternetArchive-MP3
  media_location: http://www.archive.org/download/MIT6.046JF05/ocw-6.046-05dec2005.mp3
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-Internet Archive-MP3
  type: Video
  uid: b128760fba37badd2f2067db76b01e66
- id: Video-VideoLecturesnet-Stream
  media_location: http://videolectures.net/mit6046jf05_introduction_algorithms/
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Video-VideoLectures.net-Stream
  type: Video
  uid: 149a96b17fb20b252e4fdb66d68d1cfb
- id: Thumbnail-OCW-JPG
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Thumbnail-OCW-JPG
  type: Thumbnail
  uid: 1ce20aa2b333583e3511911d50c76038
- id: 3Play-3PlayYouTubeid-MP4
  media_location: PYvJmLKhM-Y
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: 3Play-3Play YouTube id
  type: 3Play
  uid: 14ec5dfb6c4735eda927f3f192f1ed57
- id: PYvJmLKhM-Y.srt
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-22-advanced-topics/PYvJmLKhM-Y.srt
  title: 3play caption file
  type: null
  uid: 85dbce5ffe4e76e4065b5aeca3ef74c2
- id: PYvJmLKhM-Y.pdf
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-22-advanced-topics/PYvJmLKhM-Y.pdf
  title: 3play pdf file
  type: null
  uid: 8b44bfc85aeab0268a2c9400cbe6633a
- id: Caption-3Play YouTube id-SRT
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Caption-3Play YouTube id-SRT-English - US
  type: Caption
  uid: 7bb6d4ffcb1cf8785d333298dcbc15b4
- id: Transcript-3Play YouTube id-PDF
  parent_uid: e9d8462200b474f0ee3d4dbd3a22ebe9
  title: Transcript-3Play YouTube id-PDF-English - US
  type: Transcript
  uid: 4fdc2faeb4474b65463cfe675279b6d1
inline_embed_id: 33914394lecture22:advancedtopics19967270
layout: video
order_index: null
parent_uid: c492612542f7cc7a09f73790a5f91d81
related_resources_text: <p><a target="_blank" href="./resolveuid/efc69ef86c18e164d675bd8808c6477a">Assignments</a><br
  />             <a target="_blank" href="./resolveuid/144d9e513546eac8c1fd9b0d278e6eb2">Exams</a></p>
short_url: lecture-22-advanced-topics
technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-22-advanced-topics
template_type: Tabbed
title: 'Lecture 22: Advanced Topics'
transcript: <p><span m='7000'>We only have four more lectures left, and what Professor
  Demaine</span> <span m='12000'>and I have decided to do is give two series of lectures
  on sort</span> <span m='18000'>of advanced topics. So, today at Wednesday we're</span>
  <span m='22000'>going to talk about parallel algorithms, algorithms where you</span>
  <span m='27000'>have more than one processor whacking away on your problem.</span>
  </p><p><span m='34000'>And this is a very hot topic right now because all of the</span>
  <span m='38000'>chip manufacturers are now producing so-called multicore</span>
  <span m='42000'>processors where you have more than one processor per chip.</span>
  </p><p><span m='47000'>So, knowing something about that is good.</span> </p><p><span
  m='50000'>The second topic we're going to cover is going to be caching,</span> <span
  m='55000'>and how you design algorithms for systems with cache.</span> </p><p><span
  m='60000'>Right now, we've sort of program to everything as if it</span> <span m='63000'>were
  just a single level of memory, and for some problems</span> <span m='67000'>that's
  not an entirely realistic model.</span> </p><p><span m='70000'>You'd like to have
  some model for how the caching hierarchy</span> <span m='74000'>works, and how you
  can take advantage of that.</span> </p><p><span m='78000'>And there's been a lot
  of research in that area as well.</span> </p><p><span m='82000'>So, both of those
  actually turn out to be my area of research.</span> </p><p><span m='86000'>So, this
  is actually fun for me.</span> </p><p><span m='90000'>Actually, most of it's fun
  anyway.</span> </p><p><span m='93000'>So, today we'll talk about parallel algorithms.</span>
  </p><p><span m='97000'>And the particular topic, it turns out that there are</span>
  <span m='103000'>lots of models for parallel algorithms, and for parallelism.</span>
  </p><p><span m='109000'>And it's one of the reasons that, whereas for serial</span>
  <span m='114000'>algorithms, most people sort of have this basic model that we've</span>
  <span m='120000'>been using. It's sometimes called a random</span> <span m='124000'>access
  machine model, which is what we've been using</span> <span m='128000'>to analyze
  things, whereas in the parallel space,</span> <span m='131000'>there's just a huge
  number of models, and there is no general</span> <span m='135000'>agreement on what
  is the best model because there are</span> <span m='139000'>different machines that
  are made with different configurations,</span> <span m='143000'>etc. and people
  haven't,</span> <span m='144000'>sort of, agreed on, even how parallel machines</span>
  <span m='147000'>should be organized. So, we're going to deal with a</span> <span
  m='152000'>particular model, which goes under the rubric of</span> <span m='157000'>dynamic
  multithreading, which is appropriate for the</span> <span m='162000'>multicore machines
  that are now being built for shared memory</span> <span m='168000'>programming.
  It's not appropriate for what's</span> <span m='172000'>called distributed memory
  programs particularly because</span> <span m='177000'>the processors are able to
  access things.</span> </p><p><span m='183000'>And for those, you need more involved
  models.</span> </p><p><span m='186000'>And so, let me start just by giving an example
  of how one</span> <span m='190000'>would write something. I'm going to give you
  a program</span> <span m='194000'>for calculating the nth Fibonacci number in this
  model.</span> </p><p><span m='198000'>This is actually a really bad algorithm that
  I'm going to give</span> <span m='203000'>you because it's going to be the exponential
  time algorithm,</span> <span m='208000'>whereas we know from week one or two that
  you can calculate</span> <span m='212000'>the nth Fibonacci number and how much
  time?</span> </p><p><span m='217000'>Log n time. So, this is too exponentials</span>
  <span m='220000'>off what you should be able to get, OK, two exponentials off.</span>
  </p><p><span m='226000'>OK, so here's the code.</span> </p><p><span m='276000'>OK,
  so this is essentially the pseudocode we would write.</span> </p><p><span m='280000'>And
  let me just explain a little bit about,</span> <span m='284000'>we have a couple
  of key words here we haven't seen before:</span> <span m='288000'>in particular,
  spawn and sync.</span> </p><p><span m='292000'>OK, so spawn, this basically says
  that the</span> <span m='298000'>subroutine that you're calling, you use it as a
  keyword before</span> <span m='307000'>a subroutine, that it can execute at the
  same</span> <span m='314000'>time as its parent. So, here, what we say x equals</span>
  <span m='321000'>spawn of n minus one, we immediately go onto the next</span> <span
  m='329000'>statement. And now, while we're executing</span> <span m='336000'>fib
  of n minus one, we can also be executing,</span> <span m='342000'>now, this statement
  which itself will spawn something off.</span> </p><p><span m='349000'>OK, and we
  continue, and then we hit the sync</span> <span m='354000'>statement. And, what
  sync says is,</span> <span m='358000'>wait until all children are done.</span> </p><p><span
  m='364000'>OK, so it says once you get to this point, you've got to wait</span>
  <span m='369000'>until everything here has completed before you execute the</span>
  <span m='375000'>x plus y because otherwise you're going to try to execute</span>
  <span m='381000'>the calculation of x plus y without having computed it yet.</span>
  </p><p><span m='386000'>OK, so that's the basic structure.</span> </p><p><span m='391000'>What
  this describes, notice in here we never said</span> <span m='393000'>how many processors
  or anything we are running on.</span> </p><p><span m='396000'>OK, so this actually
  is just describing logical parallelism</span> <span m='400000'>--</span> <span m='411000'>--
  not the actual parallelism when we execute it.</span> </p><p><span m='422000'>And
  so, what we need is a scheduler, OK,</span> <span m='431000'>to determine how to
  map this dynamically, unfolding execution</span> <span m='445000'>onto whatever
  processors you have available.</span> </p><p><span m='457000'>OK, and so, today
  actually we're going to talk mostly about</span> <span m='465000'>scheduling. OK,
  and then,</span> <span m='468000'>next time we're going to talk about specific application</span>
  <span m='476000'>algorithms, and how you analyze them.</span> </p><p><span m='481000'>OK,
  so you can view the actual multithreaded computation.</span> </p><p><span m='491000'>If
  you take a look at the parallel instruction stream,</span> <span m='496000'>it's
  just a directed acyclic graph, OK?</span> </p><p><span m='501000'>So, let me show
  you how that works.</span> </p><p><span m='505000'>So, normally when we have an
  instruction stream,</span> <span m='510000'>I look at each instruction being executed.</span>
  </p><p><span m='516000'>If I'm in a loop, I'm not looking at it as a</span> <span
  m='518000'>loop. I'm just looking at the</span> <span m='520000'>sequence of instructions
  that actually executed.</span> </p><p><span m='522000'>I can do that just as a chain.
  Before I execute one</span> <span m='525000'>instruction, I have to execute the
  one before it.</span> </p><p><span m='528000'>Before I execute that, I've got to
  execute the one</span> <span m='531000'>before it. At least, that's the</span> <span
  m='533000'>abstraction. If you've studied processors,</span> <span m='535000'>you
  know that there are a lot of tricks there in figuring out</span> <span m='538000'>instruction
  level parallelism, and how you can actually make</span> <span m='542000'>that serial
  instruction stream actually execute in parallel.</span> </p><p><span m='547000'>But
  what we are going to be mostly talking about is the</span> <span m='555000'>logical
  parallelism here, and what we can do in that</span> <span m='562000'>context. So,
  in this DAG,</span> <span m='566000'>the vertices are threads, which are maximal
  sequences of</span> <span m='574000'>instructions not containing --</span> <span
  m='587000'>-- parallel control. And by parallel control,</span> <span m='592000'>I
  just mean spawn, sync, and return from a spawned</span> <span m='598000'>procedure.
  So, let's just mark the,</span> <span m='602000'>so the vertices are threads. So,
  let's just mark what the</span> <span m='606000'>vertices are here, OK, what the
  threads are here.</span> </p><p><span m='610000'>So, when we enter the function
  here, we basically execute up to</span> <span m='616000'>the point where, basically,
  here,</span> <span m='618000'>let's call that thread A where we are just doing a
  sequential</span> <span m='624000'>execution up to either returning or starting
  to do the spawn,</span> <span m='629000'>fib of n minus one. So actually,</span>
  <span m='633000'>thread A would include the calculation of n minus one right</span>
  <span m='638000'>up to the point where you actually make the subroutine</span> <span
  m='643000'>jump. That's thread A.</span> </p><p><span m='645000'>Thread B would
  be the stuff that you would do,</span> <span m='649000'>executing from fib of, sorry,
  B would be from the,</span> <span m='654000'>right. We'd go up to the spawn.</span>
  </p><p><span m='657000'>So, we've done the spawn. I'm really looking at this.</span>
  </p><p><span m='663000'>So, B would be up to the spawn of y.</span> </p><p><span
  m='665000'>OK, spawn of fib of n minus two to compute y,</span> <span m='669000'>and
  then we'd have essentially an empty thread.</span> </p><p><span m='672000'>So, I'll
  ignore that for now, but really then we have after</span> <span m='677000'>the sync
  up to the point that we get to the return of x plus y.</span> </p><p><span m='682000'>So
  basically, we're just looking at maximal</span> <span m='685000'>sequences of instructions
  that are all serial.</span> </p><p><span m='690000'>And every time I do a parallel
  instruction, OK,</span> <span m='694000'>spawn or a sync, or return from it,</span>
  <span m='697000'>that terminates the current thread.</span> </p><p><span m='700000'>OK,
  so we can look at that as a bunch of small threads.</span> </p><p><span m='705000'>So
  those of you who are familiar with threads from Java</span> <span m='710000'>threads,
  or POSIX threads, OK, so-called P threads,</span> <span m='714000'>those are sort
  of heavyweight static threads.</span> </p><p><span m='720000'>This is a much lighter
  weight notion of thread,</span> <span m='724000'>OK, that we are using in this model.</span>
  </p><p><span m='728000'>OK, so these are the vertices. And now, let me map out a</span>
  <span m='733000'>little bit how this works, so we can where the edges come</span>
  <span m='739000'>from. So, let's imagine we're</span> <span m='741000'>executing
  fib of four. So, I'm going to draw a</span> <span m='746000'>horizontal oval. That's
  going to correspond to</span> <span m='751000'>the procedure execution. And, in
  this procedure,</span> <span m='756000'>there are essentially three threads.</span>
  </p><p><span m='759000'>We start out with A, so this is our initial thread</span>
  <span m='764000'>is this guy here. And then, when he executes a</span> <span m='769000'>spawn,
  OK, he's going to execute a spawn, we are going to create</span> <span m='775000'>a
  new procedure, and he's going to execute a new</span> <span m='780000'>A recursively
  within that procedure.</span> </p><p><span m='785000'>But at the same time, we're
  also going to be,</span> <span m='789000'>now, aloud to go on and execute B in the
  parent,</span> <span m='794000'>we have parallelism here when I do a spawn.</span>
  </p><p><span m='798000'>OK, and so there's an edge here.</span> </p><p><span m='801000'>This
  edge we are going to call a spawn edge,</span> <span m='805000'>and this is called
  a continuation edge because it's</span> <span m='811000'>just simply continuing
  the procedure execution.</span> </p><p><span m='817000'>OK, now at this point, this
  guy, we now have two</span> <span m='821000'>things that can execute at the same
  time.</span> </p><p><span m='825000'>Once I've executed A, I now have two things
  that can</span> <span m='829000'>execute. OK, so this one,</span> <span m='832000'>for
  example, may spawn another thread here.</span> </p><p><span m='836000'>Oh, so this
  is fib of three, right?</span> </p><p><span m='839000'>And this is now fib of two.
  OK, so he spawns another guy</span> <span m='847000'>here, and simultaneously, he
  can go on and execute B</span> <span m='855000'>here, OK, with a continued edge.
  And B, in fact,</span> <span m='862000'>can also spawn at this point. OK, and this
  is now fib of two</span> <span m='872000'>also. And now, at this point,</span> <span
  m='876000'>we can't execute C yet here even though I've spawned things</span> <span
  m='884000'>off. And the reason is because C</span> <span m='888000'>won't execute
  until we've executed the sync statement,</span> <span m='894000'>which can't occur
  until A and B have both been executed,</span> <span m='901000'>OK? So, he just sort
  of sits there</span> <span m='906000'>waiting, OK, and a scheduler can't try to
  schedule him.</span> </p><p><span m='912000'>Or if he does, then nothing's going
  to happen</span> <span m='918000'>here, OK? So, we can go on.</span> </p><p><span
  m='921000'>Let's see, here we could call fib of one.</span> </p><p><span m='925000'>The
  fib of one is only going to execute an A statement here.</span> </p><p><span m='934000'>OK,
  of course it can't continue here because A is the only</span> <span m='939000'>thing,
  when I execute fib of one, if we look at the code,</span> <span m='945000'>it never
  executes B or C. OK, and similarly here,</span> <span m='950000'>this guy here to
  do fib of one. OK, and this guy,</span> <span m='955000'>I guess, could execute
  A here of fib of one.</span> </p><p><span m='970000'>OK, and maybe now this guy
  calls his another fib of one,</span> <span m='977000'>and this guy does another
  one. This is going to be fib of</span> <span m='985000'>zero, right? I keep drawing
  that arrow to</span> <span m='991000'>the wrong place, OK?</span> </p><p><span m='995000'>And
  now, once these guys return, well,</span> <span m='998000'>let's say these guys
  return here, I can now execute C.</span> </p><p><span m='1002000'>But I can't execute
  with them until both of these guys are</span> <span m='1007000'>done, and that guy
  is done. So, you see that we get a</span> <span m='1012000'>synchronization point
  here before executing C.</span> </p><p><span m='1016000'>And then, similarly here,
  now that we've executed this</span> <span m='1021000'>and this, we can now execute
  this guy here.</span> </p><p><span m='1026000'>And so, those returns go to there.</span>
  </p><p><span m='1031000'>Likewise here, this guy can now execute his C,</span> <span
  m='1037000'>and now once both of those are done, we can execute this guy</span>
  <span m='1046000'>here. And then we are done.</span> </p><p><span m='1050000'>This
  is our final thread. So, I should have labeled also</span> <span m='1061000'>that
  when I get one of these guys here, that's a return edge.</span> </p><p><span m='1073000'>So,
  the three types of edges are spawn, return,</span> <span m='1081000'>and continuation.
  OK, and by describing it in</span> <span m='1088000'>this way, I essentially get
  a DAG that unfolds.</span> </p><p><span m='1091000'>So, rather than having just
  a serial execution trace,</span> <span m='1095000'>I get something where I have
  still some serial dependencies.</span> </p><p><span m='1099000'>There are still
  some things that have to be done before</span> <span m='1103000'>other things, but
  there are also things that</span> <span m='1107000'>can be done at the same time.
  So how are we doing?</span> </p><p><span m='1111000'>Yeah, question? Is every spawn
  were covered by</span> <span m='1115000'>a sync, effectively, yeah, yeah, effectively.</span>
  </p><p><span m='1118000'>There's actually a null thread that gets executed in there,</span>
  <span m='1123000'>which I hadn't bothered to show.</span> </p><p><span m='1125000'>But
  yes, basically you would then not have any parallelism,</span> <span m='1130000'>OK,
  because you would spawn it off, but then you're not doing</span> <span m='1134000'>anything
  in the parent. So it's pretty much the same,</span> <span m='1138000'>yeah, as if
  it had executed serially.</span> </p><p><span m='1143000'>Yep, OK, so you can see
  that basically what we had here in</span> <span m='1146000'>some sense is a DAG
  embedded in a tree.</span> </p><p><span m='1149000'>OK, so you have a tree that's
  sort of the procedure structure,</span> <span m='1153000'>but in their you have
  a DAG, and that DAG can actually get</span> <span m='1156000'>to be pretty complicated.
  OK, now what I want to do is</span> <span m='1160000'>now that we understand that
  we've got an underlying DAG,</span> <span m='1163000'>I want to switch to trying
  to study the performance attributes</span> <span m='1167000'>of a particular DAG
  execution, so looking at performance</span> <span m='1171000'>measures.</span> </p><p><span
  m='1185000'>So, the notation that we'll use is we'll let T_P be the running</span>
  <span m='1195000'>time of whatever our computation is on P processors.</span> </p><p><span
  m='1205000'>OK, so, T_P is, how long does it take to</span> <span m='1207000'>execute
  this on P processors? Now, in general,</span> <span m='1210000'>this is not going
  to be just a particular number,</span> <span m='1213000'>OK, because I can have
  different scheduling disciplines</span> <span m='1217000'>would lead me to get numbers
  for T_P, OK?</span> </p><p><span m='1220000'>But when we talk about the running
  time,</span> <span m='1222000'>we'll still sort of use this notation, and I'll try
  to be</span> <span m='1226000'>careful as we go through to make sure that there's
  no confusion</span> <span m='1230000'>about what that means in context.</span> </p><p><span
  m='1234000'>There are a couple of them, though, which are fairly well</span> <span
  m='1238000'>defined. One is based on this.</span> </p><p><span m='1240000'>One is
  T_1. So, T_1 is the running time on</span> <span m='1243000'>one processor. OK,
  so if I were to execute</span> <span m='1246000'>this on one processor, you can
  imagine it's just as if</span> <span m='1249000'>I had just gotten rid of the spawn,
  and syncs,</span> <span m='1253000'>and everything, and just executed it.</span>
  </p><p><span m='1255000'>That will give me a particular running time.</span> </p><p><span
  m='1260000'>We call that running time on one processor the work.</span> </p><p><span
  m='1266000'>It's essentially the serial time.</span> </p><p><span m='1270000'>OK,
  so when we talk about the work of a computation,</span> <span m='1276000'>we just
  been essentially a serial running time.</span> </p><p><span m='1282000'>OK, the
  other measure that ends up being interesting is what we</span> <span m='1290000'>call
  T infinity. OK, and this is the critical</span> <span m='1295000'>pathlength, OK,
  which is essentially the</span> <span m='1300000'>longest path in the DAG. So, for
  example,</span> <span m='1306000'>if we look at the fib of four in this example,</span>
  <span m='1310000'>it has T of one equal to, so let's assume we have unit</span>
  <span m='1314000'>time threads. I know they're not unit time,</span> <span m='1318000'>but
  let's just imagine, for the purposes of</span> <span m='1321000'>understanding this,
  that every thread costs me one</span> <span m='1326000'>unit of time to execute.
  What would be the work of this</span> <span m='1332000'>particular computation?
  17, right, OK,</span> <span m='1336000'>because all we do is just add up three,
  six,</span> <span m='1341000'>nine, 12, 13, 14, 15, 16, 17.</span> </p><p><span
  m='1344000'>So, the work is 17 in this case if it were unit time threads.</span>
  </p><p><span m='1352000'>In general, you would add up how many instructions or</span>
  <span m='1355000'>whatever were in there. OK, and then T infinity is the</span>
  <span m='1359000'>longest path. So, this is the longest</span> <span m='1362000'>sequence.
  It's like, if you had an</span> <span m='1364000'>infinite number of processors,
  you still can't just do</span> <span m='1368000'>everything at once because some
  things have to come before other</span> <span m='1372000'>things. But if you had
  an infinite</span> <span m='1375000'>number of processors, as many processors as
  you want,</span> <span m='1379000'>what's the fastest you could possibly execute
  this?</span> </p><p><span m='1384000'>A little trickier. Seven?</span> </p><p><span
  m='1387000'>So, what's your seven? So, one, two,</span> <span m='1392000'>three,
  four, five, six, seven,</span> <span m='1397000'>eight, yeah, eight is the longest
  path.</span> </p><p><span m='1402000'>So, the work and the critical path length,
  as we'll see,</span> <span m='1410000'>are key attributes of any computation.</span>
  </p><p><span m='1418000'>And abstractly, and this is just for [the</span> <span
  m='1424000'>notes?], if they're unit time threads.</span> </p><p><span m='1430000'>OK,
  so we can use these two measures to derive lower bounds</span> <span m='1439000'>on
  T_P for P that fall between one and infinity,</span> <span m='1447000'>OK?</span>
  </p><p><span m='1460000'>OK, so the first lower bound we can derive is that T_P
  has got</span> <span m='1470000'>to be at least T_1 over P. OK, so why is that a
  lower</span> <span m='1479000'>bound? Yeah?</span> </p><p><span m='1482000'>But
  if I have P processors, and, OK, and why would I have</span> <span m='1497000'>this
  lower bound? OK, yeah, you've got the right</span> <span m='1505000'>idea. So, but
  can we be a little bit</span> <span m='1507000'>more articulate about it? So, that's
  right,</span> <span m='1510000'>so you want to use all of processors.</span> </p><p><span
  m='1513000'>If you could use all of processors, why couldn't I use</span> <span
  m='1517000'>all the processors, though, and have T_P be less</span> <span m='1520000'>than
  this? Why does it have to be at least</span> <span m='1523000'>as big as T_1 over
  P? I'm just asking for a little</span> <span m='1527000'>more precision in the answer.
  You've got exactly the right</span> <span m='1531000'>idea, but I need a little
  more precision if we're going to</span> <span m='1535000'>persuade the rest of the
  class that this is the lower bound.</span> </p><p><span m='1541000'>Yeah?</span>
  </p><p><span m='1550000'>Yeah, that's another way of looking at it.</span> </p><p><span
  m='1553000'>If you were to serialize the computation, OK,</span> <span m='1556000'>so
  whatever things you execute on each step,</span> <span m='1559000'>you do P of them,
  and so if you serialized it,</span> <span m='1562000'>somehow then it would take
  you P steps to execute one step of a</span> <span m='1567000'>P way, a machine with
  P processors.</span> </p><p><span m='1569000'>So then, OK, yeah?</span> </p><p><span
  m='1571000'>OK, maybe a little more precise.</span> </p><p><span m='1573000'>David?</span>
  </p><p><span m='1588000'>Yeah, good, so let me just state this a little bit.</span>
  </p><p><span m='1593000'>So, P processors, so what are we relying on?</span> </p><p><span
  m='1598000'>P processors can do, at most, P work in one step,</span> <span m='1603000'>right?
  So, in one step they do,</span> <span m='1607000'>at most P work. They can't do
  more than P work.</span> </p><p><span m='1612000'>And so, if they can do, at most
  P work in one step,</span> <span m='1618000'>then if the number of steps was, in
  fact,</span> <span m='1622000'>less than T_1 over P, they would be able to do more</span>
  <span m='1628000'>than T_1 work in P steps. And, there's only T_1 work to</span>
  <span m='1635000'>be done. OK, I just stated that almost</span> <span m='1639000'>as
  badly as all the responses I got.</span> </p><p><span m='1642000'>[LAUGHTER] OK,
  P processors can do,</span> <span m='1645000'>at most, P work in one step, right?</span>
  </p><p><span m='1650000'>So, if there's T_1 work to be done, the number of steps
  is</span> <span m='1654000'>going to be at least T_1 over P, OK?</span> </p><p><span
  m='1657000'>There we go. OK, it wasn't that hard.</span> </p><p><span m='1660000'>It's
  just like, I've got a certain amount of,</span> <span m='1663000'>I've got T_1 work
  to do. I can knock off,</span> <span m='1666000'>at most, P on every step. How many
  steps?</span> </p><p><span m='1669000'>Just divide. OK, so it's going to have to
  be</span> <span m='1673000'>at least that amount. OK, good.</span> </p><p><span
  m='1675000'>The other lower bound is T_P is greater than or equal to T</span> <span
  m='1679000'>infinity. Somebody explain to me why that</span> <span m='1684000'>might
  be true. Yeah?</span> </p><p><span m='1686000'>Yeah, if you have an infinite number
  of processors,</span> <span m='1690000'>you have P. so if you could do it in a</span>
  <span m='1693000'>certain amount of time with P, you can certainly do it in that</span>
  <span m='1698000'>time with an infinite number of processors.</span> </p><p><span
  m='1701000'>OK, this is in this model where, you know,</span> <span m='1705000'>there
  is lots of stuff that this model doesn't model like</span> <span m='1709000'>communication
  costs and interference,</span> <span m='1712000'>and all sorts of things. But it
  is simple model,</span> <span m='1717000'>which actually in practice works out pretty
  well,</span> <span m='1721000'>OK, you're not going to be able to do more work with
  P</span> <span m='1725000'>processors than you are with an infinite number of processors.</span>
  </p><p><span m='1746000'>OK, so those are helpful bounds to understand when we are
  trying</span> <span m='1752000'>to make something go faster, it's nice to know what
  you</span> <span m='1757000'>could possibly hope to achieve, OK, as opposed to beating
  your</span> <span m='1763000'>head against a wall, how come I can't get it to go</span>
  <span m='1768000'>much faster? Maybe it's because one of these</span> <span m='1773000'>lower
  bounds is operating. OK, well, we're interested in</span> <span m='1779000'>how
  fast we can go. That's the main reason for</span> <span m='1784000'>using multiple
  processors is you hope you're going to go faster</span> <span m='1791000'>than you
  could with one processor.</span> </p><p><span m='1795000'>So, we define T_1 over
  T_P to be the speedup on P processors.</span> </p><p><span m='1803000'>OK, so we
  say, how much faster is it on P</span> <span m='1809000'>processors than on one
  processor?</span> </p><p><span m='1814000'>OK, that's the speed up. If T_1 over
  T_P is order P,</span> <span m='1822000'>we say that it's linear speedup.</span>
  </p><p><span m='1827000'>OK, in other words, why?</span> </p><p><span m='1832000'>Because
  that says that it means that if I've thrown P processors</span> <span m='1838000'>at
  the job I'm going to get a speedup that's proportional to</span> <span m='1844000'>P.
  OK, so when I throw P</span> <span m='1846000'>processors at the job and I get T_P,
  if that's order P,</span> <span m='1851000'>that means that in some sense my processors
  each contributed</span> <span m='1857000'>within a constant factor its full measure
  of support.</span> </p><p><span m='1864000'>If this, in fact, were equal to P,</span>
  <span m='1868000'>we'd call that perfect linear speedup.</span> </p><p><span m='1873000'>OK,
  so but here we're looking at giving ourselves,</span> <span m='1880000'>for theoretical
  purposes, a little bit of a constant</span> <span m='1887000'>buffer here, perhaps.
  If T_1 over T_P is greater than</span> <span m='1894000'>P, we call that super linear
  speedup.</span> </p><p><span m='1901000'>OK, so can somebody tell me, when can I
  get super linear</span> <span m='1905000'>speedup?</span> </p><p><span m='1916000'>When
  can I get super linear speed up?</span> </p><p><span m='1919000'>Never. OK, why
  never?</span> </p><p><span m='1921000'>Yeah, if we buy these lower bounds, the first
  lower bound</span> <span m='1926000'>there, it is T_P is greater than or equal to
  T_1 over P.</span> </p><p><span m='1931000'>And, if I just take T_1 over T_P, that
  says it's less than or</span> <span m='1937000'>equal to P. so, this is never,</span>
  <span m='1939000'>OK, not possible in this model. OK, there are other models</span>
  <span m='1945000'>where it is possible to get super linear speed up due to</span>
  <span m='1950000'>caching effects, and things of that nature.</span> </p><p><span
  m='1956000'>But in this simple model that we are dealing with,</span> <span m='1963000'>it's
  not possible to get super linear speedup.</span> </p><p><span m='1970000'>OK, not
  possible. Now, the maximum possible</span> <span m='1977000'>speedup, given some
  amount of work and critical path length is</span> <span m='1986000'>what? What's
  the maximum possible</span> <span m='1993000'>speed up I could get over any number
  of processors?</span> </p><p><span m='2000000'>What's the maximum I could possibly
  get?</span> </p><p><span m='2006000'>No, I'm saying, no matter how many processors,</span>
  <span m='2012000'>what's the most speedup that I could get?</span> </p><p><span
  m='2020000'>T_1 over T infinity, because this is the,</span> <span m='2024000'>so
  T_1 over T infinity is the maximum I could possibly get.</span> </p><p><span m='2029000'>OK,
  if I threw an infinite number of processors at the</span> <span m='2035000'>problem,
  that's going to give me my biggest speedup.</span> </p><p><span m='2040000'>OK,
  and we call that the parallelism.</span> </p><p><span m='2045000'>OK, so that's
  defined to be the parallelism.</span> </p><p><span m='2048000'>So the parallelism
  of the particular algorithm is</span> <span m='2051000'>essentially the work divided
  by the critical path length.</span> </p><p><span m='2056000'>Another way of viewing
  it is that this is the average amount</span> <span m='2071000'>of work that can
  be done in parallel along each step of the</span> <span m='2086000'>critical path.
  And, we denote it often by P</span> <span m='2097000'>bar. So, do not get confused.</span>
  </p><p><span m='2101000'>P bar does not have anything to do with P at some level.</span>
  </p><p><span m='2105000'>OK, P is going to be a certain number of processors you're</span>
  <span m='2110000'>running. P bar is defined just in terms</span> <span m='2113000'>of
  the computation you're executing, not in terms of the</span> <span m='2117000'>machine
  you're running it on. OK, it's just the average</span> <span m='2121000'>amount
  of work that can be done in parallel along each step of</span> <span m='2125000'>the
  critical path. OK, questions so far?</span> </p><p><span m='2130000'>So mostly we're
  just doing definitions so far.</span> </p><p><span m='2133000'>OK, now we get into,
  OK, so it's helpful to know</span> <span m='2137000'>what the parallelism is, because
  the parallelism is</span> <span m='2141000'>going to, there's no real point in trying
  to get speed up bigger</span> <span m='2146000'>than the parallelism. OK, so if
  you are given a</span> <span m='2150000'>particular computation, you'll be able
  to say,</span> <span m='2153000'>oh, it doesn't go any faster. You're throwing more
  processors</span> <span m='2158000'>at it. Why is it that going any</span> <span
  m='2163000'>faster? And the answer could be,</span> <span m='2167000'>no more parallelism.
  OK, let's see what I want to,</span> <span m='2174000'>yeah, I think we can raise
  the example here.</span> </p><p><span m='2180000'>We'll talk more about this model.</span>
  </p><p><span m='2185000'>Mostly, now, we're going to just talk about</span> <span
  m='2191000'>DAG's. So, we'll talk about the</span> <span m='2195000'>programming
  model next time. So, let's talk about</span> <span m='2203000'>scheduling. The goal
  of scheduler is to map</span> <span m='2208000'>the computation to P processors.
  And this is typically done by a</span> <span m='2215000'>runtime system, which,
  if you will,</span> <span m='2219000'>is an algorithm that is running underneath
  the language layer</span> <span m='2226000'>that I showed you. OK, so the programmer
  designs</span> <span m='2232000'>an algorithm using spawns, and syncs, and so forth.</span>
  </p><p><span m='2235000'>Then, underneath that, there's an algorithm that has</span>
  <span m='2239000'>to actually map that executing program onto the processors of</span>
  <span m='2244000'>the machine as it executes. And that's the scheduler.</span> </p><p><span
  m='2247000'>OK, so it's done by the language runtime system,</span> <span m='2251000'>typically.
  OK, so it turns out that online</span> <span m='2257000'>schedulers, let me just
  say they're complex.</span> </p><p><span m='2262000'>OK, they're not necessarily
  easy things to build.</span> </p><p><span m='2269000'>OK, they're not too bad actually.</span>
  </p><p><span m='2273000'>But, we are not going to go there because we only have
  two</span> <span m='2281000'>lectures to do this. Instead, we're going to do is</span>
  <span m='2287000'>we'll illustrate the ideas using off-line scheduling.</span> </p><p><span
  m='2296000'>OK, so you'll get an idea out of this for what a scheduler</span> <span
  m='2300000'>does, and it turns out that doing these things online is</span> <span
  m='2304000'>another level of complexity beyond that.</span> </p><p><span m='2307000'>And
  typically, the online schedulers that are</span> <span m='2311000'>good, these days,
  are randomized schedulers.</span> </p><p><span m='2315000'>And they have very strong
  proofs of their ability to</span> <span m='2322000'>perform. But we're not going
  to go</span> <span m='2326000'>there. We'll keep it simple.</span> </p><p><span
  m='2330000'>And in particular, we're going to look at a</span> <span m='2336000'>particular
  type of scheduler called a greedy scheduler.</span> </p><p><span m='2345000'>So,
  if you have a DAG to execute, so the basic rules of</span> <span m='2349000'>the
  scheduler is you can't execute a node until all of the</span> <span m='2355000'>nodes
  that precede it in the DAG have executed.</span> </p><p><span m='2359000'>OK, so
  you've got to wait until everything is executed.</span> </p><p><span m='2364000'>So,
  a greedy scheduler, what it says is let's just try</span> <span m='2369000'>to do
  as much as possible on every step, OK?</span> </p><p><span m='2390000'>In other
  words, it says I'm never going to try</span> <span m='2392000'>to guess that it's
  worthwhile delaying doing something.</span> </p><p><span m='2396000'>If I could
  do something now, I'm going to do it.</span> </p><p><span m='2400000'>And so, each
  step is going to correspond to be one of two</span> <span m='2408000'>types. The
  first type is what we'll</span> <span m='2413000'>call a complete step. And this
  is a step in which</span> <span m='2421000'>there are at least P threads ready to
  run.</span> </p><p><span m='2427000'>And, I'm executing on P processors.</span>
  </p><p><span m='2434000'>There are at least P threads ready to run.</span> </p><p><span
  m='2438000'>So, what's a greedy strategy here?</span> </p><p><span m='2442000'>I've
  got P processors. I've got at least P threads.</span> </p><p><span m='2448000'>Run
  any P. Yeah, first P would be if you</span> <span m='2452000'>had a notion of ordering.
  That would be perfectly</span> <span m='2457000'>reasonable. Here, we are just going
  to</span> <span m='2462000'>execute any P. We might make a mistake there,</span>
  <span m='2467000'>because there may be a particular one that if we</span> <span
  m='2470000'>execute now, that'll enable more parallelism later on.</span> </p><p><span
  m='2474000'>We might not execute that one. We don't know.</span> </p><p><span m='2478000'>OK,
  but basically, what we're going to do is just</span> <span m='2481000'>execute any
  P willy-nilly. So, there's some,</span> <span m='2484000'>if you will, non-determinism
  in this step</span> <span m='2487000'>here because which one you execute may or
  may not be a good</span> <span m='2492000'>choice. OK, the second type of step</span>
  <span m='2498000'>we're going to have is an incomplete step.</span> </p><p><span
  m='2505000'>And this is a situation where we have fewer than P threads</span> <span
  m='2515000'>ready to run. So, what's our strategy there?</span> </p><p><span m='2524000'>Execute
  all of them. OK, if it's greedy,</span> <span m='2530000'>no point in not executing.
  OK, so if I've got more than P</span> <span m='2539000'>threads ready to run, I
  execute any P.</span> </p><p><span m='2545000'>If I have fewer than P threads ready
  to run,</span> <span m='2552000'>we execute all of them. So, it turns out this is
  a good</span> <span m='2559000'>strategy. It's not a perfect strategy.</span> </p><p><span
  m='2562000'>In fact, the strategy of trying to schedule optimally a DAG on P</span>
  <span m='2568000'>processors is NP complete, meaning it's very difficult.</span>
  </p><p><span m='2573000'>So, those of you going to take 6.045 or 6.840,</span> <span
  m='2577000'>I highly recommend these courses, and we'll talk more</span> <span m='2581000'>about
  that in the last lecture as we talked a little bit about</span> <span m='2586000'>what's
  coming up in the theory engineering concentration.</span> </p><p><span m='2593000'>You
  can learn about NP completeness and about how you</span> <span m='2596000'>show
  that certain problems, there are no good algorithms</span> <span m='2599000'>for
  them, OK, that we are aware of,</span> <span m='2602000'>OK, and what exactly that
  means.</span> </p><p><span m='2604000'>So, it turns out that this type of scheduling
  problem turns out</span> <span m='2608000'>to be a very difficult problem to get
  it optimal.</span> </p><p><span m='2612000'>But, there's nice theorem, due independently
  to Graham and</span> <span m='2626000'>Brent. It says, essentially,</span> <span
  m='2633000'>a greedy scheduler executes any computation,</span> <span m='2645000'>G,
  with work, T_1, and critical path length,</span> <span m='2655000'>T infinity in
  time, T_P, less than or equal to T_1</span> <span m='2667000'>over P plus T infinity
  --</span> <span m='2684000'>-- on a computer with P processors.</span> </p><p><span
  m='2689000'>OK, so, it says that I can achieve T_1 over P plus T</span> <span m='2696000'>infinity.
  So, what does that say?</span> </p><p><span m='2702000'>If we take a look and compare
  this with our lower bounds on</span> <span m='2709000'>runtime, how efficient is
  this? How does this compare with the</span> <span m='2716000'>optimal execution?
  Yeah, it's two competitive.</span> </p><p><span m='2722000'>It's within a factor
  of two of optimal because this is a lower</span> <span m='2730000'>bound and this
  is a lower bound. And so, if I take twice the max</span> <span m='2737000'>of these
  two, twice the maximum of these two,</span> <span m='2741000'>that's going to be
  bigger than the sum.</span> </p><p><span m='2744000'>So, I'm within a factor of
  two of which ever is the stronger,</span> <span m='2749000'>lower bound for any
  situation. So, this says you get within a</span> <span m='2754000'>factor of two
  of efficiency of scheduling in terms of the</span> <span m='2758000'>runtime on
  P processors. OK, does everybody see that?</span> </p><p><span m='2764000'>So, let's
  prove this theorem. It's quite an elegant theorem.</span> </p><p><span m='2770000'>It's
  not a hard theorem. One of the nice things,</span> <span m='2775000'>by the way,
  about this week, is that nothing is very hard.</span> </p><p><span m='2780000'>It
  just requires you to think differently.</span> </p><p><span m='2785000'>OK, so the
  proof has to do with counting up how many complete</span> <span m='2791000'>steps
  we have, and how many incomplete steps</span> <span m='2795000'>we have. OK, so
  we'll start with the</span> <span m='2801000'>number of complete steps. So, can
  somebody tell me what's</span> <span m='2809000'>the largest number of complete
  steps I could possibly have?</span> </p><p><span m='2818000'>Yeah, I heard somebody
  mumble it back there.</span> </p><p><span m='2825000'>T_1 over P. Why is that?</span>
  </p><p><span m='2828000'>Yeah, so the number of complete steps is, at most,</span>
  <span m='2837000'>T_1 over P because why? Yeah, once you've had this</span> <span
  m='2845000'>many, you've done T_1 work, OK?</span> </p><p><span m='2852000'>So,
  every complete step I'm getting P work done.</span> </p><p><span m='2856000'>So,
  if I did more than T_1 over P steps, there would be no more</span> <span m='2861000'>work
  to be done. So, the number of complete</span> <span m='2865000'>steps can't be bigger
  than T_1 over P.</span> </p><p><span m='2890000'>OK, so that's this piece. OK, now
  we're going to count up</span> <span m='2896000'>the incomplete steps, and show
  its bounded by T</span> <span m='2901000'>infinity. OK, so let's consider an</span>
  <span m='2905000'>incomplete step. And, let's see what happens.</span> </p><p><span
  m='2919000'>And, let's let G prime be the subgraph of G that remains to be</span>
  <span m='2937000'>executed. OK, so we'll draw a picture</span> <span m='2942000'>here.
  So, imagine we have,</span> <span m='2944000'>let's draw it on a new board.</span>
  </p><p><span m='2966000'>So here, we're going to have a graph, our graph,</span>
  <span m='2972000'>G. We're going to do actually P</span> <span m='2976000'>equals
  three as our example here.</span> </p><p><span m='2980000'>So, imagine that this
  is the graph, G.</span> </p><p><span m='2985000'>And, I'm not showing the procedures
  here because this</span> <span m='2992000'>actually is a theorem that works for
  any DAG.</span> </p><p><span m='3000000'>And, the procedure outlines are not necessary.</span>
  </p><p><span m='3009000'>All we care about is the threads.</span> </p><p><span m='3016000'>I
  missed one. OK, so imagine that's my DAG,</span> <span m='3025000'>G, and imagine
  that I have executed up to this point.</span> </p><p><span m='3038000'>Which ones
  have I executed? Yeah, I've executed these guys.</span> </p><p><span m='3047000'>So,
  the things that are in G prime are just the things that</span> <span m='3057000'>have
  yet to be executed. And these guys are the ones</span> <span m='3064000'>that are
  already executed. And, we'll imagine that all of</span> <span m='3069000'>them are
  unit time threads without loss of generality.</span> </p><p><span m='3074000'>The
  theorem would go through, even if each of these had a</span> <span m='3079000'>particular
  time associated with it.</span> </p><p><span m='3083000'>The same scheduling algorithm
  will work just fine.</span> </p><p><span m='3087000'>So, how can I characterize
  the threads that are ready to be</span> <span m='3092000'>executed? Which are the
  threads that are</span> <span m='3098000'>ready to be executed here? Let's just
  see.</span> </p><p><span m='3102000'>So, that one? No, that's not ready to be</span>
  <span m='3106000'>executed. Why?</span> </p><p><span m='3108000'>Because it's got
  a predecessor here, this guy.</span> </p><p><span m='3112000'>OK, so this guy is
  ready to be executed, and this guy is ready</span> <span m='3119000'>to be executed.
  OK, so those two threads are</span> <span m='3124000'>ready to be, how can I characterize
  this?</span> </p><p><span m='3128000'>What's their property? What's a graph theoretic</span>
  <span m='3132000'>property in G prime that tells me whether or not something is</span>
  <span m='3137000'>ready to be executed? It has no predecessor,</span> <span m='3141000'>but
  what's another way of saying that?</span> </p><p><span m='3144000'>It's got no predecessor
  in G prime.</span> </p><p><span m='3149000'>What does it mean for a node not to
  have a predecessor in a</span> <span m='3158000'>graph? Its in degree is zero,</span>
  <span m='3163000'>right? Same thing.</span> </p><p><span m='3166000'>OK, the threads
  with in degree, zero and G prime are the ones</span> <span m='3176000'>that are
  ready to be executed. OK, and if it's incomplete</span> <span m='3186000'>step,
  what do I do? I'm going to execute says,</span> <span m='3191000'>if it's an incomplete
  step, I execute all of them.</span> </p><p><span m='3197000'>OK, so I execute all
  of these. OK, now I execute all of the in</span> <span m='3204000'>degree zero threads,
  what happens to the critical</span> <span m='3210000'>path length of the graph that
  remains to be executed?</span> </p><p><span m='3218000'>It decreases by one. OK,
  so the critical path length</span> <span m='3228000'>of what remains to be executed,
  G prime, is reduced by one.</span> </p><p><span m='3240000'>So, what's left to be
  executed on every incomplete step,</span> <span m='3244000'>what's left to be executed
  always reduces by one.</span> </p><p><span m='3248000'>Notice the next step here
  is going to be a complete step,</span> <span m='3252000'>because I've got four things
  that are ready to go.</span> </p><p><span m='3256000'>And, I can execute them in
  such a way that the critical path</span> <span m='3261000'>length doesn't get reduced
  on that step.</span> </p><p><span m='3264000'>OK, but if I had to execute all of
  them, then it does reduce the</span> <span m='3269000'>critical path length. Now,
  of course,</span> <span m='3273000'>both could happen, OK, at the same time,</span>
  <span m='3278000'>OK, but any time that I have an incomplete step,</span> <span
  m='3283000'>I'm guaranteed to reduce the critical path length by one.</span> </p><p><span
  m='3290000'>OK, so that implies that the number of incomplete steps is,</span> <span
  m='3296000'>at most, T infinity. And so, therefore,</span> <span m='3301000'>T of
  P is, at most, the number of complete steps</span> <span m='3305000'>plus the number
  of incomplete steps.</span> </p><p><span m='3308000'>And we get our bound. This
  is sort of an amortized</span> <span m='3312000'>argument if you want to think of
  it that way, OK,</span> <span m='3317000'>that at every step I'm either amortizing
  the step against the</span> <span m='3322000'>work, or I'm amortizing it against
  the critical path</span> <span m='3326000'>length, or possibly both. But I'm at
  least doing one of</span> <span m='3332000'>those for every step, OK, and so, in
  the end,</span> <span m='3335000'>I just have to add up the two contributions.</span>
  </p><p><span m='3339000'>Any questions about that? So this, by the way,</span> <span
  m='3342000'>is the fundamental theorem of all scheduling.</span> </p><p><span m='3346000'>If
  ever you study anything having to do with scheduling,</span> <span m='3350000'>this
  basic result is sort of the foundation of a huge number</span> <span m='3355000'>of
  things. And then what people do is they</span> <span m='3358000'>gussy it up, like,
  let's do this online,</span> <span m='3361000'>OK, with a scheduler, etc., that
  everybody's trying</span> <span m='3365000'>to match these bounds, OK, of what an
  omniscient</span> <span m='3369000'>greedy scheduler would achieve, OK, and there
  are all kinds of</span> <span m='3374000'>other things. But this is sort of the
  basic</span> <span m='3379000'>theorem that just pervades the whole area of scheduling.</span>
  </p><p><span m='3385000'>OK, let's do a quick corollary. I'm not going to erase
  those.</span> </p><p><span m='3392000'>Those are just too important. I want to erase
  those.</span> </p><p><span m='3397000'>Let's not erase those. I want to erase that
  either.</span> </p><p><span m='3402000'>We're going to go back to the top.</span>
  </p><p><span m='3405000'>Actually, we'll put the corollary here because that's</span>
  <span m='3411000'>just one line. OK.</span> </p><p><span m='3431000'>The corollary
  says you get linear speed up if the number of</span> <span m='3437000'>processors
  that you allocate, that you run your job on is</span> <span m='3444000'>order, the
  parallelism. OK, so greedy scheduler gives</span> <span m='3451000'>you linear speed
  up if you're running on essentially</span> <span m='3457000'>parallelism or fewer
  processors. OK, so let's see why that is.</span> </p><p><span m='3466000'>And I
  hope I'll fit this, OK?</span> </p><p><span m='3471000'>So, P bar is T_1 over T
  infinity.</span> </p><p><span m='3478000'>And that implies that if P equals order
  T_1 over T</span> <span m='3484000'>infinity, then that says just bringing those
  around,</span> <span m='3490000'>T infinity is order T_1 over P. So, everybody with
  me?</span> </p><p><span m='3497000'>It's just algebra. So, it says this is the</span>
  <span m='3502000'>definition of parallelism, T_1 over T infinity,</span> <span m='3508000'>and
  so, if P is order parallelism, then it's order T_1</span> <span m='3515000'>over
  T infinity. And now, just bring it around.</span> </p><p><span m='3523000'>It says
  T infinity is order T_1 over P.</span> </p><p><span m='3529000'>So, that says T
  infinity is order T_1 over P.</span> </p><p><span m='3536000'>OK, and so, therefore,
  continue the proof here,</span> <span m='3543000'>thus T_P is at most T_1 over P
  plus T infinity.</span> </p><p><span m='3552000'>Well, if this is order T_1 over
  P, the whole thing is order T_1</span> <span m='3563000'>over P. OK, and so, now
  I have T_P is</span> <span m='3569000'>order T_1 over P, and what we need is to
  compute</span> <span m='3577000'>T_1 over T_P, and that's going to be order</span>
  <span m='3585000'>T_P. OK?</span> </p><p><span m='3588000'>Does everybody see that?
  So what that says is that if I</span> <span m='3591000'>have a certain amount of
  parallelism, if I run</span> <span m='3594000'>essentially on fewer processors than
  that parallelism,</span> <span m='3598000'>I get linear speed up if I use greedy
  scheduling.</span> </p><p><span m='3602000'>OK, if I run on more processors than
  the parallelism,</span> <span m='3605077'>in some sense I'm being wasteful because
  I can't</span> <span m='3607859'>possibly get enough speed up to justify those extra
  processors.</span> </p><p><span m='3611529'>So, understanding parallelism of a job
  says that's sort of a</span> <span m='3615021'>limit on the number of processors
  I want to have.</span> </p><p><span m='3617862'>And, in fact, I can achieve that.</span>
  </p><p><span m='3619757'>Question?</span> </p><p><span m='3639000'>Yeah, really,
  in some sense,</span> <span m='3641008'>this is saying it should be omega P.</span>
  </p><p><span m='3643611'>Yeah, so that's fine. It's a question of,</span> <span
  m='3646586'>so ask again.</span> </p><p><span m='3663000'>No, no, it's only if it's
  bounded above by a constant.</span> </p><p><span m='3666495'>T_1 and T infinity
  aren't constants.</span> </p><p><span m='3668804'>They're variables in this. So,
  we are doing multivariable</span> <span m='3672497'>asymptotic analysis. So, any
  of these things can be</span> <span m='3675795'>a function of anything else, and
  can be growing as much as</span> <span m='3679555'>we want. So, the fact that we
  say we are</span> <span m='3682127'>given it for a particular thing, we're really
  not given that</span> <span m='3686019'>number. We're given a whole class of</span>
  <span m='3688327'>DAG's or whatever of various sizes is really what we're</span>
  <span m='3691889'>talking about. So, I can look at the growth.</span> </p><p><span
  m='3697788'>Here, where it's talking about the growth of the parallelism,</span>
  <span m='3705626'>sorry, the growth of the runtime T_P as a function of T_1</span>
  <span m='3712941'>and T infinity. So, I am talking about things</span> <span m='3718689'>that
  are growing here, OK?</span> </p><p><span m='3723000'>OK, so let's put this to work,
  OK?</span> </p><p><span m='3726018'>And, in fact, so now I'm going to go back to</span>
  <span m='3729951'>here. Now I'm going to tell you about</span> <span m='3733243'>a
  little bit of my own research, and how we use this in some of</span> <span m='3738913'>the
  work that we did. OK, so we've developed a</span> <span m='3743030'>dynamic multithreaded
  language called Cilk, spelled with a C</span> <span m='3748426'>because it's based
  on the language, C.</span> </p><p><span m='3753000'>And, it's not an acronym because
  silk is like nice</span> <span m='3759837'>threads, OK, although at one point my
  students had a</span> <span m='3766953'>competition for what the acronym silk could
  mean.</span> </p><p><span m='3773651'>The winner, turns out, was Charles' Idiotic
  Linguistic</span> <span m='3781046'>Kluge. So anyway, if you want to take</span>
  <span m='3786214'>a look at it, you can find some stuff on it</span> <span m='3790714'>here.
  OK,</span> <span m='3800000'>OK, and what it uses is actually one of these more</span>
  <span m='3808412'>complicated schedulers. It's a randomized online</span> <span
  m='3816480'>scheduler, OK, and if you look at its expected</span> <span m='3824206'>runtime
  on P processors, it gets effectively T_1 over P</span> <span m='3833476'>plus O
  of T infinity provably. OK, and empirically,</span> <span m='3841428'>if you actually
  look at what kind of runtimes you get to find</span> <span m='3845714'>out what's
  hidden in the big O there, it turns out,</span> <span m='3849285'>in fact, it's
  T_1 over P plus T infinity with the constants here</span> <span m='3853785'>being
  very close to one empirically.</span> </p><p><span m='3856285'>So, no guarantees,
  but this turns out to be a</span> <span m='3859428'>pretty good bound. Sometimes,
  you see a</span> <span m='3862142'>coefficient on T infinity that's up maybe close
  to four or</span> <span m='3866214'>something. But generally,</span> <span m='3869385'>you
  don't see something that's much bigger than that.</span> </p><p><span m='3874533'>And
  mostly, it tends to be around, if you do a linear</span> <span m='3879680'>regression
  curve fit, you get that the constant here</span> <span m='3884729'>is close to one.
  And so, with this,</span> <span m='3888094'>you get near perfect if you use this
  formula as a model for your</span> <span m='3894331'>runtime. You get near perfect
  linear</span> <span m='3897795'>speed up if the number of processors you're running
  on is</span> <span m='3903339'>much less than your average parallelism, which,</span>
  <span m='3907892'>of course, is the same thing as if T infinity is much less than</span>
  <span m='3914029'>T_1 over P. So, what happens here is that</span> <span m='3919481'>when
  P is much less than P infinity, that is,</span> <span m='3923247'>T infinity is
  much less than T_1 over P, this term ceases to</span> <span m='3928297'>matter very
  much, and you get very good speedup,</span> <span m='3932319'>OK, in fact, almost
  perfect speedup.</span> </p><p><span m='3936000'>So, each processor gives you another
  processor's work as long</span> <span m='3942357'>as you are the range where the
  number of processors is much</span> <span m='3948503'>less than the number of parallelism.</span>
  </p><p><span m='3952211'>Now, with this language many years ago, which seems now
  like</span> <span m='3958463'>many years ago, OK, it turned out we competed.</span>
  </p><p><span m='3963231'>We built a bunch of chess programs.</span> </p><p><span
  m='3968000'>And, among our programs were Starsocrates,</span> <span m='3971962'>and
  Cilkchess, and we also had several others.</span> </p><p><span m='3976312'>And these
  were, I would call them,</span> <span m='3979501'>world-class. In particular,</span>
  <span m='3982014'>we tied for first in the 1995 World Computer Chess</span> <span
  m='3986750'>Championship in Hong Kong, and then we had a playoff and</span> <span
  m='3992066'>we lost. It was really a shame.</span> </p><p><span m='3995860'>We almost
  won, running on a big parallel</span> <span m='3999157'>machine. That was, incidentally,</span>
  <span m='4001778'>some of you may know about the Deep Blue chess playing program.</span>
  </p><p><span m='4007020'>That was the last time before they faced then world champion</span>
  <span m='4012008'>Kasparov that they competed against programs.</span> </p><p><span
  m='4015728'>They tied for third in that tournament.</span> </p><p><span m='4018941'>OK,
  so we actually out-placed them.</span> </p><p><span m='4023000'>However, in the
  head-to-head competition, we lost to them.</span> </p><p><span m='4027159'>So we
  had one loss in the tournament up to the point of</span> <span m='4031099'>the finals.
  They had a loss and a draw.</span> </p><p><span m='4033872'>Most people aren't aware
  that Deep Blue, in fact,</span> <span m='4037375'>was not the reigning World Computer
  Chess Championship when</span> <span m='4041608'>they faced Kasparov. The reason
  that they faced</span> <span m='4044964'>Kasparov was because IBM was willing to
  put up the money.</span> </p><p><span m='4050000'>OK, so we developed these chess
  programs, and the way we</span> <span m='4058029'>developed them, let me in particular
  talk about</span> <span m='4064747'>Starsocrates. We had this interesting anomaly</span>
  <span m='4071172'>come up. We were running on a 32</span> <span m='4075699'>processor
  computer at MIT for development.</span> </p><p><span m='4083000'>And, we had access
  to a 512 processor computer for the</span> <span m='4087463'>tournament at NCSA
  at the University of Illinois.</span> </p><p><span m='4091505'>So, we had this big
  machine. Of course, they didn't want to</span> <span m='4096389'>give it to us very
  much, but we have the same machine,</span> <span m='4100852'>just a small one, at
  MIT.</span> </p><p><span m='4102872'>So, we would develop on this, and occasionally
  we'd be able</span> <span m='4107756'>to run on this, and this was what we were</span>
  <span m='4111126'>developing for on our processor. So, let me show you sort of the</span>
  <span m='4117719'>anomaly that came up, OK?</span> </p><p><span m='4128000'>So,
  we had a version of a program that I'll call the</span> <span m='4135974'>original
  program, OK, and we had an optimized</span> <span m='4142854'>program that included
  some new features that were supposed to</span> <span m='4152236'>make the program
  go faster. And so, we timed it on our 32</span> <span m='4160992'>processor machine.
  And, it took us 65 seconds to</span> <span m='4168341'>run it. OK, and then we timed
  this new</span> <span m='4173839'>program. So, I'll call that T prime of</span>
  <span m='4177340'>sub 32 on our 32 processor machine, and it ran and 40</span> <span
  m='4182261'>seconds to do this particular benchmark.</span> </p><p><span m='4185952'>Now,
  let me just say, I've lied about the actual</span> <span m='4190399'>numbers here
  to make the calculations easy.</span> </p><p><span m='4194375'>But, the same idea
  happened. Just the numbers were messier.</span> </p><p><span m='4201000'>OK, so
  this looks like a significant improvement in</span> <span m='4207275'>runtime, but
  we rejected the optimization.</span> </p><p><span m='4212421'>OK, and the reason
  we rejected it is because we understood</span> <span m='4219574'>about the issues
  of work and critical path.</span> </p><p><span m='4224846'>So, let me show you the
  analysis that we did,</span> <span m='4230368'>OK? So the analysis,</span> <span
  m='4233813'>it turns out, if we looked at our</span> <span m='4237441'>instrumentation,
  the work in this case was</span> <span m='4242089'>2,048. And, the critical path
  was one</span> <span m='4246170'>second, which, over here with the optimized</span>
  <span m='4250931'>program, the work was, in fact, 1,024.</span> </p><p><span m='4255125'>But
  the critical path was eight.</span> </p><p><span m='4260000'>So, if we plug into
  our simple model here, the one I have up</span> <span m='4267375'>there with the
  approximation there, I have T_32 is equal to</span> <span m='4274625'>T_1 over 32
  plus T infinity, and that's equal to,</span> <span m='4280625'>well, the work is
  2,048 divided by 32.</span> </p><p><span m='4285250'>What's that? 64, good, plus
  the critical</span> <span m='4290125'>path, one, that's 65. So, that checks out
  with what</span> <span m='4297625'>we saw. OK, in fact,</span> <span m='4300000'>we
  did that, and it checked out.</span> </p><p><span m='4303875'>OK, it was very close.
  OK, over here,</span> <span m='4308375'>T prime of 32 is T prime, one over 32 plus
  T infinity</span> <span m='4314875'>prime, and that's equal to 1,024 divided by
  32 is 32 plus eight,</span> <span m='4322750'>the critical path here. That's 40.</span>
  </p><p><span m='4327981'>So, that checked out too. So, now what we did is we said</span>
  <span m='4333377'>is we said, OK, let's extrapolate to our big</span> <span m='4337596'>machine.
  How fast are these things going</span> <span m='4341422'>to run on our big machine?
  Well, for that,</span> <span m='4345445'>we want T of 512. And, that's equal to
  T_1 over</span> <span m='4349958'>512 plus T infinity. And so, what's 2,048 divided
  by</span> <span m='4356913'>512? It's four, plus T infinity is</span> <span m='4361079'>one.
  That's equal to five.</span> </p><p><span m='4364235'>So, go quite a bit faster
  on this.</span> </p><p><span m='4368401'>But here, T prime of 512 is equal to T
  one prime over 512</span> <span m='4375471'>plus T infinity prime is equal to, well,
  1,024 plus divided by</span> <span m='4383172'>512 is two plus critical path of
  eight, that's ten.</span> </p><p><span m='4391000'>OK, and so, you see that on the
  big machine, we would have been</span> <span m='4395913'>running twice as slow had
  we adopted that,</span> <span m='4399163'>quote, "optimization", OK, because we
  had run out of</span> <span m='4403205'>parallelism, and this was making the path
  longer.</span> </p><p><span m='4407009'>We needed to have a way of doing it where
  we could reduce</span> <span m='4411447'>the work. Yeah, it's good to reduce the</span>
  <span m='4414459'>work but not as the critical path ends up getting rid of the</span>
  <span m='4419135'>parallels that we hope to be able to use during the runtime.</span>
  </p><p><span m='4425000'>So, it's twice as slow, OK, twice as slow.</span> </p><p><span
  m='4428186'>So the moral is that the work and critical path length predict</span>
  <span m='4432927'>the performance better than the execution time alone,</span> <span
  m='4436968'>OK, when you look at scalability.</span> </p><p><span m='4440000'>And
  a big issue on a lot of these machines is scalability;</span> <span m='4443600'>not
  always, sometimes you're not worried about scalability.</span> </p><p><span m='4447263'>Sometimes
  you just care. Had we been running in the</span> <span m='4450421'>competition on
  a 32 processor machine, we would have accepted</span> <span m='4454210'>this optimization.
  It would have been a good</span> <span m='4456926'>trade-off. OK, but because we
  knew that we</span> <span m='4459515'>were running on a machine with a lot more
  processors,</span> <span m='4462800'>and that we were close to running out of the
  parallelism,</span> <span m='4466336'>it didn't make sense to be increasing the
  critical path at</span> <span m='4469936'>that point, because that was just reducing
  the parallelism of</span> <span m='4473726'>our calculation. OK, next time,</span>
  <span m='4476887'>any questions about that first? No?</span> </p><p><span m='4479041'>OK.
  Next time, now that we</span> <span m='4480626'>understand the model for execution,
  we're going to start</span> <span m='4484111'>looking at the performance of particular
  algorithms what we</span> <span m='4487786'>code them up in a dynamic, multithreaded
  style,</span> <span m='4490701'>OK?</span> </p>
type: course
uid: e9d8462200b474f0ee3d4dbd3a22ebe9

---
None