---
about_this_resource_text: <p><strong>Topics covered:</strong>&nbsp;Greedy Algorithms,
  Minimum Spanning Trees</p><p><strong>Instructors:</strong>&nbsp;Prof. Erik Demaine,&nbsp;Prof.
  Charles Leiserson</p>
course_id: 6-046j-introduction-to-algorithms-sma-5503-fall-2005
embedded_media:
- id: lec16.pdf
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/lec16.pdf
  title: lec16.pdf
  type: null
  uid: 07deed5b5a439ef982ef40aaa282d444
- id: 6_046J_lec16_th.jpg
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/6_046J_lec16_th.jpg
  title: 6_046J_lec16_th.jpg
  type: null
  uid: 45818c7b132e73f0513da040c2325342
- id: Video-YouTube-Stream
  media_location: FPEMBWg_WlY
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-YouTube-Stream
  type: Video
  uid: 510efe0e42db989342bbf1ee4e797a62
- id: Thumbnail-YouTube-JPG
  media_location: https://img.youtube.com/vi/FPEMBWg_WlY/default.jpg
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Thumbnail-YouTube-JPG
  type: Thumbnail
  uid: f921cfbdca94b76c2fdc87374a50e4b0
- id: Video-iTunesU-MP4
  media_location: https://itunes.apple.com/us/itunes-u/id341597754
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-iTunes U-MP4
  type: Video
  uid: 3e8ed181b48adf7b2b20f1008819b3b0
- id: Video-InternetArchive-MP4
  media_location: http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-09nov2005-220k.mp4
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-Internet Archive-MP4
  type: Video
  uid: 6aa9cb88afe5f7ac9505ce2c8030af79
- id: Video-iTunesU-MP3
  media_location: http://deimos3.apple.com/WebObjects/Core.woa/Browse/mit.edu.1298167185.01298167189.1303027031?i=1854015852
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-iTunes U-MP3
  type: Video
  uid: 36af5993fef3f7a70917921015db5458
- id: Video-InternetArchive-MP3
  media_location: http://www.archive.org/download/MIT6.046JF05/ocw-6.046-09nov2005.mp3
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-Internet Archive-MP3
  type: Video
  uid: 45b173220b1325371b00a29170147267
- id: Video-VideoLecturesnet-Stream
  media_location: http://videolectures.net/mit6046jf05_introduction_algorithms/
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Video-VideoLectures.net-Stream
  type: Video
  uid: f6d52cc1ef418c3a7b62f5e194962209
- id: Thumbnail-OCW-JPG
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Thumbnail-OCW-JPG
  type: Thumbnail
  uid: 3d93faff318b77fef613b861747b9d23
- id: 3Play-3PlayYouTubeid-MP4
  media_location: FPEMBWg_WlY
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: 3Play-3Play YouTube id
  type: 3Play
  uid: 90532f0c27b51846075674adf40cb257
- id: FPEMBWg_WlY.srt
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/FPEMBWg_WlY.srt
  title: 3play caption file
  type: null
  uid: 6ac64f7203de1bea56b570e76e0f06ea
- id: FPEMBWg_WlY.pdf
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/FPEMBWg_WlY.pdf
  title: 3play pdf file
  type: null
  uid: 1d8cc61551128f9281fb52ea5c4bff91
- id: Caption-3Play YouTube id-SRT
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Caption-3Play YouTube id-SRT-English - US
  type: Caption
  uid: f4c5317f433d448197c5656cec573b02
- id: Transcript-3Play YouTube id-PDF
  parent_uid: 3b98255fecbddd4ef435b8937a71eed9
  title: Transcript-3Play YouTube id-PDF-English - US
  type: Transcript
  uid: 40705abd5b997de55b30b8b8b6e43d74
inline_embed_id: 40635472lecture16:greedyalgorithms,minimumspanningtrees92356012
layout: video
order_index: null
parent_uid: c492612542f7cc7a09f73790a5f91d81
related_resources_text: <p>Lecture Notes (<a target="_blank" href="./resolveuid/07deed5b5a439ef982ef40aaa282d444">PDF</a>)<br
  />             <a target="_blank" href="./resolveuid/efc69ef86c18e164d675bd8808c6477a">Assignments</a><br
  />             <a target="_blank" href="./resolveuid/144d9e513546eac8c1fd9b0d278e6eb2">Exams</a></p>
short_url: lecture-16-greedy-algorithms-minimum-spanning-trees
technical_location: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees
template_type: Tabbed
title: 'Lecture 16: Greedy Algorithms, Minimum Spanning Trees'
transcript: '<p><span m=''7000''>-- valuable experience. OK, today we''re going to
  start</span> <span m=''12000''>talking about a particular class of algorithms called
  greedy</span> <span m=''18000''>algorithms. But we''re going to do it in the</span>
  <span m=''22000''>context of graphs. So, I want to review a little</span> <span
  m=''27000''>bit about graphs, which mostly you can find in</span> <span m=''32000''>the
  textbook in appendix B. And so, if you haven''t reviewed</span> <span m=''39000''>in
  appendix B recently, please sit down and review</span> <span m=''45000''>appendix
  B. It will pay off especially</span> <span m=''50000''>during our take-home quiz.
  So, just reminder,</span> <span m=''55000''>a digraph, what''s a digraph? What''s
  that short for?</span> </p><p><span m=''61000''>Directed graph, OK?</span> </p><p><span
  m=''64000''>Directed graph, G equals (V,E),</span> <span m=''67000''>OK, has a set,
  V, of vertices.</span> </p><p><span m=''73000''>And, I always get people telling
  me that I have one</span> <span m=''77000''>vertice. The singular is not vertice;</span>
  <span m=''80000''>it is vertex, OK?</span> </p><p><span m=''81000''>The plural is
  vertices. The singular is vertex.</span> </p><p><span m=''85000''>It''s one of those
  weird English words.</span> </p><p><span m=''89000''>It''s probably originally like
  French or something,</span> <span m=''93000''>right? I don''t know.</span> </p><p><span
  m=''97000''>OK, anyway, and we have a set, E, which is a subset of V cross</span>
  <span m=''107000''>V of edges. So that''s a digraph.</span> </p><p><span m=''112000''>And
  undirected graph, E contains unordered pairs.</span> </p><p><span m=''132000''>OK,
  and, sorry? It''s Latin, OK,</span> <span m=''135000''>so it''s probably pretty
  old, then, in English.</span> </p><p><span m=''141000''>I guess the vertex would
  be a little bit of a giveaway that</span> <span m=''148000''>maybe it wasn''t French.
  It started to be used in 1570,</span> <span m=''154000''>OK. OK, good, OK,</span>
  <span m=''159000''>so the number of edges is, whether it''s directed or</span> <span
  m=''172000''>undirected, is O of what? V^2, good.</span> </p><p><span m=''182000''>OK,
  and one of the conventions that will have when we''re</span> <span m=''185000''>dealing,
  once we get into graphs, we deal a lot with sets.</span> </p><p><span m=''189000''>We
  generally drop the vertical bar notation within O''s just</span> <span m=''193000''>because
  it''s applied. It just makes it messier.</span> </p><p><span m=''196000''>So, once
  again, another abuse of notation.</span> </p><p><span m=''198000''>It really should
  be order the size of V^2, but it just messes</span> <span m=''202000''>up, I mean,
  it''s just more stuff to write down.</span> </p><p><span m=''205000''>And, you''re
  multiplying these things, and all those vertical</span> <span m=''209000''>bars.
  Since they don''t even have a</span> <span m=''213000''>sense to the vertical bar,
  it gets messy.</span> </p><p><span m=''216000''>So, we just drop the vertical bars
  there when it''s in</span> <span m=''220000''>asymptotic notation. So, E is order
  V^2 when it''s a</span> <span m=''224000''>set of pairs, because if it''s a set
  of pairs,</span> <span m=''228000''>it''s at most n choose two, which is where it''s
  at most n^2</span> <span m=''232000''>over 2, here it could be, at most, sorry,</span>
  <span m=''236000''>V^2 over 2, here it''s at most V^2.</span> </p><p><span m=''240000''>And
  then, another property that sometimes comes up is if the G</span> <span m=''247000''>is
  connected, we have another bound,</span> <span m=''251000''>implies that the size
  of E is at least the size of V minus</span> <span m=''258000''>one. OK, so if it''s
  connected,</span> <span m=''262000''>meaning, what does it mean to have a graph
  that''s connected?</span> </p><p><span m=''271000''>Yeah, there''s a path from any
  vertex to any other vertex in</span> <span m=''277000''>the graph. That''s what
  it means to be</span> <span m=''280000''>connected. So if that''s the case,</span>
  <span m=''284000''>that a number of edges is at least the number of vertices</span>
  <span m=''290000''>minus one, OK? And so, what that says,</span> <span m=''293000''>so
  one of the things we''ll get into, a fact that I just wanted</span> <span m=''300000''>to
  remind you, is that in that case,</span> <span m=''304000''>if I look at log E,
  OK, log of the number of edges,</span> <span m=''309000''>that is O of log V. And
  by this,</span> <span m=''314000''>is omega of log V. So, it''s equal to theta of
  log</span> <span m=''318000''>V. OK, so basically the number of,</span> <span m=''321000''>in
  the case of a connected graph, the number of edges,</span> <span m=''325000''>and
  the number of vertices are polynomially related.</span> </p><p><span m=''330000''>So,
  their logs are comparable. OK, so that''s helpful just to</span> <span m=''336000''>know
  because sometimes I just get questions later on where</span> <span m=''341000''>people
  will say, oh, you showed it was log E but</span> <span m=''345000''>you didn''t
  show it was log V. And I could point out that it''s</span> <span m=''351000''>the
  same thing. OK, so there''s various ways of</span> <span m=''355000''>representing
  graphs in computers, and I''m just going to</span> <span m=''359000''>cover a couple
  of the important ones.</span> </p><p><span m=''364000''>There''s actually more.
  We''ll see some more.</span> </p><p><span m=''371000''>So, the simplest one is what''s
  called an adjacency matrix.</span> </p><p><span m=''380000''>An adjacency matrix
  of the graph, G, equals (V,E),</span> <span m=''390000''>where, for simplicity,
  I''ll let V be the set of</span> <span m=''400000''>integers from one up to n, OK,
  is the n by n matrix A</span> <span m=''412000''>given by the ij-th at the entry
  is simply one if the edge,</span> <span m=''424000''>ij, is in the edge set and
  zero if ij is not in the edge set.</span> </p><p><span m=''440000''>OK, so it''s
  simply the matrix where you say,</span> <span m=''442000''>the ij entry is one if
  it''s in the matrix.</span> </p><p><span m=''445000''>So, this is, in some sense,</span>
  <span m=''447000''>giving you the predicate for, is there an edge from i to j?</span>
  </p><p><span m=''452000''>OK, remember, predicate is Boolean formula</span> <span
  m=''455000''>that is either zero or one, and in this case,</span> <span m=''459000''>you''re
  saying it''s one if there is an edge from i to j and zero</span> <span m=''465000''>otherwise.
  OK, sometimes you have edge</span> <span m=''468000''>weighted graphs, and then
  sometimes what people</span> <span m=''472000''>will do is replace this by edge
  weights.</span> </p><p><span m=''476000''>OK, it will be the weight of the edge
  from i to j.</span> </p><p><span m=''482000''>So, let''s just do an example of that
  just to make sure that our</span> <span m=''492000''>intuition corresponds to our
  mathematical definitions.</span> </p><p><span m=''502000''>So, here''s an example
  graph. Let''s say that''s our graph.</span> </p><p><span m=''513000''>So let''s
  just draw the adjacency the matrix.</span> </p><p><span m=''517000''>OK, so what
  this says: is there''s an edge from one to</span> <span m=''522000''>one? And the
  answer is no.</span> </p><p><span m=''524000''>Is there an edge from one to two?</span>
  </p><p><span m=''527000''>Yes. Is there an edge from one to</span> <span m=''530000''>three
  here? Yep.</span> </p><p><span m=''531000''>Is there an edge for one to four?</span>
  </p><p><span m=''534000''>No. Is there an edge from two until</span> <span m=''538000''>one?
  No.</span> </p><p><span m=''540000''>Two to two? No.</span> </p><p><span m=''542000''>Two
  to three? Yes.</span> </p><p><span m=''544000''>Two to four? No.</span> </p><p><span
  m=''546000''>No edges going out of three. Edge from four to three,</span> <span
  m=''553000''>and that''s it. That''s the adjacency matrix for</span> <span m=''559000''>this
  particular graph, OK?</span> </p><p><span m=''563000''>And so, I can represent a
  graph as this adjacency matrix.</span> </p><p><span m=''573000''>OK, when I represent
  it in this way, how much storage do I need?</span> </p><p><span m=''583000''>OK,
  n^2 or V^2 because the size is the same thing for V^2</span> <span m=''592000''>storage,
  OK, and that''s what we call a dense representation.</span> </p><p><span m=''603000''>OK,
  it works well when the graph is dense.</span> </p><p><span m=''606000''>So, the
  graph is dense if the number of edges is close to all</span> <span m=''611000''>of
  the edges possible. OK, then this is a good</span> <span m=''614000''>representation.
  But for many types of graphs,</span> <span m=''618000''>the number of edges is much
  less than the possible number of</span> <span m=''623000''>edges, in which case
  we say the graph is sparse.</span> </p><p><span m=''626000''>Can somebody give me
  an example of a sparse graph?</span> </p><p><span m=''632000''>A class of graphs:
  so, I want a class of graphs</span> <span m=''635000''>that as n grows, the number
  of edges in the</span> <span m=''638000''>graph doesn''t grow as the square, but
  grows rather as</span> <span m=''642000''>something much smaller. A linked list,</span>
  <span m=''645000''>so, a chain, OK, if you look at it from a</span> <span m=''648000''>graph
  theoretically, is a perfectly good example:</span> <span m=''652000''>only n edges
  in the chain for a chain of length n.</span> </p><p><span m=''656000''>So therefore,
  the number of edges would be</span> <span m=''659000''>order V. And in particular,</span>
  <span m=''662000''>you''d only have one edge per row here.</span> </p><p><span m=''667000''>What
  other graphs are sparse? Yeah?</span> </p><p><span m=''670000''>Good, a planar graph,
  a graph that can be drawn in a</span> <span m=''676000''>plane turns out that if
  it has V vertices has,</span> <span m=''681000''>and V is at least three, then it
  has,</span> <span m=''685000''>at most, three V minus six edges.</span> </p><p><span
  m=''690000''>So, it turns out that''s order V edges again.</span> </p><p><span m=''694000''>What''s
  another example of a common graph?</span> </p><p><span m=''698000''>Yeah, binary
  tree, or even actually any tree,</span> <span m=''702000''>you know, what''s called
  a free tree if you read the appendix,</span> <span m=''709000''>OK, a tree that
  just is a connected graph that has no</span> <span m=''714000''>cycles, OK, is another
  example. What''s an example of a graph</span> <span m=''720000''>that''s dense?
  A complete graph,</span> <span m=''724000''>OK: it''s all ones, OK, or if you have
  edge</span> <span m=''727000''>weights, it would be a completely filled in matrix.</span>
  </p><p><span m=''731000''>OK, good. So, this is good for dense</span> <span m=''734000''>representation.
  But sometimes you want to have</span> <span m=''737000''>a sparse representation
  so we don''t have to spend V^2 space to</span> <span m=''742000''>deal with all
  of the, where most of it''s going to be</span> <span m=''746000''>zeroes. OK, it''s
  sort of like,</span> <span m=''748000''>if we know why it''s zero, why bother representing
  it as</span> <span m=''753000''>zero? So, one such representation is</span> <span
  m=''760000''>an adjacency list representation.</span> </p><p><span m=''766000''>Actually,
  adjacency list of a given vertex is the list,</span> <span m=''776000''>which we
  denote by Adj of V, of vertices adjacent to V.</span> </p><p><span m=''788000''>OK,
  just in terms by their terminology, vertices are</span> <span m=''792000''>adjacent,
  but edges are incident on vertices.</span> </p><p><span m=''797000''>OK, so the
  incidence is a relation between a vertex and an</span> <span m=''802000''>edge.
  An adjacency is a relation</span> <span m=''805000''>between two vertices. OK, that''s
  just the language.</span> </p><p><span m=''811000''>Why they use to different terms,
  I don''t know,</span> <span m=''816000''>but that''s what they do. So, in the graph,</span>
  <span m=''820000''>for example, the adjacency list for vertex</span> <span m=''825000''>one
  is just the list or the set of two three because one has</span> <span m=''832000''>going
  out of one are edges to two and three.</span> </p><p><span m=''837000''>The adjacency
  list for two is just three, four,</span> <span m=''842000''>three. It''s the empty
  set,</span> <span m=''847000''>and for four, it is three.</span> </p><p><span m=''850000''>OK,
  so that''s the representation.</span> </p><p><span m=''853000''>Now, if we want
  to figure out how much storage is required for</span> <span m=''861000''>this representation,
  OK, we need to understand how</span> <span m=''866000''>long the adjacency list
  is. So, what is the length of an</span> <span m=''875000''>adjacency list of a vertex,
  V?</span> </p><p><span m=''880000''>What name do we give to that? It''s the degree.</span>
  </p><p><span m=''888000''>So, in an undirected graph, we call it the degree of the</span>
  <span m=''897000''>vertex. This is undirected.</span> </p><p><span m=''902000''>OK,
  about here, OK.</span> </p><p><span m=''907000''>So that''s an undirected case.
  In the directed case,</span> <span m=''912000''>OK, actually I guess the way we
  should do this is say this.</span> </p><p><span m=''918000''>If the degree, we call
  it the out degree for a</span> <span m=''922000''>digraph. OK, so in a digraph,</span>
  <span m=''925000''>we have an out degree and an in degree for each vertex.</span>
  </p><p><span m=''932000''>So here, the in degree is three.</span> </p><p><span m=''936000''>Here,
  the out degree is two, OK?</span> </p><p><span m=''941000''>So, one of the important
  lemma that comes up is what''s called</span> <span m=''950000''>the handshaking
  lemma. OK, it''s one of these</span> <span m=''956000''>mathematical lemmas.</span>
  </p><p><span m=''971000''>And so, it comes from a story. Go to a dinner party,</span>
  <span m=''976000''>and everybody at the dinner party shakes other people''s</span>
  <span m=''981000''>hands. Some people may not shake</span> <span m=''984000''>anybody''s
  hand. Some people may shake several</span> <span m=''989000''>people''s hands. Nobody
  shakes hands with</span> <span m=''992000''>themselves. And at some point during
  the</span> <span m=''997000''>dinner party, the host goes around and counts</span>
  <span m=''1001000''>up how many, the sum, of the number of hands that</span> <span
  m=''1005000''>each person has shaken. OK, so he says,</span> <span m=''1008000''>how
  many did you shake? How many did you shake?</span> </p><p><span m=''1012000''>How
  many did you shake? He adds them up,</span> <span m=''1015000''>OK, and that number
  is guaranteed to be even.</span> </p><p><span m=''1020000''>OK, that''s the handshaking
  lemma.</span> </p><p><span m=''1023000''>Or, stated a little bit more precisely,
  if I take for any</span> <span m=''1028000''>graph the degree of the vertex, and
  sum them all up,</span> <span m=''1033000''>that''s how many hands everybody shook,
  OK, that''s actually equal</span> <span m=''1040000''>to always twice the number
  of edges.</span> </p><p><span m=''1043000''>So, why is that going to be true?</span>
  </p><p><span m=''1046000''>Why is that going to be twice the number of edges?</span>
  </p><p><span m=''1053000''>Yeah? Yeah. Every time you put in an edge, you add one
  to the degree of</span> <span m=''1059000''>each person on each end. So, it''s just
  two different</span> <span m=''1064000''>ways of counting up the same number of
  edges.</span> </p><p><span m=''1068000''>OK, I can go around, and if you imagine
  that,</span> <span m=''1072000''>that every time I count the degree of the node,</span>
  <span m=''1076000''>I put a mark on every edge. Then, when I''m done,</span> <span
  m=''1081000''>every edge has two marks on it, one for each end.</span> </p><p><span
  m=''1087000''>OK: a pretty simple theorem. So, what that says is that for</span>
  <span m=''1097000''>undirected graphs, that implies that the adjacency</span> <span
  m=''1106000''>list representation, uses how much storage?</span> </p><p><span m=''1115000''>OK,
  at most, 2E, so order E because that''s</span> <span m=''1119000''>not all. Yeah,
  so you have to have the</span> <span m=''1122000''>number of vertices plus order
  the number of edges,</span> <span m=''1127000''>OK, whether it''s directed or undirected
  because I may have a</span> <span m=''1133000''>graph, say it has a whole bunch
  of vertices and no edges,</span> <span m=''1139000''>that''s still going to cost
  me order V, OK?</span> </p><p><span m=''1145000''>So, it uses theta of V plus E
  storage.</span> </p><p><span m=''1149000''>And, it''s basically the same thing asymptotically.</span>
  </p><p><span m=''1155000''>In fact, it''s easier to see in some sense for digraphs
  because</span> <span m=''1162000''>for digraphs, what I do is I just add up the</span>
  <span m=''1167000''>out degrees, and that equal to E, OK, if I add up the out</span>
  <span m=''1173000''>degrees as equally. In fact, this is kind of like</span> <span
  m=''1179000''>it amortized analysis, if you will,</span> <span m=''1181000''>a book
  keeping analysis, that if I''m adding up the total</span> <span m=''1185000''>number
  of edges, one way of doing it is</span> <span m=''1188000''>accounting for a vertex
  by vertex.</span> </p><p><span m=''1190000''>OK, so for each vertex, I basically
  can take each</span> <span m=''1194000''>degree, and basically each vertex, look
  at the degree,</span> <span m=''1198000''>and that allocating of account per edge,
  and then ending up</span> <span m=''1202000''>with twice the number of edges, that''s
  exactly accounting type</span> <span m=''1206000''>of analysis that we might do
  for amortized analysis.</span> </p><p><span m=''1212000''>OK, so we''ll see that.
  So, this is a sparse</span> <span m=''1217000''>representation, and it''s often
  better than an</span> <span m=''1222000''>adjacency matrix. For example,</span>
  <span m=''1225000''>you can imagine if the World Wide Web were done with an</span>
  <span m=''1232000''>adjacency matrix as opposed to, essentially,</span> <span m=''1237000''>with
  an adjacency list type of representation.</span> </p><p><span m=''1244000''>Every
  link on the World Wide Web, I had to say,</span> <span m=''1247000''>here are the
  ones that I''m connected to,</span> <span m=''1250000''>and here are all the ones
  I''m not connected to.</span> </p><p><span m=''1253000''>OK, that list of things
  you''re not connected to for a given</span> <span m=''1257000''>page would be pretty
  dramatically,</span> <span m=''1259000''>show you that there is an advantage to
  sparse</span> <span m=''1263000''>representation. On the other hand,</span> <span
  m=''1266000''>one of the nice things about an adjacency matrix representation</span>
  <span m=''1273000''>is that each edge can be represented with a single bit,</span>
  <span m=''1279000''>whereas typical when I''m representing things with an</span>
  <span m=''1284000''>adjacency list representation, how many bits am I going to</span>
  <span m=''1290000''>need to represent each adjacency?</span> </p><p><span m=''1295000''>You''ll
  need order log of V to be able to name each different</span> <span m=''1299000''>vertex.
  OK, the log of the number is</span> <span m=''1301000''>the number of bits that
  I need. So, there are places where this</span> <span m=''1306000''>is actually a
  far more efficient representation.</span> </p><p><span m=''1310000''>In particular,
  if you have a very dense graph,</span> <span m=''1313000''>OK, this may be a better
  way of representing it.</span> </p><p><span m=''1316000''>OK, the other thing I
  want you to get, and we''re going to see</span> <span m=''1321000''>more of this
  in particular next week, is that a matrix and a</span> <span m=''1325000''>graph,
  there are two ways of looking at the same thing.</span> </p><p><span m=''1331000''>OK,
  and in fact, there''s a lot of graph theory</span> <span m=''1334000''>that when
  you do things like multiply the adjacency matrix,</span> <span m=''1337000''>OK,
  and so forth. So, there''s a lot of</span> <span m=''1340000''>commonality between
  graphs and matrices, a lot of mathematics</span> <span m=''1344000''>that if it
  applies for one, it applies to the other.</span> </p><p><span m=''1348000''>Do you
  have a question, or just holding your finger in</span> <span m=''1351000''>the air?
  OK, good.</span> </p><p><span m=''1353000''>OK, so that''s all just review. Now
  I want to get onto today''s</span> <span m=''1357000''>lecture. OK, so any questions
  about</span> <span m=''1360000''>graphs? So, this is a good time to</span> <span
  m=''1362000''>review appendix B. there are a lot of great</span> <span m=''1365000''>properties
  in there, and in particular,</span> <span m=''1368000''>there is a theorem that
  we''re going to cover today that we''re</span> <span m=''1372000''>going to talk
  about today, which is properties of trees.</span> </p><p><span m=''1376000''>Trees
  are very special kinds of graphs, so I really want you to</span> <span m=''1380000''>go
  and look to see what the properties are.</span> </p><p><span m=''1385000''>There
  is, I think, something like six different</span> <span m=''1388000''>definitions
  of trees that are all equivalent,</span> <span m=''1391000''>OK, and so, I think
  a very good idea to go through and read</span> <span m=''1396000''>through that
  theorem. We''re not going to prove it in</span> <span m=''1400000''>class, but really,
  provides a very good basis for</span> <span m=''1403000''>the thinking that we''re
  going to be doing today.</span> </p><p><span m=''1407000''>And we''ll see more of
  that in the future.</span> </p><p><span m=''1410000''>OK, so today, we''re going
  to talk about</span> <span m=''1413000''>minimum spanning trees. OK, this is one
  of the world''s</span> <span m=''1418000''>most important algorithms. OK, it is
  important in</span> <span m=''1422000''>distributed systems. It''s one of the first
  things</span> <span m=''1426000''>that almost any distributed system tries to find
  is a</span> <span m=''1430000''>minimum spanning tree of the nodes that happened
  to be alive</span> <span m=''1435000''>at any point, OK?</span> </p><p><span m=''1436000''>And
  one of the people who developed an algorithm for this,</span> <span m=''1441000''>we''ll
  talk about this a little bit later, OK,</span> <span m=''1444000''>it was the basis
  of the billing system for AT&T for many years</span> <span m=''1449000''>while it
  was a monopoly. OK, so very important kind of</span> <span m=''1456000''>thing.
  It''s got a huge number of</span> <span m=''1461000''>applications. So the problem
  is the</span> <span m=''1465000''>following. You have a connected undirected</span>
  <span m=''1471000''>graph, G equals (V,E),</span> <span m=''1475000''>with an edge
  weight function, w, which maps the edges into</span> <span m=''1482000''>weights
  that are real numbers. And for today''s lecture,</span> <span m=''1490000''>we''re
  going to make an important assumption,</span> <span m=''1496000''>OK, for simplicity.
  The book does not make this</span> <span m=''1502000''>assumption. And so, I encourage
  you to look</span> <span m=''1508000''>at the alternative presentation or, because
  what they do in the</span> <span m=''1516000''>book is much more general, but for
  simplicity and</span> <span m=''1522000''>intuition, I''m going to make this a little
  bit easier.</span> </p><p><span m=''1529000''>We''re going to assume that all edge
  weights are distinct.</span> </p><p><span m=''1537000''>OK, all edge weights are
  distinct.</span> </p><p><span m=''1539000''>So what does that mean? What does that
  mean that this</span> <span m=''1542000''>function, w, what property does the function,</span>
  <span m=''1546000''>w, have if all edge weights are distinct?</span> </p><p><span
  m=''1548000''>Who remembers their discreet math?</span> </p><p><span m=''1551000''>It''s
  injective. OK, it''s one to one.</span> </p><p><span m=''1553000''>OK, it''s not
  one to one and onto necessarily.</span> </p><p><span m=''1556000''>In fact, it would
  be kind of hard to do that because that''s a</span> <span m=''1560000''>pretty big
  set. OK, but it''s one to one.</span> </p><p><span m=''1565000''>It''s injective.
  OK, so that''s what we''re going</span> <span m=''1569000''>to assume for simplicity.
  OK, and the book,</span> <span m=''1574000''>they don''t assume that. It just means
  that the way you</span> <span m=''1579000''>have to state things is just a little
  more precise.</span> </p><p><span m=''1584000''>It has to be more technically precise.</span>
  </p><p><span m=''1588000''>So, that''s the input. The output is--</span> <span m=''1593000''>The
  output is a spanning tree, T, and by spanning tree,</span> <span m=''1604000''>we
  mean it connects all the vertices.</span> </p><p><span m=''1612000''>OK, and it''s
  got to have minimum weight.</span> </p><p><span m=''1622000''>OK, so we can write
  the weight of the tree is going to be,</span> <span m=''1628000''>by that, we meet
  the sum over all edges that are in the tree</span> <span m=''1634000''>of the weight
  of the individual edges.</span> </p><p><span m=''1638000''>OK, so here I''(V,E)
  done a little bit of abusive notation,</span> <span m=''1644000''>which is that
  what I should be writing is w of the edge (u,v)</span> <span m=''1651000''>because
  this is a mapping from edges, which would give me a</span> <span m=''1657000''>double
  parentheses. And, you know,</span> <span m=''1662000''>as you know, I love to abuse
  notation.</span> </p><p><span m=''1665000''>So, I''m going to drop that extra parentheses,</span>
  <span m=''1668000''>because we understand that it''s really the weight of the edge,</span>
  <span m=''1674000''>OK, not the weight of the ordered pair.</span> </p><p><span
  m=''1677000''>So, that''s just a little notational convenience.</span> </p><p><span
  m=''1682000''>OK, so one of the things, when we do the take-home exam,</span> <span
  m=''1685000''>notational convenience can make the difference between having a</span>
  <span m=''1689000''>horrible time writing up a problem, and an easy time.</span>
  </p><p><span m=''1692000''>So, it''s worth thinking about what kinds of notation
  you''ll</span> <span m=''1696000''>use in writing up solutions to problems, and
  so forth.</span> </p><p><span m=''1699000''>OK, and just in general, a technical
  communication,</span> <span m=''1702000''>you adopt good notation people understand
  you.</span> </p><p><span m=''1705000''>You adopt a poor notation: nobody pays attention
  to what</span> <span m=''1709000''>you''re doing because they don''t understand
  what you''re saying.</span> </p><p><span m=''1714000''>OK, so let''s do an example.</span>
  </p><p><span m=''1725000''>OK, so here''s a graph. I think for this,</span> <span
  m=''1732000''>somebody asked once if I was inspired by biochemistry or</span> <span
  m=''1742000''>something, OK, but I wasn''t.</span> </p><p><span m=''1749000''>I
  was just writing these things down, OK?</span> </p><p><span m=''1751000''>So, here''s
  a graph. And let''s give us some edge</span> <span m=''1755000''>weights.</span>
  </p><p><span m=''1771000''>OK, so there are some edge weights.</span> </p><p><span
  m=''1774000''>And now, what we want is we want to find a tree.</span> </p><p><span
  m=''1779000''>So a connected acyclic graph such that every vertex is part</span>
  <span m=''1785000''>of the tree. But it''s got to have the</span> <span m=''1789000''>minimum
  weight possible. OK, so can somebody suggest to</span> <span m=''1795000''>me some
  edges that have to be in this minimum spanning tree?</span> </p><p><span m=''1803000''>Yeah,
  so nine, good.</span> </p><p><span m=''1805000''>Nine has to be in there because,
  why?</span> </p><p><span m=''1809000''>It''s the only one connecting it to this
  vertex,</span> <span m=''1814000''>OK? And likewise,</span> <span m=''1816000''>15
  has to be in there. So those both have to be in.</span> </p><p><span m=''1822000''>What
  other edges have to be in? Which one?</span> </p><p><span m=''1826000''>14 has to
  be it. Why does 14 have to be in?</span> </p><p><span m=''1833000''>Well, one of
  14 and three has to be in there.</span> </p><p><span m=''1840000''>I want the minimum
  weight. The one that has the overall</span> <span m=''1850000''>smallest weight.
  So, can somebody argue to me</span> <span m=''1857000''>that three has to be in
  there? Yeah?</span> </p><p><span m=''1864000''>That''s the minimum of two, which
  means that if I had a,</span> <span m=''1869000''>if you add something you said
  was a minimum spanning tree that</span> <span m=''1874000''>didn''t include three,
  right, and so therefore it had</span> <span m=''1879000''>to include 14, then I
  could just delete this</span> <span m=''1883000''>edge, 14, and put in edge three.
  And, I have something of lower</span> <span m=''1888000''>weight, right? So, three
  has to be in there.</span> </p><p><span m=''1894000''>What other edges have to be
  in there?</span> </p><p><span m=''1897000''>Do a little puzzle logic. Six and five
  have to be in</span> <span m=''1903000''>there. Why do they have to be in</span>
  <span m=''1906000''>there?</span> </p><p><span m=''1922000''>Yeah, well, I mean,
  it could be connected through</span> <span m=''1925000''>this or something. It doesn''t
  necessarily have to</span> <span m=''1928000''>go this way. Six definitely has to
  be in</span> <span m=''1931000''>there for the same reason that three had to be,</span>
  <span m=''1934000''>right? Because we got two choices to</span> <span m=''1936000''>connect
  up this guy. And so, if everything were</span> <span m=''1939000''>connected but
  it weren''t, 12, I mean, and 12 was in</span> <span m=''1942000''>there. I could
  always,</span> <span m=''1944000''>then, say, well, let''s connect them up this
  way</span> <span m=''1947000''>instead. OK, so definitely that''s in</span> <span
  m=''1951000''>there. I still don''t have everything</span> <span m=''1955000''>connected
  up.</span> </p><p><span m=''1970000''>What else has to be in there for minimum spanning
  tree?</span> </p><p><span m=''1983000''>Seven, five, and eight, why seven,</span>
  <span m=''1991000''>five, and eight? OK, so can we argue those one</span> <span
  m=''2002000''>at a time? Why does five have to be in</span> <span m=''2012000''>there?
  Yeah?</span> </p><p><span m=''2017000''>OK, so we have four connected components
  because we have this</span> <span m=''2021000''>one, this one, we actually have,</span>
  <span m=''2023000''>yeah, this one here, and this one,</span> <span m=''2026000''>good.
  We need at least three edges to</span> <span m=''2029000''>connect them because
  each edge is going to reduce the connected</span> <span m=''2033000''>components
  by one. OK, so we need three edges,</span> <span m=''2037000''>and those are the
  three cheapest ones.</span> </p><p><span m=''2039000''>And they work. That works,
  right?</span> </p><p><span m=''2044000''>Any other edges are going to be bigger,
  so that works.</span> </p><p><span m=''2051000''>Good. OK, and so, now do we have
  a</span> <span m=''2055000''>spanning tree? Everything is,</span> <span m=''2059000''>we
  have one big connected graph here, right?</span> </p><p><span m=''2064000''>Is that
  what I got? Hey, that''s the same as what I</span> <span m=''2071000''>got. Life
  is predictable.</span> </p><p><span m=''2075000''>OK, so, so everybody had the idea
  of what a minimum spanning</span> <span m=''2081000''>tree is, then, out of this,</span>
  <span m=''2084000''>OK, what''s going on there? So, let''s first of all make</span>
  <span m=''2089000''>some observations about this puzzle.</span> </p><p><span m=''2093000''>And
  what I want to do is remind you about the optimal</span> <span m=''2099000''>substructure
  property because it turns out minimum spanning tree</span> <span m=''2106000''>has
  a great optimal substructure property.</span> </p><p><span m=''2112000''>OK, so
  the setup is going to be, we''re going to have some</span> <span m=''2117000''>minimum
  spanning tree. Let''s call it T.</span> </p><p><span m=''2122000''>And, I''m going
  to show that with the other edges in the</span> <span m=''2127000''>graph, are not
  going to be shown.</span> </p><p><span m=''2132000''>OK, so here''s a graph.</span>
  </p><p><span m=''2154000''>OK, so here''s a graph. It looks like the one I have
  my</span> <span m=''2158000''>piece of paper here. OK, so the idea is,</span> <span
  m=''2161000''>this is some minimum spanning tree.</span> </p><p><span m=''2165000''>Now,
  we want to look at a property of optimal</span> <span m=''2169000''>substructure.
  And the way I''m going to get</span> <span m=''2173000''>that, is, I''m going to
  remove some edge, (u,v),</span> <span m=''2177000''>move an arbitrary edge, (u,v),
  in the minimum spanning</span> <span m=''2182000''>tree. So, let''s call this u
  and this</span> <span m=''2186000''>V. And so, we''re removing this</span> <span
  m=''2189000''>edge. OK, so when I remove an edge in</span> <span m=''2193000''>a
  tree, what happens to the tree?</span> </p><p><span m=''2196000''>What''s left?
  I have two trees left,</span> <span m=''2199000''>OK? I have two trees left.</span>
  </p><p><span m=''2201000''>Now, proving that, that''s basically one of the</span>
  <span m=''2205000''>properties in that appendix, and the properties of trees</span>
  <span m=''2210000''>that I want you to read, OK, because you can actually</span>
  <span m=''2215000''>prove that kind of thing rather than it just being obvious,</span>
  <span m=''2220000''>which is, OK? OK, so we remove that.</span> </p><p><span m=''2225000''>Then,
  T is partitioned into two subtrees.</span> </p><p><span m=''2231000''>And, we''ll
  call them T_1 and T_2.</span> </p><p><span m=''2235000''>So, here''s one subtree,
  and here''s another subtree.</span> </p><p><span m=''2242000''>We''(V,E) partitioned
  it. No matter what edge I picked,</span> <span m=''2249000''>there would be two
  subtrees that it''s partitioned into.</span> </p><p><span m=''2258000''>Even if
  the sub tree is a trivial subtree,</span> <span m=''2260000''>for example, it just
  has a single node in it</span> <span m=''2263000''>and no edges.</span> </p><p><span
  m=''2278000''>So, the theorem that we''ll prove demonstrates a property of</span>
  <span m=''2291000''>optimal substructure. T_1 is a minimum spanning tree</span>
  <span m=''2304000''>for the graph, G_1, E_1,</span> <span m=''2311000''>a subgraph
  of G induced by the vertices in T_1.</span> </p><p><span m=''2323000''>OK, that
  is, V_1 is just the vertices in T_1</span> <span m=''2335000''>is what it means
  to be induced. OK, so V_1 is the vertices in</span> <span m=''2349000''>T_1. So,
  in this picture,</span> <span m=''2352000''>I didn''t label it. This is T_1.</span>
  </p><p><span m=''2356000''>This is T_2. In this picture,</span> <span m=''2360000''>these
  are the vertices of T_1. So, that''s V_1,</span> <span m=''2367000''>OK? And, E_1
  is the set of pairs of</span> <span m=''2372000''>vertices, x and y, that are the
  edges that are in</span> <span m=''2379000''>E_1 such that both x and y belong to
  V_1.</span> </p><p><span m=''2387000''>OK, so I haven''t shown the edges of G here.</span>
  </p><p><span m=''2389000''>But basically, if an edge went from here to</span> <span
  m=''2392000''>here, that would be in the E_1. If it went from here to here,</span>
  <span m=''2397000''>it would not. And if it went from here to</span> <span m=''2400000''>here,
  it would not. OK, so the vertices,</span> <span m=''2404000''>the subgraph induced
  by the vertices of T_1 are just those</span> <span m=''2410000''>that connect up
  things in T_1, and similarly for T_2.</span> </p><p><span m=''2427000''>So, the
  theorem says that if I look at just the edges within</span> <span m=''2433000''>the
  graph here, G_1, those that are induced by</span> <span m=''2438000''>these vertices,
  T_1 is, in fact,</span> <span m=''2441000''>a minimum spanning tree for that subgraph.</span>
  </p><p><span m=''2446000''>That''s what the theorem says. OK, if I look over here</span>
  <span m=''2451000''>conversely, or correspondingly, if I look at the set of edges</span>
  <span m=''2458000''>that are induced by this set of vertices, the vertices in T_2,</span>
  <span m=''2465000''>in fact, T_2 is a minimum spanning tree on that subgraph.</span>
  </p><p><span m=''2473000''>OK, OK, we can even do it over here.</span> </p><p><span
  m=''2477000''>If I took a look, for example,</span> <span m=''2481000''>at these,
  let''s see, let''s say we cut out five,</span> <span m=''2487000''>and if I cut
  out edge five, that T_1 would be these four</span> <span m=''2495000''>vertices
  here. And, the point is that if I</span> <span m=''2500000''>look at the subgraph
  induced on that, that these edges here.</span> </p><p><span m=''2504000''>In fact,
  the six, eight, and three are all edges</span> <span m=''2508000''>in a minimum
  spanning tree for that subgraph.</span> </p><p><span m=''2512000''>OK, so that''s
  what the theorem says.</span> </p><p><span m=''2514000''>So let''s prove it.</span>
  </p><p><span m=''2529000''>OK, and so what technique are we going to use to prove
  it?</span> </p><p><span m=''2539000''>OK, we learned this technique last time: hint,</span>
  <span m=''2548000''>hint. It''s something you do it in</span> <span m=''2553000''>your
  text editor all the time: cut and paste,</span> <span m=''2559000''>good, cut and
  paste. OK, so the weight of T I can</span> <span m=''2565000''>express as the weight
  of the edge I removed,</span> <span m=''2571000''>plus the weight of T_1, plus the
  weight of T_2.</span> </p><p><span m=''2577000''>OK, so that''s the total weight.
  So, the argument is pretty</span> <span m=''2587000''>simple. Suppose that there
  were some</span> <span m=''2593000''>T_1 prime that was better than T_1 for G_1.</span>
  </p><p><span m=''2600000''>Suppose I had some better way of forming a spanning tree.</span>
  </p><p><span m=''2611000''>OK, then I would make up a T prime, which just contained
  the</span> <span m=''2622000''>edges, (u,v), and T_1 prime,</span> <span m=''2628000''>union
  T_2. So, I would take,</span> <span m=''2633000''>if I had a better spanning tree,
  a spanning tree of lower</span> <span m=''2645000''>weight for T_1. And I call that
  T_1 prime.</span> </p><p><span m=''2652000''>I just substitute that and make up
  a spanning tree that</span> <span m=''2657000''>consisted of my edge, (u,v), whatever
  works well for</span> <span m=''2662000''>T_1 prime and whatever works well for
  T.</span> </p><p><span m=''2666000''>And, that would be a spanning tree.</span>
  </p><p><span m=''2670000''>And it would be better than T itself was for G,</span>
  <span m=''2676000''>OK, because the weight of these is just as the weight for this,</span>
  <span m=''2684000''>I now just get to use the weight of T_1 prime,</span> <span
  m=''2690000''>and that''s less. And so, therefore,</span> <span m=''2694000''>the
  assumption that T was a minimum spanning tree would be</span> <span m=''2702000''>violated
  if I could find a better one for the subpiece.</span> </p><p><span m=''2711000''>So,
  we have this nice property of optimal substructure.</span> </p><p><span m=''2716000''>OK,
  I have subproblems that exhibit optimal,</span> <span m=''2720000''>if I have a
  globally optimal solution to the whole problem</span> <span m=''2725000''>within
  it, I can find optimal solutions to subproblems.</span> </p><p><span m=''2731000''>So,
  now the question is, that''s one hallmark.</span> </p><p><span m=''2736000''>That''s
  one hallmark of dynamic programming.</span> </p><p><span m=''2741000''>What about
  overlapping subproblems?</span> </p><p><span m=''2745000''>Do I have that property?
  Do I have overlapping</span> <span m=''2751000''>subproblems over here for this
  type of problem?</span> </p><p><span m=''2779000''>So, imagine, for example,</span>
  <span m=''2780000''>that I''m removing different edges.</span> </p><p><span m=''2782000''>I
  look at the space of taking a given edge, and removing it.</span> </p><p><span m=''2786000''>It
  partitions it into two pieces, and now I have another</span> <span m=''2790000''>piece.
  And I remove it,</span> <span m=''2792000''>etc. Am I going to end up getting a</span>
  <span m=''2795000''>bunch of subproblems that are similar in there?</span> </p><p><span
  m=''2798000''>Yeah, I am. OK, if I take out this one,</span> <span m=''2801000''>then
  I take out, say, this one here,</span> <span m=''2803000''>and then I''ll have another
  tree here and here.</span> </p><p><span m=''2806000''>OK, that would be the same
  as if I had originally taken this</span> <span m=''2811000''>out, and then taken
  that one out.</span> </p><p><span m=''2813000''>If I look at simple ordering of
  taking out the edges,</span> <span m=''2817000''>I''m going to end up with a whole
  bunch of overlapping</span> <span m=''2820000''>subproblems. Yeah, OK.</span> </p><p><span
  m=''2824000''>So then, what does that suggest we use as an approach?</span> </p><p><span
  m=''2834000''>Dynamic programming, good.</span> </p><p><span m=''2838000''>What
  a surprise! Yes, OK, you could use dynamic</span> <span m=''2846000''>programming.
  But it turns out that minimum</span> <span m=''2853000''>spanning tree exhibits
  an even more powerful property.</span> </p><p><span m=''2861000''>OK, so we''(V,E)
  got all the clues for dynamic programming,</span> <span m=''2868000''>but it turns
  out that there''s an even bigger clue that''s going</span> <span m=''2877000''>to
  help us to use an even more powerful technique.</span> </p><p><span m=''2885000''>And
  that, we call, the hallmark for greedy</span> <span m=''2891000''>algorithms.</span>
  </p><p><span m=''2912000''>And that is, we have a thing called the</span> <span
  m=''2921000''>greedy choice property, which says that a locally</span> <span m=''2933000''>optimal
  choice is globally optimal.</span> </p><p><span m=''2943000''>And, of course, as
  all these hallmarks is the</span> <span m=''2945000''>kind of thing you want to
  box, OK, because these are the clues</span> <span m=''2949000''>that you''re going
  to be able to do that.</span> </p><p><span m=''2952000''>So, we have this property
  that we call the greedy choice</span> <span m=''2955000''>property. I''m going to
  show you how it</span> <span m=''2958000''>works in this case. And when you have
  a greedy</span> <span m=''2961000''>choice property, it turns out you can do even</span>
  <span m=''2964000''>better that dynamic programming. OK, so when you see the two</span>
  <span m=''2969000''>dynamic programming properties, there is a clue that says</span>
  <span m=''2973000''>dynamic programming, yes, but also it says,</span> <span m=''2976000''>let
  me see whether it also has this greedy property because if</span> <span m=''2981000''>it
  does, you''re going to come up with something that''s even</span> <span m=''2986000''>better
  than dynamic programming, OK?</span> </p><p><span m=''2989000''>So, if you just
  have the two, you can usually do dynamic</span> <span m=''2993000''>programming,
  but if you have this third one,</span> <span m=''2996000''>it''s like, whoa! Jackpot!</span>
  </p><p><span m=''3000000''>OK, so here''s the theorem we''ll prove to illustrate
  this idea.</span> </p><p><span m=''3004000''>Once again, these are not, all these
  hallmarks are not</span> <span m=''3008000''>things. They are heuristics.</span>
  </p><p><span m=''3009000''>I can''t give you an algorithm to say, here''s where
  dynamic</span> <span m=''3014000''>programming works, or here''s where greedy</span>
  <span m=''3016000''>algorithms work. But I can sort of indicate when</span> <span
  m=''3020000''>they work, the kind of structure they have.</span> </p><p><span m=''3023000''>OK,
  so here''s the theorem. So let''s let T be the MST of</span> <span m=''3032000''>our
  graph. And, let''s let A be any subset</span> <span m=''3040000''>of V, so, some
  subset of vertices.</span> </p><p><span m=''3049000''>And now, let''s suppose that
  edge, (u,v), is the least weight</span> <span m=''3064000''>edge connecting our
  set A to A complement, that is,</span> <span m=''3077000''>V minus A. Then the theorem
  says that</span> <span m=''3087000''>(u,v) is in the minimum spanning tree.</span>
  </p><p><span m=''3099000''>So let''s just take a look at our graph over here and
  see if</span> <span m=''3103000''>that''s, in fact, the case.</span> </p><p><span
  m=''3105000''>OK, so let''s take, so one thing I could do for A</span> <span m=''3109000''>is
  just take a singleton node. So, I take a singleton node,</span> <span m=''3113000''>let''s
  say this guy here, that can be my A,</span> <span m=''3116000''>and everything else
  is V minus A.</span> </p><p><span m=''3120000''>And I look at the least weight edge
  connecting this to</span> <span m=''3124000''>everything else. Well, there are only
  two edges</span> <span m=''3127000''>that connect it to everything else.</span>
  </p><p><span m=''3130000''>And the theorem says that the lighter one is in the minimum</span>
  <span m=''3135000''>spanning tree. Hey, I win.</span> </p><p><span m=''3137000''>OK,
  if you take a look, every vertex that I pick,</span> <span m=''3141000''>the latest
  edge coming out of that vertex is in the minimum</span> <span m=''3145000''>spanning
  tree. OK, the lightest weight edge</span> <span m=''3149000''>coming out, but that''s
  not all the edges that are in here.</span> </p><p><span m=''3155000''>OK, or let''s
  just imagine, let''s take a look at these</span> <span m=''3159000''>three vertices
  connected to this set of vertices.</span> </p><p><span m=''3163000''>I have three
  edges is going across.</span> </p><p><span m=''3166000''>The least weight one is
  five. That''s the minimum spanning</span> <span m=''3170000''>tree. Or, I can cut
  it this way.</span> </p><p><span m=''3173000''>OK, the ones above one, the edges
  going down are seven,</span> <span m=''3177000''>eight, and 14. Seven is the least
  weight.</span> </p><p><span m=''3182000''>It''s in the minimum spanning tree.</span>
  </p><p><span m=''3184000''>So, no matter how I choose, I could make this one in,</span>
  <span m=''3188000''>this one out, this one in,</span> <span m=''3190000''>this one
  out, this one in,</span> <span m=''3192000''>this one out, this one in,</span> <span
  m=''3194000''>this one out, take a look at what all the</span> <span m=''3198000''>edges
  are. Which ever one to the least</span> <span m=''3201000''>weight: it''s in the
  minimum spanning tree.</span> </p><p><span m=''3204000''>So, in some sense, that''s
  a local property because</span> <span m=''3208000''>I don''t have to look at what
  the rest of the tree is.</span> </p><p><span m=''3214000''>I''m just looking at
  some small set of vertices if I wish,</span> <span m=''3218000''>and I say, well,
  if I wanted to connect that set</span> <span m=''3222000''>of vertices to the rest
  of the world, what would I pick?</span> </p><p><span m=''3226000''>I''d pick the
  cheapest one. That''s the greedy approach.</span> </p><p><span m=''3230000''>It
  turns out, that wins, OK,</span> <span m=''3233000''>that picking that thing that''s
  locally good for that subset,</span> <span m=''3237000''>A, OK, is also globally
  good. OK, it optimizes the overall</span> <span m=''3244000''>function. That''s
  what the theorem says,</span> <span m=''3249000''>OK? So, let''s prove this theorem.</span>
  </p><p><span m=''3253000''>Any questions about this? OK, let''s prove this theorem.</span>
  </p><p><span m=''3260000''>So, we have (u,v) is the least weight edge connecting
  A to D</span> <span m=''3267000''>minus A. So, let''s suppose that this</span> <span
  m=''3272000''>edge, (u,v), is not in the minimum spanning tree.</span> </p><p><span
  m=''3280000''>OK, let''s suppose that somehow there is a minimum spanning tree</span>
  <span m=''3285000''>that doesn''t include this least weight edge.</span> </p><p><span
  m=''3290000''>OK, so what technique you think will use to prove to get a</span>
  <span m=''3295000''>contradiction here? Cut and paste,</span> <span m=''3298000''>good.
  Yeah, we''re going to cut paste.</span> </p><p><span m=''3304000''>OK, we''re going
  to cut and paste.</span> </p><p><span m=''3308000''>So here, I did an example. OK,
  so --</span> <span m=''3340000''>OK, and so I''m going to use the notation.</span>
  </p><p><span m=''3342000''>I''m going to color some of these in.</span> </p><p><span
  m=''3365000''>OK, and so my notation here is this is an element of A,</span> <span
  m=''3370000''>and color it in. It''s an element of V minus A.</span> </p><p><span
  m=''3374000''>OK, so if it''s not colored it, that''s an A.</span> </p><p><span
  m=''3378000''>This is my minimum spanning tree.</span> </p><p><span m=''3381000''>Once
  again, I''m not showing the overall edges of all the graphs,</span> <span m=''3387000''>but
  they''re there, OK?</span> </p><p><span m=''3390000''>So, my edge, (u,v), which
  is not my minimum</span> <span m=''3393000''>spanning tree I say, let''s say is
  this edge here.</span> </p><p><span m=''3398000''>It''s an edge from u, u as in
  A, v as in V minus A.</span> </p><p><span m=''3402000''>OK, so everybody see the
  setup? So, I want to prove that this</span> <span m=''3408000''>edge should have
  been in the minimum spanning tree,</span> <span m=''3412000''>OK, that the contention
  that this is a minimum spanning tree,</span> <span m=''3418000''>and does include
  (u,v) is wrong.</span> </p><p><span m=''3422000''>So, what I want to do, that, is
  I have a tree here,</span> <span m=''3425000''>T, and I have two vertices, u and
  v, and in a tree,</span> <span m=''3428000''>between any two vertices there is a
  unique, simple path:</span> <span m=''3432000''>simple path meaning it doesn''t
  go back and forth and repeat</span> <span m=''3436000''>edges or vertices. OK, there''s
  a unique,</span> <span m=''3438000''>simple path from u to v. So, let''s consider
  that path.</span> </p><p><span m=''3462000''>OK, and the way that I know that that
  path exists is because</span> <span m=''3466000''>I''(V,E) read appendix B of the
  textbook, section B.5.1,</span> <span m=''3471000''>OK, which has this nice theorem
  about properties of trees.</span> </p><p><span m=''3476000''>OK, so that''s how
  I know that there exists a unique,</span> <span m=''3480000''>simple path. OK, so
  now we''re going to do is</span> <span m=''3485000''>take a look at that path. So
  in this case,</span> <span m=''3489000''>it goes from here, to here, to here,</span>
  <span m=''3493000''>to here. And along that path,</span> <span m=''3496000''>there
  must be a point where I connect from a vertex in A to a</span> <span m=''3502000''>vertex
  in V minus A. Why?</span> </p><p><span m=''3505000''>Well, because this is in A.
  This is in V minus A.</span> </p><p><span m=''3512000''>So, along the path somewhere,
  there must be a transition.</span> </p><p><span m=''3522000''>OK, they are not all
  in A, OK, because in particular,</span> <span m=''3532000''>V isn''t. OK, so we''re
  going to do is</span> <span m=''3538000''>swap (u,v) with the first edge on this
  path that connects a</span> <span m=''3549000''>vertex in A to a vertex in V minus
  A.</span> </p><p><span m=''3558000''>So in this case, it''s this edge here.</span>
  </p><p><span m=''3560000''>I go from A to V minus A. In general, I might be</span>
  <span m=''3564000''>alternating many times, OK, and I just picked the first</span>
  <span m=''3568000''>one that I encounter. OK, that this guy here.</span> </p><p><span
  m=''3572000''>And what I do is I put this edge in.</span> </p><p><span m=''3576000''>OK,
  so then, what happens?</span> </p><p><span m=''3578000''>Well, the edge, (u,v),
  is the lightest thing</span> <span m=''3582000''>connecting something in A to something
  in V minus A.</span> </p><p><span m=''3586000''>So that means, in particular,</span>
  <span m=''3589000''>it''s lighter than this edge, has lower weight.</span> </p><p><span
  m=''3593000''>So, by swapping this, I''(V,E) created a tree with</span> <span m=''3597000''>lower
  overall weight, contradicting the assumption</span> <span m=''3602198''>that this
  other thing was a minimum spanning tree.</span> </p><p><span m=''3608000''>OK: so,
  a lower weight spanning tree than T results,</span> <span m=''3614219''>and that''s
  a contradiction --</span> <span m=''3625000''>-- than T results. And that''s a contradiction,</span>
  <span m=''3633010''>OK? How are we doing?</span> </p><p><span m=''3636570''>Everybody
  with me? OK, now we get to do some</span> <span m=''3644225''>algorithms. Yea!</span>
  </p><p><span m=''3646895''>So, we are going to do an algorithm called Prim''s</span>
  <span m=''3655439''>algorithm. Prim eventually became a very</span> <span m=''3661853''>high-up
  at AT&T because he invented this algorithm for</span> <span m=''3667069''>minimum
  spanning trees, and it was used in all of the</span> <span m=''3672187''>billing
  code for AT&T for many years.</span> </p><p><span m=''3675730''>He was very high
  up at Bell Labs back in the heyday of Bell</span> <span m=''3681438''>Laboratories.
  OK, so it just shows,</span> <span m=''3684784''>all you have to do is invent an
  algorithm.</span> </p><p><span m=''3690000''>You too can be a president of a corporate
  monopoly.</span> </p><p><span m=''3696702''>Of course, the government can do things
  to monopolies,</span> <span m=''3703807''>but anyway, if that''s your mission in
  life,</span> <span m=''3709438''>invent an algorithm. OK, so here''s the idea.</span>
  </p><p><span m=''3715202''>What we''re going to do is we''re going to maintain V
  minus A as a</span> <span m=''3723648''>priority queue. We''ll call it Q.</span>
  </p><p><span m=''3731923''>And each vertex, we''re going to key each vertex</span>
  <span m=''3746076''>in Q with the weight of the least weight edge,</span> <span
  m=''3759923''>connecting it to a vertex in A. So here''s the code.</span> </p><p><span
  m=''3773280''>So, we''re going to start out with Q being all vertices.</span> </p><p><span
  m=''3780000''>So, we start out with A being, if you will,</span> <span m=''3783873''>the
  empty set. OK, and what we''re going to do</span> <span m=''3787930''>it is the
  least weight edge, therefore, for everything in</span> <span m=''3793095''>the priority
  queue is basically going to be infinity because</span> <span m=''3798536''>none
  of them have any edges. The least weight edge to the</span> <span m=''3803700''>empty
  set is going to be empty. And then, we''re going to start</span> <span m=''3809325''>out
  with one guy. We''ll call him S,</span> <span m=''3813958''>which will set to zero
  for some arbitrary S in V.</span> </p><p><span m=''3819489''>And then, the main
  part of the algorithm kicks in.</span> </p><p><span m=''3825135''>So that''s our
  initialization. OK, when we do the analysis,</span> <span m=''3831703''>I''m going
  to write some stuff on the left hand side of the</span> <span m=''3838271''>board.
  So if you''re taking notes,</span> <span m=''3844406''>you may want to also leave
  a little bit of space on the left</span> <span m=''3854406''>hand side of your notes.
  So, while Q is not empty,</span> <span m=''3862711''>we get the smallest element
  out of it.</span> </p><p><span m=''3881000''>And then we do some stuff.</span> </p><p><span
  m=''3919000''>That''s it. And the only thing I should</span> <span m=''3921970''>mention
  here is, OK, so let''s just see what''s</span> <span m=''3925503''>going on here.
  And then we''ll run it on the</span> <span m=''3928875''>example. OK, so what we
  do is we take</span> <span m=''3932256''>out the smallest element out of the queue
  at each step.</span> </p><p><span m=''3936609''>And then for each step in the adjacency
  list,</span> <span m=''3940156''>in other words, everything for which I have an</span>
  <span m=''3943783''>edge going from v to u, we take a look,</span> <span m=''3946846''>and
  if v is still in our set V minus A, so things we''(V,E)</span> <span m=''3951440''>taken
  out are going to be part of A.</span> </p><p><span m=''3954261''>OK, every time
  we take something out,</span> <span m=''3957163''>that''s going to be a new A that
  we construct.</span> </p><p><span m=''3962000''>At every step, we want to find,</span>
  <span m=''3964258''>what''s the cheapest edge connecting that A to everything</span>
  <span m=''3968400''>else? We basically are going to take</span> <span m=''3971035''>whatever
  that cheapest thing is, OK, add that edge in,</span> <span m=''3975025''>and now
  bring that into A and find the next cheapest one.</span> </p><p><span m=''3979242''>And
  we just keep repeating the process.</span> </p><p><span m=''3982103''>OK, we''ll
  do it on the example. And what we do,</span> <span m=''3985567''>is every time we
  bring it in, I keep track of,</span> <span m=''3988955''>what was the vertex responsible
  for bringing me in.</span> </p><p><span m=''3994000''>And what I claim is that at
  the end, if I look at the set of</span> <span m=''4003947''>these pairs that I''(V,E)
  made here, V and pi of V,</span> <span m=''4012209''>that forms the minimum spanning
  tree.</span> </p><p><span m=''4018279''>So let''s just do this. And, what''s that?</span>
  </p><p><span m=''4025441''>We''re all set up. So let''s get rid of these guys</span>
  <span m=''4032191''>here because we are going to recompute them from scratch.</span>
  </p><p><span m=''4040234''>OK, so you may want to copy the graph over again in your
  notes.</span> </p><p><span m=''4050000''>I was going to do it, but it turned out,</span>
  <span m=''4054840''>this is exactly the board is going to erase this.</span> </p><p><span
  m=''4060797''>OK, well let me just modify it. OK, so we start out.</span> </p><p><span
  m=''4067127''>We make everything be infinity. OK, so that''s where I''m going</span>
  <span m=''4074574''>to keep the key value. OK, and then what I''m going to</span>
  <span m=''4081028''>do is find one vertex. And I''m going to call him S.</span>
  </p><p><span m=''4087952''>And I''m going to do this vertex here.</span> </p><p><span
  m=''4091749''>We''ll call that S. So basically,</span> <span m=''4095018''>I now
  make him be zero. And now, what I do,</span> <span m=''4099447''>is I execute extract
  min. So basically,</span> <span m=''4103453''>what I''ll do is I''ll just shade
  him like this,</span> <span m=''4108198''>indicating that he has now joined the
  set A.</span> </p><p><span m=''4114000''>So, this is going to be A. And this is
  element of V minus</span> <span m=''4120931''>A. OK, so then what we do is we</span>
  <span m=''4124644''>take a look. We extract him,</span> <span m=''4127986''>and
  then for each edge in the adjacency list,</span> <span m=''4133433''>OK, so for
  each vertex in the adjacency lists,</span> <span m=''4139002''>that these guys here,
  OK, we''re going to look to see</span> <span m=''4145315''>if it''s still in Q,
  that is, in V minus A.</span> </p><p><span m=''4152000''>And if so, and its key
  value is less than what the value is at</span> <span m=''4156795''>the edge, there,
  we''re going to replace it by</span> <span m=''4160254''>the edge value. So, in
  this case,</span> <span m=''4162770''>we''re going to replace this by seven.</span>
  </p><p><span m=''4165600''>We''re going to replace this by 15, and we''re going
  to replace</span> <span m=''4170317''>this by ten, OK, because what we''re interested</span>
  <span m=''4173854''>in is, what is the cheapest? Now, notice that everything in</span>
  <span m=''4179608''>V minus A, that is, what''s in the priority queue,</span> <span
  m=''4183782''>everything in there, OK, now has its cheapest way of</span> <span
  m=''4188216''>connecting it to the things that I''(V,E) already removed,</span>
  <span m=''4193086''>the things that are in A. OK, and so now I just,</span> <span
  m=''4197173''>OK, when I actually do that update, there''s actually</span> <span
  m=''4201608''>something implicit going on in this priority queue.</span> </p><p><span
  m=''4207000''>And that is that I have to do a decreased key.</span> </p><p><span
  m=''4210636''>So, there''s an implicit decrease of the key.</span> </p><p><span
  m=''4214111''>So, decreased key is a priority queue operation that lowers the</span>
  <span m=''4219121''>value of the key in the priority queue.</span> </p><p><span
  m=''4222191''>And so, that''s implicitly going on when I look at what data</span>
  <span m=''4226878''>structure I''m going to use to implement that priority queue.</span>
  </p><p><span m=''4231646''>OK, so common data structures for implementing a priority</span>
  <span m=''4236171''>queue are a min heap. OK, so I have to make sure that</span>
  <span m=''4241376''>I''m actually doing this operation.</span> </p><p><span m=''4243905''>I
  can''t just change it and not affect my heap.</span> </p><p><span m=''4247355''>So,
  there is an implicit operation going on there.</span> </p><p><span m=''4251111''>OK,
  now I repeat. I find the cheapest thing,</span> <span m=''4254407''>oh, and I also
  have to set, now, a pointer from each of</span> <span m=''4258547''>these guys back
  to u. So here, this guy sets a</span> <span m=''4262931''>pointer going this way.
  This guy sets a pointer going</span> <span m=''4267114''>this way, and this guy
  sets a pointer going this way.</span> </p><p><span m=''4271298''>That''s my pi thing
  that''s going to keep track of who caused me</span> <span m=''4276206''>to set my
  value to what it is. So now, we go in and we find</span> <span m=''4280873''>the
  cheapest thing, again.</span> </p><p><span m=''4282885''>And we''re going to do
  it fast, too.</span> </p><p><span m=''4285620''>OK, this is a fast algorithm. OK,
  so now we''re going to go do</span> <span m=''4292361''>this again. So now, what''s
  the cheapest</span> <span m=''4296481''>thing to extract? This guy here,</span>
  <span m=''4299843''>right? So, we''ll take him out,</span> <span m=''4302987''>OK,
  and now we update all of his neighbors.</span> </p><p><span m=''4307542''>So this
  guy gets five. This guy gets 12.</span> </p><p><span m=''4311771''>This guy gets
  nine. This guy we don''t update.</span> </p><p><span m=''4316542''>We don''t update
  him because he''s no longer in the priority</span> <span m=''4322722''>queue. And
  all of these guys now,</span> <span m=''4327464''>we make point to where they''re
  supposed to point to.</span> </p><p><span m=''4332297''>And, we''re done with that
  step. Now we find the cheapest one.</span> </p><p><span m=''4337983''>What''s the
  cheapest one now? The five over here.</span> </p><p><span m=''4342437''>Good. So,
  we take him out.</span> </p><p><span m=''4344807''>OK, we update the neighbors.
  Here, yep, that goes to six</span> <span m=''4350019''>now. And, we have that pointer.</span>
  </p><p><span m=''4354000''>And, this guy we don''t do, because he''s not in there.</span>
  </p><p><span m=''4359684''>This guy becomes 14, and this guy here becomes</span>
  <span m=''4364604''>eight. So, we update that guy,</span> <span m=''4367774''>make
  him be eight. Did I do this the right way?</span> </p><p><span m=''4372803''>Yeah,
  because pi is a function of this guy.</span> </p><p><span m=''4377395''>So basically,
  this thing, then,</span> <span m=''4380675''>disappears. Yeah, did I have another
  one</span> <span m=''4384938''>that I missed? 12, yes, good,</span> <span m=''4389258''>it''s
  removed, OK, because pi is just a</span> <span m=''4392584''>function. And now I''m
  OK.</span> </p><p><span m=''4394741''>OK, so now what do I do? OK, so now my set,</span>
  <span m=''4398516''>A, consists of these three things, and now I want the</span>
  <span m=''4403191''>cheapest edge. I know it''s in the minimum</span> <span m=''4406786''>spanning
  tree. So let me just greedily pick</span> <span m=''4410561''>it. OK, so what''s
  the cheapest</span> <span m=''4414554''>thing now? This guy appear?</span> </p><p><span
  m=''4417108''>Yeah, six. So we take it.</span> </p><p><span m=''4419466''>We go
  to update these things, and nothing matters here.</span> </p><p><span m=''4424771''>OK,
  nothing changes because these guys are already in A.</span> </p><p><span m=''4430175''>OK,
  so now the cheapest one is eight here.</span> </p><p><span m=''4434202''>Good. So,
  we take eight out.</span> </p><p><span m=''4436856''>OK, we update this. Nothing
  to be done.</span> </p><p><span m=''4441656''>This: nothing to be done. This: oh,
  no,</span> <span m=''4444970''>this one, instead of 14 we can make this be three.</span>
  </p><p><span m=''4449242''>So, we get rid of that pointer and make it point that
  way.</span> </p><p><span m=''4454212''>Now three is the cheapest thing.</span> </p><p><span
  m=''4456915''>So, we take it out, and of course there''s nothing</span> <span m=''4461100''>to
  be done over there. And now, last,</span> <span m=''4464239''>I take nine. And it''s
  done.</span> </p><p><span m=''4466506''>And 15: it''s done. And the algorithm terminates.</span>
  </p><p><span m=''4472000''>OK, and as I look at, now, all the edges that I</span>
  <span m=''4476972''>picked, those are exactly all the edges that we had at the</span>
  <span m=''4483135''>beginning. OK, let''s do an analysis here.</span> </p><p><span
  m=''4498000''>OK, so let''s see, this part here costs me order</span> <span m=''4506316''>V,
  right? OK, and this part,</span> <span m=''4511197''>let''s see what we are doing
  here.</span> </p><p><span m=''4516983''>Well, we''re going to go through this loop
  how many times?</span> </p><p><span m=''4527107''>V times. It''s V elements we put
  into the</span> <span m=''4532711''>queue. We are not inserting anything.</span>
  </p><p><span m=''4535860''>We''re just taking them out. This goes V times,</span>
  <span m=''4539795''>OK, and we do a certain number of extract Mins.</span> </p><p><span
  m=''4543818''>So, we''re going to do order V extract Mins.</span> </p><p><span m=''4547492''>And
  then we go to the adjacency list, and we have some constant</span> <span m=''4552915''>things.
  But we have these implicit</span> <span m=''4555801''>decreased keys for this stuff
  here.</span> </p><p><span m=''4560000''>That''s this thing here. OK, and so how
  many implicit</span> <span m=''4567412''>decreased keys do we have? That''s going
  to be the</span> <span m=''4574389''>expensive thing. OK, we have,</span> <span
  m=''4578459''>in this case, the degree of u of those.</span> </p><p><span m=''4585000''>OK,
  so overall, how many implicit decreased</span> <span m=''4591309''>keys do we have?
  Well, we have V times through.</span> </p><p><span m=''4598218''>How big could the
  degree of u be?</span> </p><p><span m=''4603025''>OK, it could be as big as V, order
  V.</span> </p><p><span m=''4608433''>So, that''s V^2 decreased use. But we can do
  a better bound</span> <span m=''4616995''>than that. How many do we really have?</span>
  </p><p><span m=''4624189''>Yeah, at most order E, OK, because what am I doing?</span>
  </p><p><span m=''4631948''>I''m summing up the degrees of all the vertices.</span>
  </p><p><span m=''4639086''>That''s how many times I actually execute that.</span>
  </p><p><span m=''4647000''>So, I have order E, implicit decreased keys.</span> </p><p><span
  m=''4654322''>So the time overall is order V times time for whatever the</span>
  <span m=''4664028''>extract Min is plus E times the time for decreased key.</span>
  </p><p><span m=''4673224''>So now, let''s look at data structures, and we can evaluate</span>
  <span m=''4682931''>for different data structures what this formula gives us.</span>
  </p><p><span m=''4694000''>So, we have different ways of implementing a data structure.</span>
  </p><p><span m=''4701492''>We have the cost of extract Min, and of decreased key,</span>
  <span m=''4708222''>and total. So, the simplest way of</span> <span m=''4712636''>implementing
  a data structure is an unsorted array.</span> </p><p><span m=''4718369''>If I have
  an unsorted array, how much time does it take me</span> <span m=''4724904''>to extract
  the minimum element? If I have an unsorted array?</span> </p><p><span m=''4731668''>Right,
  order V in this case because it''s an array of size V.</span> </p><p><span m=''4738433''>And,
  to do a decreased key, OK, I can do it in order one.</span> </p><p><span m=''4746000''>So,
  the total is V^2, good, order V^2 algorithm.</span> </p><p><span m=''4754245''>Or,
  as people suggested, how about a binary heap?</span> </p><p><span m=''4762666''>OK,
  to do an extract Min in a binary heap will cost me what?</span> </p><p><span m=''4773017''>O
  of log V. Decreased key will cost me,</span> <span m=''4778905''>yeah, it turns
  out you can do that in order log V because</span> <span m=''4784932''>basically
  you just have to shuffle the value,</span> <span m=''4789668''>actually shuffle
  it up towards the root, OK?</span> </p><p><span m=''4794295''>Or at log V. And,
  the total cost therefore</span> <span m=''4798708''>is? E log V, good.</span> </p><p><span
  m=''4801717''>Which of these is better? It depends, good.</span> </p><p><span m=''4806869''>When
  is one better, and when is the other better?</span> </p><p><span m=''4812758''>Yeah,
  if it''s a dense graph, E is close to V^2,</span> <span m=''4818401''>the array
  is better. But if it''s a sparse graph,</span> <span m=''4824166''>and E is much
  smaller than V^2, then the binary heap is better.</span> </p><p><span m=''4833000''>So
  that motivated the invention of a data structure,</span> <span m=''4837824''>OK,
  called a Fibonacci Heap. So, Fibonacci Heap is covered</span> <span m=''4843216''>in
  Chapter 20 of CLRS. We''re not going to hold you</span> <span m=''4847851''>responsible
  for the content, but it''s an interesting data</span> <span m=''4853148''>structure
  because it''s an amortized data structure.</span> </p><p><span m=''4857878''>And
  it turns out that it is data structure,</span> <span m=''4861851''>you can do extract
  Min in order log V amortized time.</span> </p><p><span m=''4868000''>And remarkably,
  you can do decreased key in</span> <span m=''4872747''>order one amortized. So,
  when I plug those in,</span> <span m=''4877834''>what do I get over here?</span>
  </p><p><span m=''4894000''>What''s that going to be? Plug that it here.</span> </p><p><span
  m=''4902088''>It''s going to be V times log V plus E: E plus V log V.</span> </p><p><span
  m=''4912296''>These are amortized, so what''s this?</span> </p><p><span m=''4920000''>Trick
  question. It''s worst-case.</span> </p><p><span m=''4922317''>It''s not amortized
  over here. These are amortized,</span> <span m=''4925979''>but that''s the beauty
  of amortization.</span> </p><p><span m=''4928745''>I can say it''s going to be worst
  case: E plus V log V over</span> <span m=''4933006''>here, because when I add up
  the amortized cost of my operations,</span> <span m=''4937715''>it''s an upper bound
  on the true costs.</span> </p><p><span m=''4940480''>OK, so that''s why I say, one
  of the beauties of this</span> <span m=''4944291''>amortized analysis, and in particular,</span>
  <span m=''4947058''>being able to assign different costs to different operations
  is</span> <span m=''4951692''>I can just add them up and I get my worst-case costs.</span>
  </p><p><span m=''4957000''>So this is already V log V. There are a couple other</span>
  <span m=''4960565''>algorithms just before I let you go.</span> </p><p><span m=''4963012''>Kruskal''s
  Algorithm in the book uses another amortized data</span> <span m=''4967066''>structure
  called a disjoint set data structure,</span> <span m=''4970282''>which also runs
  in E log V, that is, this time:</span> <span m=''4973498''>runs in this time, the
  same as using a binary</span> <span m=''4976574''>heap. So, I''ll refer you to the
  book.</span> </p><p><span m=''4980000''>The best algorithm to date with this problem
  is done by our own</span> <span m=''4984934''>David Karger on the faculty here with
  one of our former</span> <span m=''4989233''>graduates, Phil Kline, who is now a
  professor at</span> <span m=''4992975''>Brown, and Robert Tarjan, who is sort of
  like the master</span> <span m=''4997353''>of all data structures who was a professor
  at Princeton in 1993.</span> </p><p><span m=''5002368''>OK, it''s a randomized algorithm,
  and it gives you</span> <span m=''5006189''>order V plus E expected time. OK, so
  that''s the best to date.</span> </p><p><span m=''5012000''>It''s still open as
  to whether there is a deterministic,</span> <span m=''5016300''>there is worst-case
  bound, whether there is a worst-case</span> <span m=''5020679''>bound that is linear
  time. OK, but there is a randomized</span> <span m=''5025059''>to linear time, and
  otherwise,</span> <span m=''5027369''>this is essentially the best bound without
  additional</span> <span m=''5031509''>assumptions. OK, very cool stuff.</span> </p><p><span
  m=''5034058''>Next, we''re going to see a lot of these ideas of greedy and</span>
  <span m=''5038675''>dynamic programming in practice.</span> </p>'
type: course
uid: 3b98255fecbddd4ef435b8937a71eed9

---
None